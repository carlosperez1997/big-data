21/12/17 13:33:58 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
21/12/17 13:34:01 INFO SparkContext: Running Spark version 2.3.3
21/12/17 13:34:01 WARN SparkConf: In Spark 1.0 and later spark.local.dir will be overridden by the value set by the cluster manager (via SPARK_LOCAL_DIRS in mesos/standalone and LOCAL_DIRS in YARN).
21/12/17 13:34:01 INFO SparkContext: Submitted application: sparklyr
21/12/17 13:34:01 INFO SecurityManager: Changing view acls to: uhp07025
21/12/17 13:34:01 INFO SecurityManager: Changing modify acls to: uhp07025
21/12/17 13:34:01 INFO SecurityManager: Changing view acls groups to: 
21/12/17 13:34:01 INFO SecurityManager: Changing modify acls groups to: 
21/12/17 13:34:01 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(uhp07025); groups with view permissions: Set(); users  with modify permissions: Set(uhp07025); groups with modify permissions: Set()
21/12/17 13:34:01 INFO Utils: Successfully started service 'sparkDriver' on port 56966.
21/12/17 13:34:01 INFO SparkEnv: Registering MapOutputTracker
21/12/17 13:34:01 INFO SparkEnv: Registering BlockManagerMaster
21/12/17 13:34:01 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
21/12/17 13:34:01 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
21/12/17 13:34:01 INFO DiskBlockManager: Created local directory at C:\Users\uhp07025\AppData\Local\spark\spark-2.3.3-bin-hadoop2.7\tmp\local\blockmgr-4c6778a6-e5aa-4783-b3ec-e44534ff5399
21/12/17 13:34:01 INFO MemoryStore: MemoryStore started with capacity 912.3 MB
21/12/17 13:34:01 INFO SparkEnv: Registering OutputCommitCoordinator
21/12/17 13:34:01 WARN Utils: The configured local directories are not expected to be URIs; however, got suspicious values [C:/Users/uhp07025/AppData/Local/spark/spark-2.3.3-bin-hadoop2.7/tmp/local]. Please check your configured local directories.
21/12/17 13:34:02 INFO Utils: Successfully started service 'SparkUI' on port 4040.
21/12/17 13:34:02 INFO SparkUI: Bound SparkUI to 127.0.0.1, and started at http://kubernetes.docker.internal:4040
21/12/17 13:34:02 INFO SparkContext: Added JAR file:/C:/Users/uhp07025/Documents/R/win-library/4.1/sparklyr/java/sparklyr-2.3-2.11.jar at spark://kubernetes.docker.internal:56966/jars/sparklyr-2.3-2.11.jar with timestamp 1639744442451
21/12/17 13:34:02 INFO Executor: Starting executor ID driver on host localhost
21/12/17 13:34:02 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 57009.
21/12/17 13:34:02 INFO NettyBlockTransferService: Server created on kubernetes.docker.internal:57009
21/12/17 13:34:02 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
21/12/17 13:34:02 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, kubernetes.docker.internal, 57009, None)
21/12/17 13:34:02 INFO BlockManagerMasterEndpoint: Registering block manager kubernetes.docker.internal:57009 with 912.3 MB RAM, BlockManagerId(driver, kubernetes.docker.internal, 57009, None)
21/12/17 13:34:02 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, kubernetes.docker.internal, 57009, None)
21/12/17 13:34:02 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, kubernetes.docker.internal, 57009, None)
21/12/17 13:34:03 INFO SharedState: loading hive config file: file:/C:/Users/uhp07025/AppData/Local/spark/spark-2.3.3-bin-hadoop2.7/conf/hive-site.xml
21/12/17 13:34:03 INFO SharedState: Setting hive.metastore.warehouse.dir ('C:/Users/uhp07025/AppData/Local/spark/spark-2.3.3-bin-hadoop2.7/tmp/hive') to the value of spark.sql.warehouse.dir ('C:/Users/uhp07025/AppData/Local/spark/spark-2.3.3-bin-hadoop2.7/tmp/hive').
21/12/17 13:34:03 INFO SharedState: Warehouse path is 'C:/Users/uhp07025/AppData/Local/spark/spark-2.3.3-bin-hadoop2.7/tmp/hive'.
21/12/17 13:34:04 INFO StateStoreCoordinatorRef: Registered StateStoreCoordinator endpoint
21/12/17 13:34:07 INFO HiveUtils: Initializing HiveMetastoreConnection version 1.2.1 using Spark classes.
21/12/17 13:34:08 INFO HiveMetaStore: 0: Opening raw store with implemenation class:org.apache.hadoop.hive.metastore.ObjectStore
21/12/17 13:34:08 INFO ObjectStore: ObjectStore, initialize called
21/12/17 13:34:08 INFO Persistence: Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
21/12/17 13:34:08 INFO Persistence: Property datanucleus.cache.level2 unknown - will be ignored
21/12/17 13:34:11 INFO ObjectStore: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
21/12/17 13:34:12 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
21/12/17 13:34:12 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
21/12/17 13:34:14 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
21/12/17 13:34:14 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
21/12/17 13:34:14 INFO MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
21/12/17 13:34:14 INFO ObjectStore: Initialized ObjectStore
21/12/17 13:34:14 WARN ObjectStore: Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 1.2.0
21/12/17 13:34:14 WARN ObjectStore: Failed to get database default, returning NoSuchObjectException
21/12/17 13:34:14 INFO HiveMetaStore: Added admin role in metastore
21/12/17 13:34:14 INFO HiveMetaStore: Added public role in metastore
21/12/17 13:34:14 INFO HiveMetaStore: No user is added in admin role, since config is empty
21/12/17 13:34:14 INFO HiveMetaStore: 0: get_all_databases
21/12/17 13:34:14 INFO audit: ugi=uhp07025	ip=unknown-ip-addr	cmd=get_all_databases	
21/12/17 13:34:14 INFO HiveMetaStore: 0: get_functions: db=default pat=*
21/12/17 13:34:14 INFO audit: ugi=uhp07025	ip=unknown-ip-addr	cmd=get_functions: db=default pat=*	
21/12/17 13:34:14 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MResourceUri" is tagged as "embedded-only" so does not have its own datastore table.
21/12/17 13:34:15 INFO SessionState: Created HDFS directory: C:/Users/uhp07025/AppData/Local/spark/spark-2.3.3-bin-hadoop2.7/tmp/hive/uhp07025
21/12/17 13:34:15 INFO SessionState: Created local directory: C:/Users/uhp07025/AppData/Local/Temp/5aa02e9f-a2ef-4578-af1b-f876d24e0e96_resources
21/12/17 13:34:15 INFO SessionState: Created HDFS directory: C:/Users/uhp07025/AppData/Local/spark/spark-2.3.3-bin-hadoop2.7/tmp/hive/uhp07025/5aa02e9f-a2ef-4578-af1b-f876d24e0e96
21/12/17 13:34:15 INFO SessionState: Created local directory: C:/Users/uhp07025/AppData/Local/spark/spark-2.3.3-bin-hadoop2.7/tmp/hive/5aa02e9f-a2ef-4578-af1b-f876d24e0e96
21/12/17 13:34:15 INFO SessionState: Created HDFS directory: C:/Users/uhp07025/AppData/Local/spark/spark-2.3.3-bin-hadoop2.7/tmp/hive/uhp07025/5aa02e9f-a2ef-4578-af1b-f876d24e0e96/_tmp_space.db
21/12/17 13:34:15 INFO HiveClientImpl: Warehouse location for Hive client (version 1.2.2) is C:/Users/uhp07025/AppData/Local/spark/spark-2.3.3-bin-hadoop2.7/tmp/hive
21/12/17 13:34:15 INFO HiveMetaStore: 0: get_database: default
21/12/17 13:34:15 INFO audit: ugi=uhp07025	ip=unknown-ip-addr	cmd=get_database: default	
21/12/17 13:34:15 INFO HiveMetaStore: 0: get_database: global_temp
21/12/17 13:34:15 INFO audit: ugi=uhp07025	ip=unknown-ip-addr	cmd=get_database: global_temp	
21/12/17 13:34:15 WARN ObjectStore: Failed to get database global_temp, returning NoSuchObjectException
21/12/17 13:34:16 INFO HiveMetaStore: 0: get_database: default
21/12/17 13:34:16 INFO audit: ugi=uhp07025	ip=unknown-ip-addr	cmd=get_database: default	
21/12/17 13:34:16 INFO HiveMetaStore: 0: get_database: default
21/12/17 13:34:16 INFO audit: ugi=uhp07025	ip=unknown-ip-addr	cmd=get_database: default	
21/12/17 13:34:16 INFO HiveMetaStore: 0: get_tables: db=default pat=*
21/12/17 13:34:16 INFO audit: ugi=uhp07025	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
21/12/17 13:34:17 INFO CodeGenerator: Code generated in 328.0836 ms
21/12/17 13:34:18 INFO CodeGenerator: Code generated in 26.017 ms
21/12/17 13:34:18 INFO CodeGenerator: Code generated in 26.4682 ms
21/12/17 13:34:18 INFO SparkContext: Starting job: collect at utils.scala:24
21/12/17 13:34:18 INFO DAGScheduler: Got job 0 (collect at utils.scala:24) with 1 output partitions
21/12/17 13:34:18 INFO DAGScheduler: Final stage: ResultStage 0 (collect at utils.scala:24)
21/12/17 13:34:18 INFO DAGScheduler: Parents of final stage: List()
21/12/17 13:34:18 INFO DAGScheduler: Missing parents: List()
21/12/17 13:34:18 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[4] at collect at utils.scala:24), which has no missing parents
21/12/17 13:34:18 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.8 KB, free 912.3 MB)
21/12/17 13:34:19 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 3.3 KB, free 912.3 MB)
21/12/17 13:34:19 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on kubernetes.docker.internal:57009 (size: 3.3 KB, free: 912.3 MB)
21/12/17 13:34:19 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1039
21/12/17 13:34:19 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[4] at collect at utils.scala:24) (first 15 tasks are for partitions Vector(0))
21/12/17 13:34:19 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks
21/12/17 13:34:19 INFO ContextCleaner: Cleaned accumulator 0
21/12/17 13:34:19 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 8067 bytes)
21/12/17 13:34:19 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
21/12/17 13:34:19 INFO Executor: Fetching spark://kubernetes.docker.internal:56966/jars/sparklyr-2.3-2.11.jar with timestamp 1639744442451
21/12/17 13:34:19 INFO TransportClientFactory: Successfully created connection to kubernetes.docker.internal/127.0.0.1:56966 after 62 ms (0 ms spent in bootstraps)
21/12/17 13:34:19 INFO Utils: Fetching spark://kubernetes.docker.internal:56966/jars/sparklyr-2.3-2.11.jar to C:\Users\uhp07025\AppData\Local\spark\spark-2.3.3-bin-hadoop2.7\tmp\local\spark-bf2229bb-13e6-4b5a-b618-2838928c1bbd\userFiles-aed64159-b439-448e-97f2-6908bed49a42\fetchFileTemp685955025388900172.tmp
21/12/17 13:34:19 INFO Executor: Adding file:/C:/Users/uhp07025/AppData/Local/spark/spark-2.3.3-bin-hadoop2.7/tmp/local/spark-bf2229bb-13e6-4b5a-b618-2838928c1bbd/userFiles-aed64159-b439-448e-97f2-6908bed49a42/sparklyr-2.3-2.11.jar to class loader
21/12/17 13:34:20 INFO CodeGenerator: Code generated in 26.0108 ms
21/12/17 13:34:20 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1329 bytes result sent to driver
21/12/17 13:34:20 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 801 ms on localhost (executor driver) (1/1)
21/12/17 13:34:20 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
21/12/17 13:34:20 INFO DAGScheduler: ResultStage 0 (collect at utils.scala:24) finished in 1.372 s
21/12/17 13:34:20 INFO DAGScheduler: Job 0 finished: collect at utils.scala:24, took 1.449147 s
21/12/17 13:34:20 INFO SparkContext: Starting job: collect at utils.scala:24
21/12/17 13:34:20 INFO DAGScheduler: Got job 1 (collect at utils.scala:24) with 1 output partitions
21/12/17 13:34:20 INFO DAGScheduler: Final stage: ResultStage 1 (collect at utils.scala:24)
21/12/17 13:34:20 INFO DAGScheduler: Parents of final stage: List()
21/12/17 13:34:20 INFO DAGScheduler: Missing parents: List()
21/12/17 13:34:20 INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[9] at collect at utils.scala:24), which has no missing parents
21/12/17 13:34:20 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 6.8 KB, free 912.3 MB)
21/12/17 13:34:20 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.3 KB, free 912.3 MB)
21/12/17 13:34:20 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on kubernetes.docker.internal:57009 (size: 3.3 KB, free: 912.3 MB)
21/12/17 13:34:20 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1039
21/12/17 13:34:20 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[9] at collect at utils.scala:24) (first 15 tasks are for partitions Vector(0))
21/12/17 13:34:20 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks
21/12/17 13:34:20 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1, localhost, executor driver, partition 0, PROCESS_LOCAL, 8067 bytes)
21/12/17 13:34:20 INFO Executor: Running task 0.0 in stage 1.0 (TID 1)
21/12/17 13:34:21 INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 1200 bytes result sent to driver
21/12/17 13:34:21 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 12 ms on localhost (executor driver) (1/1)
21/12/17 13:34:21 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
21/12/17 13:34:21 INFO DAGScheduler: ResultStage 1 (collect at utils.scala:24) finished in 0.028 s
21/12/17 13:34:21 INFO DAGScheduler: Job 1 finished: collect at utils.scala:24, took 0.032574 s
21/12/17 13:34:21 INFO HiveMetaStore: 0: get_database: default
21/12/17 13:34:21 INFO audit: ugi=uhp07025	ip=unknown-ip-addr	cmd=get_database: default	
21/12/17 13:34:21 INFO HiveMetaStore: 0: get_database: default
21/12/17 13:34:21 INFO audit: ugi=uhp07025	ip=unknown-ip-addr	cmd=get_database: default	
21/12/17 13:34:21 INFO HiveMetaStore: 0: get_tables: db=default pat=*
21/12/17 13:34:21 INFO audit: ugi=uhp07025	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
21/12/17 13:34:21 INFO CodeGenerator: Code generated in 19.2368 ms
21/12/17 13:34:21 INFO CodeGenerator: Code generated in 14.9159 ms
21/12/17 13:34:21 INFO HiveMetaStore: 0: get_database: default
21/12/17 13:34:21 INFO audit: ugi=uhp07025	ip=unknown-ip-addr	cmd=get_database: default	
21/12/17 13:34:21 INFO HiveMetaStore: 0: get_database: default
21/12/17 13:34:21 INFO audit: ugi=uhp07025	ip=unknown-ip-addr	cmd=get_database: default	
21/12/17 13:34:21 INFO HiveMetaStore: 0: get_tables: db=default pat=*
21/12/17 13:34:21 INFO audit: ugi=uhp07025	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
21/12/17 13:34:21 INFO HiveMetaStore: 0: get_database: default
21/12/17 13:34:21 INFO audit: ugi=uhp07025	ip=unknown-ip-addr	cmd=get_database: default	
21/12/17 13:34:21 INFO HiveMetaStore: 0: get_database: default
21/12/17 13:34:21 INFO audit: ugi=uhp07025	ip=unknown-ip-addr	cmd=get_database: default	
21/12/17 13:34:21 INFO HiveMetaStore: 0: get_tables: db=default pat=*
21/12/17 13:34:21 INFO audit: ugi=uhp07025	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
21/12/17 13:34:21 INFO CodeGenerator: Code generated in 14.7718 ms
21/12/17 13:34:21 INFO CodeGenerator: Code generated in 44.1709 ms
21/12/17 13:34:21 INFO SparkContext: Starting job: collect at utils.scala:24
21/12/17 13:34:21 INFO DAGScheduler: Got job 2 (collect at utils.scala:24) with 1 output partitions
21/12/17 13:34:21 INFO DAGScheduler: Final stage: ResultStage 2 (collect at utils.scala:24)
21/12/17 13:34:21 INFO DAGScheduler: Parents of final stage: List()
21/12/17 13:34:21 INFO DAGScheduler: Missing parents: List()
21/12/17 13:34:21 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[14] at collect at utils.scala:24), which has no missing parents
21/12/17 13:34:21 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 26.0 KB, free 912.3 MB)
21/12/17 13:34:21 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 9.4 KB, free 912.2 MB)
21/12/17 13:34:21 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on kubernetes.docker.internal:57009 (size: 9.4 KB, free: 912.3 MB)
21/12/17 13:34:21 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1039
21/12/17 13:34:21 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[14] at collect at utils.scala:24) (first 15 tasks are for partitions Vector(0))
21/12/17 13:34:21 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks
21/12/17 13:34:21 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2, localhost, executor driver, partition 0, PROCESS_LOCAL, 11614 bytes)
21/12/17 13:34:21 INFO Executor: Running task 0.0 in stage 2.0 (TID 2)
21/12/17 13:34:21 INFO CodeGenerator: Code generated in 17.0298 ms
21/12/17 13:34:22 INFO MemoryStore: Block rdd_6_0 stored as values in memory (estimated size 4.2 KB, free 912.2 MB)
21/12/17 13:34:22 INFO BlockManagerInfo: Added rdd_6_0 in memory on kubernetes.docker.internal:57009 (size: 4.2 KB, free: 912.3 MB)
21/12/17 13:34:22 INFO CodeGenerator: Code generated in 6.0448 ms
21/12/17 13:34:22 INFO Executor: Finished task 0.0 in stage 2.0 (TID 2). 2533 bytes result sent to driver
21/12/17 13:34:22 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 130 ms on localhost (executor driver) (1/1)
21/12/17 13:34:22 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
21/12/17 13:34:22 INFO DAGScheduler: ResultStage 2 (collect at utils.scala:24) finished in 0.150 s
21/12/17 13:34:22 INFO DAGScheduler: Job 2 finished: collect at utils.scala:24, took 0.157503 s
21/12/17 14:04:03 INFO ContextCleaner: Cleaned accumulator 24
21/12/17 14:04:03 INFO ContextCleaner: Cleaned accumulator 33
21/12/17 14:04:03 INFO ContextCleaner: Cleaned accumulator 78
21/12/17 14:04:03 INFO ContextCleaner: Cleaned accumulator 55
21/12/17 14:04:03 INFO ContextCleaner: Cleaned accumulator 80
21/12/17 14:04:03 INFO ContextCleaner: Cleaned accumulator 57
21/12/17 14:04:03 INFO ContextCleaner: Cleaned accumulator 84
21/12/17 14:04:03 INFO ContextCleaner: Cleaned accumulator 87
21/12/17 14:04:03 INFO ContextCleaner: Cleaned accumulator 54
21/12/17 14:04:03 INFO ContextCleaner: Cleaned accumulator 74
21/12/17 14:04:03 INFO ContextCleaner: Cleaned accumulator 85
21/12/17 14:04:03 INFO ContextCleaner: Cleaned accumulator 65
21/12/17 14:04:03 INFO ContextCleaner: Cleaned accumulator 68
21/12/17 14:04:03 INFO ContextCleaner: Cleaned accumulator 41
21/12/17 14:04:03 INFO ContextCleaner: Cleaned accumulator 83
21/12/17 14:04:03 INFO ContextCleaner: Cleaned accumulator 45
21/12/17 14:04:03 INFO ContextCleaner: Cleaned accumulator 52
21/12/17 14:04:03 INFO ContextCleaner: Cleaned accumulator 40
21/12/17 14:04:03 INFO ContextCleaner: Cleaned accumulator 72
21/12/17 14:04:03 INFO ContextCleaner: Cleaned accumulator 32
21/12/17 14:04:03 INFO ContextCleaner: Cleaned accumulator 31
21/12/17 14:04:03 INFO ContextCleaner: Cleaned accumulator 46
21/12/17 14:04:03 INFO BlockManagerInfo: Removed broadcast_1_piece0 on kubernetes.docker.internal:57009 in memory (size: 3.3 KB, free: 912.3 MB)
21/12/17 14:04:03 INFO ContextCleaner: Cleaned accumulator 64
21/12/17 14:04:03 INFO ContextCleaner: Cleaned accumulator 73
21/12/17 14:04:03 INFO ContextCleaner: Cleaned accumulator 67
21/12/17 14:04:03 INFO ContextCleaner: Cleaned accumulator 38
21/12/17 14:04:03 INFO ContextCleaner: Cleaned accumulator 63
21/12/17 14:04:03 INFO ContextCleaner: Cleaned accumulator 34
21/12/17 14:04:03 INFO ContextCleaner: Cleaned accumulator 42
21/12/17 14:04:03 INFO ContextCleaner: Cleaned accumulator 35
21/12/17 14:04:03 INFO ContextCleaner: Cleaned accumulator 86
21/12/17 14:04:03 INFO ContextCleaner: Cleaned accumulator 30
21/12/17 14:04:03 INFO ContextCleaner: Cleaned accumulator 59
21/12/17 14:04:03 INFO ContextCleaner: Cleaned accumulator 76
21/12/17 14:04:03 INFO BlockManagerInfo: Removed broadcast_2_piece0 on kubernetes.docker.internal:57009 in memory (size: 9.4 KB, free: 912.3 MB)
21/12/17 14:04:03 INFO ContextCleaner: Cleaned accumulator 44
21/12/17 14:04:03 INFO ContextCleaner: Cleaned accumulator 61
21/12/17 14:04:03 INFO ContextCleaner: Cleaned accumulator 66
21/12/17 14:04:03 INFO ContextCleaner: Cleaned accumulator 48
21/12/17 14:04:03 INFO ContextCleaner: Cleaned accumulator 62
21/12/17 14:04:03 INFO ContextCleaner: Cleaned accumulator 81
21/12/17 14:04:03 INFO ContextCleaner: Cleaned accumulator 50
21/12/17 14:04:03 INFO ContextCleaner: Cleaned accumulator 43
21/12/17 14:04:03 INFO ContextCleaner: Cleaned accumulator 47
21/12/17 14:04:03 INFO ContextCleaner: Cleaned accumulator 70
21/12/17 14:04:03 INFO ContextCleaner: Cleaned accumulator 75
21/12/17 14:04:03 INFO ContextCleaner: Cleaned accumulator 56
21/12/17 14:04:03 INFO ContextCleaner: Cleaned accumulator 60
21/12/17 14:04:03 INFO ContextCleaner: Cleaned accumulator 58
21/12/17 14:04:03 INFO ContextCleaner: Cleaned accumulator 82
21/12/17 14:04:03 INFO ContextCleaner: Cleaned accumulator 37
21/12/17 14:04:03 INFO ContextCleaner: Cleaned accumulator 79
21/12/17 14:04:03 INFO ContextCleaner: Cleaned accumulator 36
21/12/17 14:04:03 INFO ContextCleaner: Cleaned accumulator 53
21/12/17 14:04:03 INFO ContextCleaner: Cleaned accumulator 71
21/12/17 14:04:03 INFO ContextCleaner: Cleaned accumulator 39
21/12/17 14:04:03 INFO ContextCleaner: Cleaned accumulator 69
21/12/17 14:04:03 INFO ContextCleaner: Cleaned accumulator 77
21/12/17 14:04:03 INFO ContextCleaner: Cleaned accumulator 51
21/12/17 14:04:03 INFO ContextCleaner: Cleaned accumulator 49
21/12/17 14:04:03 INFO ContextCleaner: Cleaned accumulator 9
21/12/17 14:04:03 INFO ContextCleaner: Cleaned accumulator 26
21/12/17 14:04:03 INFO ContextCleaner: Cleaned accumulator 10
21/12/17 14:04:03 INFO ContextCleaner: Cleaned accumulator 18
21/12/17 14:04:03 INFO ContextCleaner: Cleaned accumulator 1
21/12/17 14:04:03 INFO ContextCleaner: Cleaned accumulator 11
21/12/17 14:04:03 INFO ContextCleaner: Cleaned accumulator 13
21/12/17 14:04:03 INFO ContextCleaner: Cleaned accumulator 8
21/12/17 14:04:03 INFO ContextCleaner: Cleaned accumulator 19
21/12/17 14:04:03 INFO ContextCleaner: Cleaned accumulator 6
21/12/17 14:04:03 INFO ContextCleaner: Cleaned accumulator 22
21/12/17 14:04:03 INFO ContextCleaner: Cleaned accumulator 15
21/12/17 14:04:03 INFO ContextCleaner: Cleaned accumulator 21
21/12/17 14:04:03 INFO ContextCleaner: Cleaned accumulator 12
21/12/17 14:04:03 INFO ContextCleaner: Cleaned accumulator 3
21/12/17 14:04:03 INFO ContextCleaner: Cleaned accumulator 23
21/12/17 14:04:03 INFO ContextCleaner: Cleaned accumulator 25
21/12/17 14:04:03 INFO ContextCleaner: Cleaned accumulator 16
21/12/17 14:04:03 INFO ContextCleaner: Cleaned accumulator 14
21/12/17 14:04:03 INFO ContextCleaner: Cleaned accumulator 4
21/12/17 14:04:03 INFO ContextCleaner: Cleaned accumulator 7
21/12/17 14:04:03 INFO ContextCleaner: Cleaned accumulator 2
21/12/17 14:04:03 INFO ContextCleaner: Cleaned accumulator 20
21/12/17 14:04:03 INFO ContextCleaner: Cleaned accumulator 17
21/12/17 14:04:03 INFO ContextCleaner: Cleaned accumulator 5
21/12/17 14:04:03 INFO ContextCleaner: Cleaned accumulator 27
21/12/17 14:04:03 INFO BlockManagerInfo: Removed broadcast_0_piece0 on kubernetes.docker.internal:57009 in memory (size: 3.3 KB, free: 912.3 MB)
21/12/17 14:13:09 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
21/12/17 14:13:14 INFO SparkContext: Running Spark version 2.3.3
21/12/17 14:13:14 WARN SparkConf: In Spark 1.0 and later spark.local.dir will be overridden by the value set by the cluster manager (via SPARK_LOCAL_DIRS in mesos/standalone and LOCAL_DIRS in YARN).
21/12/17 14:13:14 INFO SparkContext: Submitted application: sparklyr
21/12/17 14:13:14 INFO SecurityManager: Changing view acls to: uhp07025
21/12/17 14:13:14 INFO SecurityManager: Changing modify acls to: uhp07025
21/12/17 14:13:14 INFO SecurityManager: Changing view acls groups to: 
21/12/17 14:13:14 INFO SecurityManager: Changing modify acls groups to: 
21/12/17 14:13:14 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(uhp07025); groups with view permissions: Set(); users  with modify permissions: Set(uhp07025); groups with modify permissions: Set()
21/12/17 14:13:14 INFO Utils: Successfully started service 'sparkDriver' on port 49654.
21/12/17 14:13:14 INFO SparkEnv: Registering MapOutputTracker
21/12/17 14:13:14 INFO SparkEnv: Registering BlockManagerMaster
21/12/17 14:13:14 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
21/12/17 14:13:14 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
21/12/17 14:13:14 INFO DiskBlockManager: Created local directory at C:\Users\uhp07025\AppData\Local\spark\spark-2.3.3-bin-hadoop2.7\tmp\local\blockmgr-1843b951-93c3-4373-a338-dc7935f257a9
21/12/17 14:13:14 INFO MemoryStore: MemoryStore started with capacity 912.3 MB
21/12/17 14:13:14 INFO SparkEnv: Registering OutputCommitCoordinator
21/12/17 14:13:14 WARN Utils: The configured local directories are not expected to be URIs; however, got suspicious values [C:/Users/uhp07025/AppData/Local/spark/spark-2.3.3-bin-hadoop2.7/tmp/local]. Please check your configured local directories.
21/12/17 14:13:15 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
21/12/17 14:13:15 INFO Utils: Successfully started service 'SparkUI' on port 4041.
21/12/17 14:13:15 INFO SparkUI: Bound SparkUI to 127.0.0.1, and started at http://kubernetes.docker.internal:4041
21/12/17 14:13:15 INFO SparkContext: Added JAR file:/C:/Users/uhp07025/Documents/R/win-library/4.1/sparklyr/java/sparklyr-2.3-2.11.jar at spark://kubernetes.docker.internal:49654/jars/sparklyr-2.3-2.11.jar with timestamp 1639746795631
21/12/17 14:13:15 INFO Executor: Starting executor ID driver on host localhost
21/12/17 14:13:15 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 49803.
21/12/17 14:13:15 INFO NettyBlockTransferService: Server created on kubernetes.docker.internal:49803
21/12/17 14:13:15 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
21/12/17 14:13:15 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, kubernetes.docker.internal, 49803, None)
21/12/17 14:13:15 INFO BlockManagerMasterEndpoint: Registering block manager kubernetes.docker.internal:49803 with 912.3 MB RAM, BlockManagerId(driver, kubernetes.docker.internal, 49803, None)
21/12/17 14:13:15 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, kubernetes.docker.internal, 49803, None)
21/12/17 14:13:15 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, kubernetes.docker.internal, 49803, None)
21/12/17 14:13:16 INFO SharedState: loading hive config file: file:/C:/Users/uhp07025/AppData/Local/spark/spark-2.3.3-bin-hadoop2.7/conf/hive-site.xml
21/12/17 14:13:16 INFO SharedState: Setting hive.metastore.warehouse.dir ('C:/Users/uhp07025/AppData/Local/spark/spark-2.3.3-bin-hadoop2.7/tmp/hive') to the value of spark.sql.warehouse.dir ('C:/Users/uhp07025/AppData/Local/spark/spark-2.3.3-bin-hadoop2.7/tmp/hive').
21/12/17 14:13:16 INFO SharedState: Warehouse path is 'C:/Users/uhp07025/AppData/Local/spark/spark-2.3.3-bin-hadoop2.7/tmp/hive'.
21/12/17 14:13:17 INFO StateStoreCoordinatorRef: Registered StateStoreCoordinator endpoint
21/12/17 14:13:21 INFO HiveUtils: Initializing HiveMetastoreConnection version 1.2.1 using Spark classes.
21/12/17 14:13:22 INFO HiveMetaStore: 0: Opening raw store with implemenation class:org.apache.hadoop.hive.metastore.ObjectStore
21/12/17 14:13:22 INFO ObjectStore: ObjectStore, initialize called
21/12/17 14:13:22 INFO Persistence: Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
21/12/17 14:13:22 INFO Persistence: Property datanucleus.cache.level2 unknown - will be ignored
21/12/17 14:13:29 INFO ObjectStore: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
21/12/17 14:13:31 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
21/12/17 14:13:31 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
21/12/17 14:13:33 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
21/12/17 14:13:33 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
21/12/17 14:13:33 INFO MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
21/12/17 14:13:33 INFO ObjectStore: Initialized ObjectStore
21/12/17 14:13:33 WARN ObjectStore: Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 1.2.0
21/12/17 14:13:33 WARN ObjectStore: Failed to get database default, returning NoSuchObjectException
21/12/17 14:13:33 INFO HiveMetaStore: Added admin role in metastore
21/12/17 14:13:33 INFO HiveMetaStore: Added public role in metastore
21/12/17 14:13:34 INFO HiveMetaStore: No user is added in admin role, since config is empty
21/12/17 14:13:34 INFO HiveMetaStore: 0: get_all_databases
21/12/17 14:13:34 INFO audit: ugi=uhp07025	ip=unknown-ip-addr	cmd=get_all_databases	
21/12/17 14:13:34 INFO HiveMetaStore: 0: get_functions: db=default pat=*
21/12/17 14:13:34 INFO audit: ugi=uhp07025	ip=unknown-ip-addr	cmd=get_functions: db=default pat=*	
21/12/17 14:13:34 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MResourceUri" is tagged as "embedded-only" so does not have its own datastore table.
21/12/17 14:13:34 INFO SessionState: Created local directory: C:/Users/uhp07025/AppData/Local/Temp/e543a97d-0811-41a2-8b60-6c7a7d3182a4_resources
21/12/17 14:13:34 INFO SessionState: Created HDFS directory: C:/Users/uhp07025/AppData/Local/spark/spark-2.3.3-bin-hadoop2.7/tmp/hive/uhp07025/e543a97d-0811-41a2-8b60-6c7a7d3182a4
21/12/17 14:13:34 INFO SessionState: Created local directory: C:/Users/uhp07025/AppData/Local/spark/spark-2.3.3-bin-hadoop2.7/tmp/hive/e543a97d-0811-41a2-8b60-6c7a7d3182a4
21/12/17 14:13:35 INFO SessionState: Created HDFS directory: C:/Users/uhp07025/AppData/Local/spark/spark-2.3.3-bin-hadoop2.7/tmp/hive/uhp07025/e543a97d-0811-41a2-8b60-6c7a7d3182a4/_tmp_space.db
21/12/17 14:13:35 INFO HiveClientImpl: Warehouse location for Hive client (version 1.2.2) is C:/Users/uhp07025/AppData/Local/spark/spark-2.3.3-bin-hadoop2.7/tmp/hive
21/12/17 14:13:35 INFO HiveMetaStore: 0: get_database: default
21/12/17 14:13:35 INFO audit: ugi=uhp07025	ip=unknown-ip-addr	cmd=get_database: default	
21/12/17 14:13:35 INFO HiveMetaStore: 0: get_database: global_temp
21/12/17 14:13:35 INFO audit: ugi=uhp07025	ip=unknown-ip-addr	cmd=get_database: global_temp	
21/12/17 14:13:35 WARN ObjectStore: Failed to get database global_temp, returning NoSuchObjectException
21/12/17 14:13:36 INFO HiveMetaStore: 0: get_database: default
21/12/17 14:13:36 INFO audit: ugi=uhp07025	ip=unknown-ip-addr	cmd=get_database: default	
21/12/17 14:13:36 INFO HiveMetaStore: 0: get_database: default
21/12/17 14:13:36 INFO audit: ugi=uhp07025	ip=unknown-ip-addr	cmd=get_database: default	
21/12/17 14:13:36 INFO HiveMetaStore: 0: get_tables: db=default pat=*
21/12/17 14:13:36 INFO audit: ugi=uhp07025	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
21/12/17 14:13:37 INFO CodeGenerator: Code generated in 506.2595 ms
21/12/17 14:13:39 INFO CodeGenerator: Code generated in 33.7291 ms
21/12/17 14:13:39 INFO CodeGenerator: Code generated in 28.7326 ms
21/12/17 14:13:39 INFO SparkContext: Starting job: collect at utils.scala:24
21/12/17 14:13:39 INFO DAGScheduler: Got job 0 (collect at utils.scala:24) with 1 output partitions
21/12/17 14:13:39 INFO DAGScheduler: Final stage: ResultStage 0 (collect at utils.scala:24)
21/12/17 14:13:39 INFO DAGScheduler: Parents of final stage: List()
21/12/17 14:13:39 INFO DAGScheduler: Missing parents: List()
21/12/17 14:13:39 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[4] at collect at utils.scala:24), which has no missing parents
21/12/17 14:13:39 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.8 KB, free 912.3 MB)
21/12/17 14:13:39 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 3.3 KB, free 912.3 MB)
21/12/17 14:13:39 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on kubernetes.docker.internal:49803 (size: 3.3 KB, free: 912.3 MB)
21/12/17 14:13:39 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1039
21/12/17 14:13:39 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[4] at collect at utils.scala:24) (first 15 tasks are for partitions Vector(0))
21/12/17 14:13:39 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks
21/12/17 14:13:40 INFO ContextCleaner: Cleaned accumulator 0
21/12/17 14:13:40 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 8067 bytes)
21/12/17 14:13:40 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
21/12/17 14:13:40 INFO Executor: Fetching spark://kubernetes.docker.internal:49654/jars/sparklyr-2.3-2.11.jar with timestamp 1639746795631
21/12/17 14:13:40 INFO TransportClientFactory: Successfully created connection to kubernetes.docker.internal/127.0.0.1:49654 after 42 ms (0 ms spent in bootstraps)
21/12/17 14:13:40 INFO Utils: Fetching spark://kubernetes.docker.internal:49654/jars/sparklyr-2.3-2.11.jar to C:\Users\uhp07025\AppData\Local\spark\spark-2.3.3-bin-hadoop2.7\tmp\local\spark-6739d3fd-a4c8-4249-9dbe-98977f8b38e7\userFiles-867aecb8-7044-4201-925e-9e3135574850\fetchFileTemp3051339632069400125.tmp
21/12/17 14:13:40 INFO Executor: Adding file:/C:/Users/uhp07025/AppData/Local/spark/spark-2.3.3-bin-hadoop2.7/tmp/local/spark-6739d3fd-a4c8-4249-9dbe-98977f8b38e7/userFiles-867aecb8-7044-4201-925e-9e3135574850/sparklyr-2.3-2.11.jar to class loader
21/12/17 14:13:40 INFO CodeGenerator: Code generated in 13.7056 ms
21/12/17 14:13:40 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1329 bytes result sent to driver
21/12/17 14:13:40 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 695 ms on localhost (executor driver) (1/1)
21/12/17 14:13:40 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
21/12/17 14:13:40 INFO DAGScheduler: ResultStage 0 (collect at utils.scala:24) finished in 1.326 s
21/12/17 14:13:40 INFO DAGScheduler: Job 0 finished: collect at utils.scala:24, took 1.442547 s
21/12/17 14:13:41 INFO SparkContext: Starting job: collect at utils.scala:24
21/12/17 14:13:41 INFO DAGScheduler: Got job 1 (collect at utils.scala:24) with 1 output partitions
21/12/17 14:13:41 INFO DAGScheduler: Final stage: ResultStage 1 (collect at utils.scala:24)
21/12/17 14:13:41 INFO DAGScheduler: Parents of final stage: List()
21/12/17 14:13:41 INFO DAGScheduler: Missing parents: List()
21/12/17 14:13:41 INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[9] at collect at utils.scala:24), which has no missing parents
21/12/17 14:13:41 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 6.8 KB, free 912.3 MB)
21/12/17 14:13:41 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.3 KB, free 912.3 MB)
21/12/17 14:13:41 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on kubernetes.docker.internal:49803 (size: 3.3 KB, free: 912.3 MB)
21/12/17 14:13:41 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1039
21/12/17 14:13:41 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[9] at collect at utils.scala:24) (first 15 tasks are for partitions Vector(0))
21/12/17 14:13:41 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks
21/12/17 14:13:41 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1, localhost, executor driver, partition 0, PROCESS_LOCAL, 8067 bytes)
21/12/17 14:13:41 INFO Executor: Running task 0.0 in stage 1.0 (TID 1)
21/12/17 14:13:41 INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 1200 bytes result sent to driver
21/12/17 14:13:41 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 9 ms on localhost (executor driver) (1/1)
21/12/17 14:13:41 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
21/12/17 14:13:41 INFO DAGScheduler: ResultStage 1 (collect at utils.scala:24) finished in 0.022 s
21/12/17 14:13:41 INFO DAGScheduler: Job 1 finished: collect at utils.scala:24, took 0.028510 s
21/12/17 14:13:41 INFO CodeGenerator: Code generated in 32.6051 ms
21/12/17 14:13:41 INFO CodeGenerator: Code generated in 58.7524 ms
21/12/17 14:13:41 INFO SparkContext: Starting job: collect at utils.scala:24
21/12/17 14:13:41 INFO DAGScheduler: Got job 2 (collect at utils.scala:24) with 1 output partitions
21/12/17 14:13:41 INFO DAGScheduler: Final stage: ResultStage 2 (collect at utils.scala:24)
21/12/17 14:13:41 INFO DAGScheduler: Parents of final stage: List()
21/12/17 14:13:41 INFO DAGScheduler: Missing parents: List()
21/12/17 14:13:41 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[14] at collect at utils.scala:24), which has no missing parents
21/12/17 14:13:41 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 26.0 KB, free 912.3 MB)
21/12/17 14:13:41 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 9.4 KB, free 912.2 MB)
21/12/17 14:13:41 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on kubernetes.docker.internal:49803 (size: 9.4 KB, free: 912.3 MB)
21/12/17 14:13:41 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1039
21/12/17 14:13:41 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[14] at collect at utils.scala:24) (first 15 tasks are for partitions Vector(0))
21/12/17 14:13:41 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks
21/12/17 14:13:41 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2, localhost, executor driver, partition 0, PROCESS_LOCAL, 11614 bytes)
21/12/17 14:13:41 INFO Executor: Running task 0.0 in stage 2.0 (TID 2)
21/12/17 14:13:42 INFO CodeGenerator: Code generated in 47.9002 ms
21/12/17 14:13:42 INFO MemoryStore: Block rdd_6_0 stored as values in memory (estimated size 4.2 KB, free 912.2 MB)
21/12/17 14:13:42 INFO BlockManagerInfo: Added rdd_6_0 in memory on kubernetes.docker.internal:49803 (size: 4.2 KB, free: 912.3 MB)
21/12/17 14:13:42 INFO CodeGenerator: Code generated in 12.1956 ms
21/12/17 14:13:42 INFO Executor: 1 block locks were not released by TID = 2:
[rdd_6_0]
21/12/17 14:13:42 INFO Executor: Finished task 0.0 in stage 2.0 (TID 2). 1770 bytes result sent to driver
21/12/17 14:13:42 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 314 ms on localhost (executor driver) (1/1)
21/12/17 14:13:42 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
21/12/17 14:13:42 INFO DAGScheduler: ResultStage 2 (collect at utils.scala:24) finished in 0.349 s
21/12/17 14:13:42 INFO DAGScheduler: Job 2 finished: collect at utils.scala:24, took 0.360924 s
21/12/17 14:13:48 INFO SparkContext: Invoking stop() from shutdown hook
21/12/17 14:13:48 INFO SparkUI: Stopped Spark web UI at http://kubernetes.docker.internal:4041
21/12/17 14:13:48 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
21/12/17 14:13:48 INFO MemoryStore: MemoryStore cleared
21/12/17 14:13:48 INFO BlockManager: BlockManager stopped
21/12/17 14:13:48 INFO BlockManagerMaster: BlockManagerMaster stopped
21/12/17 14:13:48 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
21/12/17 14:13:48 WARN SparkEnv: Exception while deleting Spark temp dir: C:\Users\uhp07025\AppData\Local\spark\spark-2.3.3-bin-hadoop2.7\tmp\local\spark-6739d3fd-a4c8-4249-9dbe-98977f8b38e7\userFiles-867aecb8-7044-4201-925e-9e3135574850
java.io.IOException: Failed to delete: C:\Users\uhp07025\AppData\Local\spark\spark-2.3.3-bin-hadoop2.7\tmp\local\spark-6739d3fd-a4c8-4249-9dbe-98977f8b38e7\userFiles-867aecb8-7044-4201-925e-9e3135574850
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1074)
	at org.apache.spark.SparkEnv.stop(SparkEnv.scala:103)
	at org.apache.spark.SparkContext$$anonfun$stop$11.apply$mcV$sp(SparkContext.scala:1947)
	at org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1361)
	at org.apache.spark.SparkContext.stop(SparkContext.scala:1946)
	at org.apache.spark.SparkContext$$anonfun$2.apply$mcV$sp(SparkContext.scala:573)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:216)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1992)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at scala.util.Try$.apply(Try.scala:192)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at org.apache.hadoop.util.ShutdownHookManager$1.run(ShutdownHookManager.java:54)
21/12/17 14:13:48 INFO SparkContext: Successfully stopped SparkContext
21/12/17 14:13:48 INFO ShutdownHookManager: Shutdown hook called
21/12/17 14:13:48 INFO ShutdownHookManager: Deleting directory C:\Users\uhp07025\AppData\Local\Temp\spark-8ebedd12-618c-407d-96ef-4216a865bbf4
21/12/17 14:13:48 INFO ShutdownHookManager: Deleting directory C:\Users\uhp07025\AppData\Local\spark\spark-2.3.3-bin-hadoop2.7\tmp\local\spark-6739d3fd-a4c8-4249-9dbe-98977f8b38e7\userFiles-867aecb8-7044-4201-925e-9e3135574850
21/12/17 14:13:48 ERROR ShutdownHookManager: Exception while deleting Spark temp dir: C:\Users\uhp07025\AppData\Local\spark\spark-2.3.3-bin-hadoop2.7\tmp\local\spark-6739d3fd-a4c8-4249-9dbe-98977f8b38e7\userFiles-867aecb8-7044-4201-925e-9e3135574850
java.io.IOException: Failed to delete: C:\Users\uhp07025\AppData\Local\spark\spark-2.3.3-bin-hadoop2.7\tmp\local\spark-6739d3fd-a4c8-4249-9dbe-98977f8b38e7\userFiles-867aecb8-7044-4201-925e-9e3135574850
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1074)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1$$anonfun$apply$mcV$sp$3.apply(ShutdownHookManager.scala:65)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1$$anonfun$apply$mcV$sp$3.apply(ShutdownHookManager.scala:62)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1.apply$mcV$sp(ShutdownHookManager.scala:62)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:216)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1992)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at scala.util.Try$.apply(Try.scala:192)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at org.apache.hadoop.util.ShutdownHookManager$1.run(ShutdownHookManager.java:54)
21/12/17 14:13:48 INFO ShutdownHookManager: Deleting directory C:\Users\uhp07025\AppData\Local\spark\spark-2.3.3-bin-hadoop2.7\tmp\local\spark-6739d3fd-a4c8-4249-9dbe-98977f8b38e7
21/12/17 14:13:48 ERROR ShutdownHookManager: Exception while deleting Spark temp dir: C:\Users\uhp07025\AppData\Local\spark\spark-2.3.3-bin-hadoop2.7\tmp\local\spark-6739d3fd-a4c8-4249-9dbe-98977f8b38e7
java.io.IOException: Failed to delete: C:\Users\uhp07025\AppData\Local\spark\spark-2.3.3-bin-hadoop2.7\tmp\local\spark-6739d3fd-a4c8-4249-9dbe-98977f8b38e7
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1074)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1$$anonfun$apply$mcV$sp$3.apply(ShutdownHookManager.scala:65)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1$$anonfun$apply$mcV$sp$3.apply(ShutdownHookManager.scala:62)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1.apply$mcV$sp(ShutdownHookManager.scala:62)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:216)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1992)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at scala.util.Try$.apply(Try.scala:192)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at org.apache.hadoop.util.ShutdownHookManager$1.run(ShutdownHookManager.java:54)
21/12/17 14:16:38 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
21/12/17 14:16:41 INFO SparkContext: Running Spark version 2.3.3
21/12/17 14:16:41 WARN SparkConf: In Spark 1.0 and later spark.local.dir will be overridden by the value set by the cluster manager (via SPARK_LOCAL_DIRS in mesos/standalone and LOCAL_DIRS in YARN).
21/12/17 14:16:41 INFO SparkContext: Submitted application: sparklyr
21/12/17 14:16:41 INFO SecurityManager: Changing view acls to: uhp07025
21/12/17 14:16:41 INFO SecurityManager: Changing modify acls to: uhp07025
21/12/17 14:16:41 INFO SecurityManager: Changing view acls groups to: 
21/12/17 14:16:41 INFO SecurityManager: Changing modify acls groups to: 
21/12/17 14:16:41 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(uhp07025); groups with view permissions: Set(); users  with modify permissions: Set(uhp07025); groups with modify permissions: Set()
21/12/17 14:16:41 INFO Utils: Successfully started service 'sparkDriver' on port 50202.
21/12/17 14:16:41 INFO SparkEnv: Registering MapOutputTracker
21/12/17 14:16:41 INFO SparkEnv: Registering BlockManagerMaster
21/12/17 14:16:41 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
21/12/17 14:16:41 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
21/12/17 14:16:41 INFO DiskBlockManager: Created local directory at C:\Users\uhp07025\AppData\Local\spark\spark-2.3.3-bin-hadoop2.7\tmp\local\blockmgr-49b7b011-68dd-4425-a271-2575b6226967
21/12/17 14:16:42 INFO MemoryStore: MemoryStore started with capacity 912.3 MB
21/12/17 14:16:42 INFO SparkEnv: Registering OutputCommitCoordinator
21/12/17 14:16:42 WARN Utils: The configured local directories are not expected to be URIs; however, got suspicious values [C:/Users/uhp07025/AppData/Local/spark/spark-2.3.3-bin-hadoop2.7/tmp/local]. Please check your configured local directories.
21/12/17 14:16:42 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
21/12/17 14:16:42 INFO Utils: Successfully started service 'SparkUI' on port 4041.
21/12/17 14:16:42 INFO SparkUI: Bound SparkUI to 127.0.0.1, and started at http://kubernetes.docker.internal:4041
21/12/17 14:16:42 INFO SparkContext: Added JAR file:/C:/Users/uhp07025/Documents/R/win-library/4.1/sparklyr/java/sparklyr-2.3-2.11.jar at spark://kubernetes.docker.internal:50202/jars/sparklyr-2.3-2.11.jar with timestamp 1639747002514
21/12/17 14:16:42 INFO Executor: Starting executor ID driver on host localhost
21/12/17 14:16:42 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 50247.
21/12/17 14:16:42 INFO NettyBlockTransferService: Server created on kubernetes.docker.internal:50247
21/12/17 14:16:42 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
21/12/17 14:16:42 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, kubernetes.docker.internal, 50247, None)
21/12/17 14:16:42 INFO BlockManagerMasterEndpoint: Registering block manager kubernetes.docker.internal:50247 with 912.3 MB RAM, BlockManagerId(driver, kubernetes.docker.internal, 50247, None)
21/12/17 14:16:42 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, kubernetes.docker.internal, 50247, None)
21/12/17 14:16:42 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, kubernetes.docker.internal, 50247, None)
21/12/17 14:16:43 INFO SharedState: loading hive config file: file:/C:/Users/uhp07025/AppData/Local/spark/spark-2.3.3-bin-hadoop2.7/conf/hive-site.xml
21/12/17 14:16:43 INFO SharedState: Setting hive.metastore.warehouse.dir ('C:/Users/uhp07025/AppData/Local/spark/spark-2.3.3-bin-hadoop2.7/tmp/hive') to the value of spark.sql.warehouse.dir ('C:/Users/uhp07025/AppData/Local/spark/spark-2.3.3-bin-hadoop2.7/tmp/hive').
21/12/17 14:16:43 INFO SharedState: Warehouse path is 'C:/Users/uhp07025/AppData/Local/spark/spark-2.3.3-bin-hadoop2.7/tmp/hive'.
21/12/17 14:16:43 INFO StateStoreCoordinatorRef: Registered StateStoreCoordinator endpoint
21/12/17 14:16:46 INFO HiveUtils: Initializing HiveMetastoreConnection version 1.2.1 using Spark classes.
21/12/17 14:16:47 INFO HiveMetaStore: 0: Opening raw store with implemenation class:org.apache.hadoop.hive.metastore.ObjectStore
21/12/17 14:16:47 INFO ObjectStore: ObjectStore, initialize called
21/12/17 14:16:47 INFO Persistence: Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
21/12/17 14:16:47 INFO Persistence: Property datanucleus.cache.level2 unknown - will be ignored
21/12/17 14:16:49 INFO ObjectStore: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
21/12/17 14:16:50 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
21/12/17 14:16:50 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
21/12/17 14:16:51 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
21/12/17 14:16:51 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
21/12/17 14:16:52 INFO MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
21/12/17 14:16:52 INFO ObjectStore: Initialized ObjectStore
21/12/17 14:16:52 WARN ObjectStore: Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 1.2.0
21/12/17 14:16:52 WARN ObjectStore: Failed to get database default, returning NoSuchObjectException
21/12/17 14:16:52 INFO HiveMetaStore: Added admin role in metastore
21/12/17 14:16:52 INFO HiveMetaStore: Added public role in metastore
21/12/17 14:16:52 INFO HiveMetaStore: No user is added in admin role, since config is empty
21/12/17 14:16:52 INFO HiveMetaStore: 0: get_all_databases
21/12/17 14:16:52 INFO audit: ugi=uhp07025	ip=unknown-ip-addr	cmd=get_all_databases	
21/12/17 14:16:52 INFO HiveMetaStore: 0: get_functions: db=default pat=*
21/12/17 14:16:52 INFO audit: ugi=uhp07025	ip=unknown-ip-addr	cmd=get_functions: db=default pat=*	
21/12/17 14:16:52 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MResourceUri" is tagged as "embedded-only" so does not have its own datastore table.
21/12/17 14:16:52 INFO SessionState: Created local directory: C:/Users/uhp07025/AppData/Local/Temp/8eb2948f-be29-4cbf-8f3a-69c3237e9dbb_resources
21/12/17 14:16:53 INFO SessionState: Created HDFS directory: C:/Users/uhp07025/AppData/Local/spark/spark-2.3.3-bin-hadoop2.7/tmp/hive/uhp07025/8eb2948f-be29-4cbf-8f3a-69c3237e9dbb
21/12/17 14:16:53 INFO SessionState: Created local directory: C:/Users/uhp07025/AppData/Local/spark/spark-2.3.3-bin-hadoop2.7/tmp/hive/8eb2948f-be29-4cbf-8f3a-69c3237e9dbb
21/12/17 14:16:53 INFO SessionState: Created HDFS directory: C:/Users/uhp07025/AppData/Local/spark/spark-2.3.3-bin-hadoop2.7/tmp/hive/uhp07025/8eb2948f-be29-4cbf-8f3a-69c3237e9dbb/_tmp_space.db
21/12/17 14:16:53 INFO HiveClientImpl: Warehouse location for Hive client (version 1.2.2) is C:/Users/uhp07025/AppData/Local/spark/spark-2.3.3-bin-hadoop2.7/tmp/hive
21/12/17 14:16:53 INFO HiveMetaStore: 0: get_database: default
21/12/17 14:16:53 INFO audit: ugi=uhp07025	ip=unknown-ip-addr	cmd=get_database: default	
21/12/17 14:16:53 INFO HiveMetaStore: 0: get_database: global_temp
21/12/17 14:16:53 INFO audit: ugi=uhp07025	ip=unknown-ip-addr	cmd=get_database: global_temp	
21/12/17 14:16:53 WARN ObjectStore: Failed to get database global_temp, returning NoSuchObjectException
21/12/17 14:16:54 INFO HiveMetaStore: 0: get_database: default
21/12/17 14:16:54 INFO audit: ugi=uhp07025	ip=unknown-ip-addr	cmd=get_database: default	
21/12/17 14:16:54 INFO HiveMetaStore: 0: get_database: default
21/12/17 14:16:54 INFO audit: ugi=uhp07025	ip=unknown-ip-addr	cmd=get_database: default	
21/12/17 14:16:54 INFO HiveMetaStore: 0: get_tables: db=default pat=*
21/12/17 14:16:54 INFO audit: ugi=uhp07025	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
21/12/17 14:16:54 INFO CodeGenerator: Code generated in 397.4581 ms
21/12/17 14:16:56 INFO CodeGenerator: Code generated in 18.9075 ms
21/12/17 14:16:56 INFO CodeGenerator: Code generated in 17.1632 ms
21/12/17 14:16:56 INFO SparkContext: Starting job: collect at utils.scala:24
21/12/17 14:16:56 INFO DAGScheduler: Got job 0 (collect at utils.scala:24) with 1 output partitions
21/12/17 14:16:56 INFO DAGScheduler: Final stage: ResultStage 0 (collect at utils.scala:24)
21/12/17 14:16:56 INFO DAGScheduler: Parents of final stage: List()
21/12/17 14:16:56 INFO DAGScheduler: Missing parents: List()
21/12/17 14:16:56 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[4] at collect at utils.scala:24), which has no missing parents
21/12/17 14:16:56 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.8 KB, free 912.3 MB)
21/12/17 14:16:56 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 3.3 KB, free 912.3 MB)
21/12/17 14:16:56 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on kubernetes.docker.internal:50247 (size: 3.3 KB, free: 912.3 MB)
21/12/17 14:16:56 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1039
21/12/17 14:16:56 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[4] at collect at utils.scala:24) (first 15 tasks are for partitions Vector(0))
21/12/17 14:16:56 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks
21/12/17 14:16:56 INFO ContextCleaner: Cleaned accumulator 0
21/12/17 14:16:56 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 8067 bytes)
21/12/17 14:16:56 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
21/12/17 14:16:57 INFO Executor: Fetching spark://kubernetes.docker.internal:50202/jars/sparklyr-2.3-2.11.jar with timestamp 1639747002514
21/12/17 14:16:57 INFO TransportClientFactory: Successfully created connection to kubernetes.docker.internal/127.0.0.1:50202 after 37 ms (0 ms spent in bootstraps)
21/12/17 14:16:57 INFO Utils: Fetching spark://kubernetes.docker.internal:50202/jars/sparklyr-2.3-2.11.jar to C:\Users\uhp07025\AppData\Local\spark\spark-2.3.3-bin-hadoop2.7\tmp\local\spark-0c81adf7-10d9-403c-90b6-eddb8d001931\userFiles-21aacfb3-4d32-4cf1-bd8b-8436cba734bb\fetchFileTemp8120765910617914445.tmp
21/12/17 14:16:57 INFO Executor: Adding file:/C:/Users/uhp07025/AppData/Local/spark/spark-2.3.3-bin-hadoop2.7/tmp/local/spark-0c81adf7-10d9-403c-90b6-eddb8d001931/userFiles-21aacfb3-4d32-4cf1-bd8b-8436cba734bb/sparklyr-2.3-2.11.jar to class loader
21/12/17 14:16:57 INFO CodeGenerator: Code generated in 15.289 ms
21/12/17 14:16:57 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1329 bytes result sent to driver
21/12/17 14:16:57 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 603 ms on localhost (executor driver) (1/1)
21/12/17 14:16:57 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
21/12/17 14:16:57 INFO DAGScheduler: ResultStage 0 (collect at utils.scala:24) finished in 0.986 s
21/12/17 14:16:57 INFO DAGScheduler: Job 0 finished: collect at utils.scala:24, took 1.051341 s
21/12/17 14:16:57 INFO SparkContext: Starting job: collect at utils.scala:24
21/12/17 14:16:57 INFO DAGScheduler: Got job 1 (collect at utils.scala:24) with 1 output partitions
21/12/17 14:16:57 INFO DAGScheduler: Final stage: ResultStage 1 (collect at utils.scala:24)
21/12/17 14:16:57 INFO DAGScheduler: Parents of final stage: List()
21/12/17 14:16:57 INFO DAGScheduler: Missing parents: List()
21/12/17 14:16:57 INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[9] at collect at utils.scala:24), which has no missing parents
21/12/17 14:16:57 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 6.8 KB, free 912.3 MB)
21/12/17 14:16:57 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.3 KB, free 912.3 MB)
21/12/17 14:16:57 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on kubernetes.docker.internal:50247 (size: 3.3 KB, free: 912.3 MB)
21/12/17 14:16:57 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1039
21/12/17 14:16:57 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[9] at collect at utils.scala:24) (first 15 tasks are for partitions Vector(0))
21/12/17 14:16:57 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks
21/12/17 14:16:57 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1, localhost, executor driver, partition 0, PROCESS_LOCAL, 8067 bytes)
21/12/17 14:16:57 INFO Executor: Running task 0.0 in stage 1.0 (TID 1)
21/12/17 14:16:57 INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 1200 bytes result sent to driver
21/12/17 14:16:57 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 15 ms on localhost (executor driver) (1/1)
21/12/17 14:16:57 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
21/12/17 14:16:57 INFO DAGScheduler: ResultStage 1 (collect at utils.scala:24) finished in 0.027 s
21/12/17 14:16:57 INFO DAGScheduler: Job 1 finished: collect at utils.scala:24, took 0.036060 s
21/12/17 14:16:58 INFO CodeGenerator: Code generated in 22.6415 ms
21/12/17 14:16:58 INFO CodeGenerator: Code generated in 52.4168 ms
21/12/17 14:16:58 INFO SparkContext: Starting job: collect at utils.scala:24
21/12/17 14:16:58 INFO DAGScheduler: Got job 2 (collect at utils.scala:24) with 1 output partitions
21/12/17 14:16:58 INFO DAGScheduler: Final stage: ResultStage 2 (collect at utils.scala:24)
21/12/17 14:16:58 INFO DAGScheduler: Parents of final stage: List()
21/12/17 14:16:58 INFO DAGScheduler: Missing parents: List()
21/12/17 14:16:58 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[14] at collect at utils.scala:24), which has no missing parents
21/12/17 14:16:58 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 26.0 KB, free 912.3 MB)
21/12/17 14:16:58 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 9.4 KB, free 912.2 MB)
21/12/17 14:16:58 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on kubernetes.docker.internal:50247 (size: 9.4 KB, free: 912.3 MB)
21/12/17 14:16:58 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1039
21/12/17 14:16:58 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[14] at collect at utils.scala:24) (first 15 tasks are for partitions Vector(0))
21/12/17 14:16:58 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks
21/12/17 14:16:58 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2, localhost, executor driver, partition 0, PROCESS_LOCAL, 11614 bytes)
21/12/17 14:16:58 INFO Executor: Running task 0.0 in stage 2.0 (TID 2)
21/12/17 14:16:58 INFO CodeGenerator: Code generated in 25.8842 ms
21/12/17 14:16:58 INFO MemoryStore: Block rdd_6_0 stored as values in memory (estimated size 4.2 KB, free 912.2 MB)
21/12/17 14:16:58 INFO BlockManagerInfo: Added rdd_6_0 in memory on kubernetes.docker.internal:50247 (size: 4.2 KB, free: 912.3 MB)
21/12/17 14:16:58 INFO CodeGenerator: Code generated in 7.782 ms
21/12/17 14:16:58 INFO Executor: 1 block locks were not released by TID = 2:
[rdd_6_0]
21/12/17 14:16:58 INFO Executor: Finished task 0.0 in stage 2.0 (TID 2). 1770 bytes result sent to driver
21/12/17 14:16:58 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 183 ms on localhost (executor driver) (1/1)
21/12/17 14:16:58 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
21/12/17 14:16:58 INFO DAGScheduler: ResultStage 2 (collect at utils.scala:24) finished in 0.206 s
21/12/17 14:16:58 INFO DAGScheduler: Job 2 finished: collect at utils.scala:24, took 0.213124 s
21/12/17 14:17:04 INFO SparkContext: Invoking stop() from shutdown hook
21/12/17 14:17:04 INFO SparkUI: Stopped Spark web UI at http://kubernetes.docker.internal:4041
21/12/17 14:17:05 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
21/12/17 14:17:05 INFO MemoryStore: MemoryStore cleared
21/12/17 14:17:05 INFO BlockManager: BlockManager stopped
21/12/17 14:17:05 INFO BlockManagerMaster: BlockManagerMaster stopped
21/12/17 14:17:05 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
21/12/17 14:17:05 WARN SparkEnv: Exception while deleting Spark temp dir: C:\Users\uhp07025\AppData\Local\spark\spark-2.3.3-bin-hadoop2.7\tmp\local\spark-0c81adf7-10d9-403c-90b6-eddb8d001931\userFiles-21aacfb3-4d32-4cf1-bd8b-8436cba734bb
java.io.IOException: Failed to delete: C:\Users\uhp07025\AppData\Local\spark\spark-2.3.3-bin-hadoop2.7\tmp\local\spark-0c81adf7-10d9-403c-90b6-eddb8d001931\userFiles-21aacfb3-4d32-4cf1-bd8b-8436cba734bb
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1074)
	at org.apache.spark.SparkEnv.stop(SparkEnv.scala:103)
	at org.apache.spark.SparkContext$$anonfun$stop$11.apply$mcV$sp(SparkContext.scala:1947)
	at org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1361)
	at org.apache.spark.SparkContext.stop(SparkContext.scala:1946)
	at org.apache.spark.SparkContext$$anonfun$2.apply$mcV$sp(SparkContext.scala:573)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:216)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1992)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at scala.util.Try$.apply(Try.scala:192)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at org.apache.hadoop.util.ShutdownHookManager$1.run(ShutdownHookManager.java:54)
21/12/17 14:17:05 INFO SparkContext: Successfully stopped SparkContext
21/12/17 14:17:05 INFO ShutdownHookManager: Shutdown hook called
21/12/17 14:17:05 INFO ShutdownHookManager: Deleting directory C:\Users\uhp07025\AppData\Local\spark\spark-2.3.3-bin-hadoop2.7\tmp\local\spark-0c81adf7-10d9-403c-90b6-eddb8d001931\userFiles-21aacfb3-4d32-4cf1-bd8b-8436cba734bb
21/12/17 14:17:05 ERROR ShutdownHookManager: Exception while deleting Spark temp dir: C:\Users\uhp07025\AppData\Local\spark\spark-2.3.3-bin-hadoop2.7\tmp\local\spark-0c81adf7-10d9-403c-90b6-eddb8d001931\userFiles-21aacfb3-4d32-4cf1-bd8b-8436cba734bb
java.io.IOException: Failed to delete: C:\Users\uhp07025\AppData\Local\spark\spark-2.3.3-bin-hadoop2.7\tmp\local\spark-0c81adf7-10d9-403c-90b6-eddb8d001931\userFiles-21aacfb3-4d32-4cf1-bd8b-8436cba734bb
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1074)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1$$anonfun$apply$mcV$sp$3.apply(ShutdownHookManager.scala:65)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1$$anonfun$apply$mcV$sp$3.apply(ShutdownHookManager.scala:62)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1.apply$mcV$sp(ShutdownHookManager.scala:62)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:216)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1992)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at scala.util.Try$.apply(Try.scala:192)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at org.apache.hadoop.util.ShutdownHookManager$1.run(ShutdownHookManager.java:54)
21/12/17 14:17:05 INFO ShutdownHookManager: Deleting directory C:\Users\uhp07025\AppData\Local\Temp\spark-e62e7bc4-71de-4045-a730-9b86df4403fa
21/12/17 14:17:05 INFO ShutdownHookManager: Deleting directory C:\Users\uhp07025\AppData\Local\spark\spark-2.3.3-bin-hadoop2.7\tmp\local\spark-0c81adf7-10d9-403c-90b6-eddb8d001931
21/12/17 14:17:05 ERROR ShutdownHookManager: Exception while deleting Spark temp dir: C:\Users\uhp07025\AppData\Local\spark\spark-2.3.3-bin-hadoop2.7\tmp\local\spark-0c81adf7-10d9-403c-90b6-eddb8d001931
java.io.IOException: Failed to delete: C:\Users\uhp07025\AppData\Local\spark\spark-2.3.3-bin-hadoop2.7\tmp\local\spark-0c81adf7-10d9-403c-90b6-eddb8d001931
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1074)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1$$anonfun$apply$mcV$sp$3.apply(ShutdownHookManager.scala:65)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1$$anonfun$apply$mcV$sp$3.apply(ShutdownHookManager.scala:62)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1.apply$mcV$sp(ShutdownHookManager.scala:62)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:216)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1992)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at scala.util.Try$.apply(Try.scala:192)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at org.apache.hadoop.util.ShutdownHookManager$1.run(ShutdownHookManager.java:54)
21/12/17 14:21:34 INFO SparkContext: Invoking stop() from shutdown hook
21/12/17 14:21:34 INFO SparkUI: Stopped Spark web UI at http://kubernetes.docker.internal:4040
21/12/17 14:21:34 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
21/12/17 14:21:34 INFO MemoryStore: MemoryStore cleared
21/12/17 14:21:34 INFO BlockManager: BlockManager stopped
21/12/17 14:21:34 INFO BlockManagerMaster: BlockManagerMaster stopped
21/12/17 14:21:34 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
21/12/17 14:21:34 WARN SparkEnv: Exception while deleting Spark temp dir: C:\Users\uhp07025\AppData\Local\spark\spark-2.3.3-bin-hadoop2.7\tmp\local\spark-bf2229bb-13e6-4b5a-b618-2838928c1bbd\userFiles-aed64159-b439-448e-97f2-6908bed49a42
java.io.IOException: Failed to delete: C:\Users\uhp07025\AppData\Local\spark\spark-2.3.3-bin-hadoop2.7\tmp\local\spark-bf2229bb-13e6-4b5a-b618-2838928c1bbd\userFiles-aed64159-b439-448e-97f2-6908bed49a42
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1074)
	at org.apache.spark.SparkEnv.stop(SparkEnv.scala:103)
	at org.apache.spark.SparkContext$$anonfun$stop$11.apply$mcV$sp(SparkContext.scala:1947)
	at org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1361)
	at org.apache.spark.SparkContext.stop(SparkContext.scala:1946)
	at org.apache.spark.SparkContext$$anonfun$2.apply$mcV$sp(SparkContext.scala:573)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:216)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1992)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at scala.util.Try$.apply(Try.scala:192)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at org.apache.hadoop.util.ShutdownHookManager$1.run(ShutdownHookManager.java:54)
21/12/17 14:21:34 INFO SparkContext: Successfully stopped SparkContext
21/12/17 14:21:34 INFO ShutdownHookManager: Shutdown hook called
21/12/17 14:21:34 INFO ShutdownHookManager: Deleting directory C:\Users\uhp07025\AppData\Local\Temp\spark-9cd81287-c9e2-4ed9-941f-a32e5f3c2575
21/12/17 14:21:34 INFO ShutdownHookManager: Deleting directory C:\Users\uhp07025\AppData\Local\spark\spark-2.3.3-bin-hadoop2.7\tmp\local\spark-bf2229bb-13e6-4b5a-b618-2838928c1bbd
21/12/17 14:21:34 ERROR ShutdownHookManager: Exception while deleting Spark temp dir: C:\Users\uhp07025\AppData\Local\spark\spark-2.3.3-bin-hadoop2.7\tmp\local\spark-bf2229bb-13e6-4b5a-b618-2838928c1bbd
java.io.IOException: Failed to delete: C:\Users\uhp07025\AppData\Local\spark\spark-2.3.3-bin-hadoop2.7\tmp\local\spark-bf2229bb-13e6-4b5a-b618-2838928c1bbd
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1074)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1$$anonfun$apply$mcV$sp$3.apply(ShutdownHookManager.scala:65)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1$$anonfun$apply$mcV$sp$3.apply(ShutdownHookManager.scala:62)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1.apply$mcV$sp(ShutdownHookManager.scala:62)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:216)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1992)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at scala.util.Try$.apply(Try.scala:192)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at org.apache.hadoop.util.ShutdownHookManager$1.run(ShutdownHookManager.java:54)
21/12/17 14:21:34 INFO ShutdownHookManager: Deleting directory C:\Users\uhp07025\AppData\Local\spark\spark-2.3.3-bin-hadoop2.7\tmp\local\spark-bf2229bb-13e6-4b5a-b618-2838928c1bbd\userFiles-aed64159-b439-448e-97f2-6908bed49a42
21/12/17 14:21:34 ERROR ShutdownHookManager: Exception while deleting Spark temp dir: C:\Users\uhp07025\AppData\Local\spark\spark-2.3.3-bin-hadoop2.7\tmp\local\spark-bf2229bb-13e6-4b5a-b618-2838928c1bbd\userFiles-aed64159-b439-448e-97f2-6908bed49a42
java.io.IOException: Failed to delete: C:\Users\uhp07025\AppData\Local\spark\spark-2.3.3-bin-hadoop2.7\tmp\local\spark-bf2229bb-13e6-4b5a-b618-2838928c1bbd\userFiles-aed64159-b439-448e-97f2-6908bed49a42
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1074)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1$$anonfun$apply$mcV$sp$3.apply(ShutdownHookManager.scala:65)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1$$anonfun$apply$mcV$sp$3.apply(ShutdownHookManager.scala:62)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1.apply$mcV$sp(ShutdownHookManager.scala:62)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:216)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1992)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at scala.util.Try$.apply(Try.scala:192)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at org.apache.hadoop.util.ShutdownHookManager$1.run(ShutdownHookManager.java:54)
21/12/17 14:22:34 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
21/12/17 14:22:36 INFO SparkContext: Running Spark version 2.3.3
21/12/17 14:22:36 WARN SparkConf: In Spark 1.0 and later spark.local.dir will be overridden by the value set by the cluster manager (via SPARK_LOCAL_DIRS in mesos/standalone and LOCAL_DIRS in YARN).
21/12/17 14:22:36 INFO SparkContext: Submitted application: sparklyr
21/12/17 14:22:36 INFO SecurityManager: Changing view acls to: uhp07025
21/12/17 14:22:36 INFO SecurityManager: Changing modify acls to: uhp07025
21/12/17 14:22:36 INFO SecurityManager: Changing view acls groups to: 
21/12/17 14:22:36 INFO SecurityManager: Changing modify acls groups to: 
21/12/17 14:22:36 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(uhp07025); groups with view permissions: Set(); users  with modify permissions: Set(uhp07025); groups with modify permissions: Set()
21/12/17 14:22:36 INFO Utils: Successfully started service 'sparkDriver' on port 50949.
21/12/17 14:22:36 INFO SparkEnv: Registering MapOutputTracker
21/12/17 14:22:36 INFO SparkEnv: Registering BlockManagerMaster
21/12/17 14:22:36 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
21/12/17 14:22:36 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
21/12/17 14:22:36 INFO DiskBlockManager: Created local directory at C:\Users\uhp07025\AppData\Local\spark\spark-2.3.3-bin-hadoop2.7\tmp\local\blockmgr-8d7137b0-46f9-4fbe-9412-c63dbcc959ee
21/12/17 14:22:36 INFO MemoryStore: MemoryStore started with capacity 912.3 MB
21/12/17 14:22:36 INFO SparkEnv: Registering OutputCommitCoordinator
21/12/17 14:22:36 WARN Utils: The configured local directories are not expected to be URIs; however, got suspicious values [C:/Users/uhp07025/AppData/Local/spark/spark-2.3.3-bin-hadoop2.7/tmp/local]. Please check your configured local directories.
21/12/17 14:22:37 INFO Utils: Successfully started service 'SparkUI' on port 4040.
21/12/17 14:22:37 INFO SparkUI: Bound SparkUI to 127.0.0.1, and started at http://kubernetes.docker.internal:4040
21/12/17 14:22:37 INFO SparkContext: Added JAR file:/C:/Users/uhp07025/Documents/R/win-library/4.1/sparklyr/java/sparklyr-2.3-2.11.jar at spark://kubernetes.docker.internal:50949/jars/sparklyr-2.3-2.11.jar with timestamp 1639747357267
21/12/17 14:22:37 INFO Executor: Starting executor ID driver on host localhost
21/12/17 14:22:37 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 50990.
21/12/17 14:22:37 INFO NettyBlockTransferService: Server created on kubernetes.docker.internal:50990
21/12/17 14:22:37 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
21/12/17 14:22:37 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, kubernetes.docker.internal, 50990, None)
21/12/17 14:22:37 INFO BlockManagerMasterEndpoint: Registering block manager kubernetes.docker.internal:50990 with 912.3 MB RAM, BlockManagerId(driver, kubernetes.docker.internal, 50990, None)
21/12/17 14:22:37 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, kubernetes.docker.internal, 50990, None)
21/12/17 14:22:37 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, kubernetes.docker.internal, 50990, None)
21/12/17 14:22:37 INFO SharedState: loading hive config file: file:/C:/Users/uhp07025/AppData/Local/spark/spark-2.3.3-bin-hadoop2.7/conf/hive-site.xml
21/12/17 14:22:37 INFO SharedState: Setting hive.metastore.warehouse.dir ('C:/Users/uhp07025/AppData/Local/spark/spark-2.3.3-bin-hadoop2.7/tmp/hive') to the value of spark.sql.warehouse.dir ('C:/Users/uhp07025/AppData/Local/spark/spark-2.3.3-bin-hadoop2.7/tmp/hive').
21/12/17 14:22:37 INFO SharedState: Warehouse path is 'C:/Users/uhp07025/AppData/Local/spark/spark-2.3.3-bin-hadoop2.7/tmp/hive'.
21/12/17 14:22:38 INFO StateStoreCoordinatorRef: Registered StateStoreCoordinator endpoint
21/12/17 14:22:40 INFO HiveUtils: Initializing HiveMetastoreConnection version 1.2.1 using Spark classes.
21/12/17 14:22:41 INFO HiveMetaStore: 0: Opening raw store with implemenation class:org.apache.hadoop.hive.metastore.ObjectStore
21/12/17 14:22:41 INFO ObjectStore: ObjectStore, initialize called
21/12/17 14:22:41 INFO Persistence: Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
21/12/17 14:22:41 INFO Persistence: Property datanucleus.cache.level2 unknown - will be ignored
21/12/17 14:22:44 INFO ObjectStore: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
21/12/17 14:22:45 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
21/12/17 14:22:45 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
21/12/17 14:22:46 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
21/12/17 14:22:46 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
21/12/17 14:22:46 INFO MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
21/12/17 14:22:46 INFO ObjectStore: Initialized ObjectStore
21/12/17 14:22:46 WARN ObjectStore: Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 1.2.0
21/12/17 14:22:47 WARN ObjectStore: Failed to get database default, returning NoSuchObjectException
21/12/17 14:22:47 INFO HiveMetaStore: Added admin role in metastore
21/12/17 14:22:47 INFO HiveMetaStore: Added public role in metastore
21/12/17 14:22:47 INFO HiveMetaStore: No user is added in admin role, since config is empty
21/12/17 14:22:47 INFO HiveMetaStore: 0: get_all_databases
21/12/17 14:22:47 INFO audit: ugi=uhp07025	ip=unknown-ip-addr	cmd=get_all_databases	
21/12/17 14:22:47 INFO HiveMetaStore: 0: get_functions: db=default pat=*
21/12/17 14:22:47 INFO audit: ugi=uhp07025	ip=unknown-ip-addr	cmd=get_functions: db=default pat=*	
21/12/17 14:22:47 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MResourceUri" is tagged as "embedded-only" so does not have its own datastore table.
21/12/17 14:22:47 INFO SessionState: Created local directory: C:/Users/uhp07025/AppData/Local/Temp/618e0b7a-d4df-4218-8da6-21f9879ce8c7_resources
21/12/17 14:22:47 INFO SessionState: Created HDFS directory: C:/Users/uhp07025/AppData/Local/spark/spark-2.3.3-bin-hadoop2.7/tmp/hive/uhp07025/618e0b7a-d4df-4218-8da6-21f9879ce8c7
21/12/17 14:22:47 INFO SessionState: Created local directory: C:/Users/uhp07025/AppData/Local/spark/spark-2.3.3-bin-hadoop2.7/tmp/hive/618e0b7a-d4df-4218-8da6-21f9879ce8c7
21/12/17 14:22:47 INFO SessionState: Created HDFS directory: C:/Users/uhp07025/AppData/Local/spark/spark-2.3.3-bin-hadoop2.7/tmp/hive/uhp07025/618e0b7a-d4df-4218-8da6-21f9879ce8c7/_tmp_space.db
21/12/17 14:22:47 INFO HiveClientImpl: Warehouse location for Hive client (version 1.2.2) is C:/Users/uhp07025/AppData/Local/spark/spark-2.3.3-bin-hadoop2.7/tmp/hive
21/12/17 14:22:47 INFO HiveMetaStore: 0: get_database: default
21/12/17 14:22:47 INFO audit: ugi=uhp07025	ip=unknown-ip-addr	cmd=get_database: default	
21/12/17 14:22:47 INFO HiveMetaStore: 0: get_database: global_temp
21/12/17 14:22:47 INFO audit: ugi=uhp07025	ip=unknown-ip-addr	cmd=get_database: global_temp	
21/12/17 14:22:47 WARN ObjectStore: Failed to get database global_temp, returning NoSuchObjectException
21/12/17 14:22:48 INFO HiveMetaStore: 0: get_database: default
21/12/17 14:22:48 INFO audit: ugi=uhp07025	ip=unknown-ip-addr	cmd=get_database: default	
21/12/17 14:22:48 INFO HiveMetaStore: 0: get_database: default
21/12/17 14:22:48 INFO audit: ugi=uhp07025	ip=unknown-ip-addr	cmd=get_database: default	
21/12/17 14:22:48 INFO HiveMetaStore: 0: get_tables: db=default pat=*
21/12/17 14:22:48 INFO audit: ugi=uhp07025	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
21/12/17 14:22:49 INFO CodeGenerator: Code generated in 327.9734 ms
21/12/17 14:22:49 INFO HiveMetaStore: 0: get_database: default
21/12/17 14:22:49 INFO audit: ugi=uhp07025	ip=unknown-ip-addr	cmd=get_database: default	
21/12/17 14:22:49 INFO HiveMetaStore: 0: get_database: default
21/12/17 14:22:49 INFO audit: ugi=uhp07025	ip=unknown-ip-addr	cmd=get_database: default	
21/12/17 14:22:49 INFO HiveMetaStore: 0: get_tables: db=default pat=*
21/12/17 14:22:49 INFO audit: ugi=uhp07025	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
21/12/17 14:22:49 INFO CodeGenerator: Code generated in 14.7969 ms
21/12/17 14:22:50 INFO CodeGenerator: Code generated in 14.6997 ms
21/12/17 14:22:50 INFO CodeGenerator: Code generated in 19.9112 ms
21/12/17 14:22:50 INFO SparkContext: Starting job: collect at utils.scala:24
21/12/17 14:22:50 INFO DAGScheduler: Got job 0 (collect at utils.scala:24) with 1 output partitions
21/12/17 14:22:50 INFO DAGScheduler: Final stage: ResultStage 0 (collect at utils.scala:24)
21/12/17 14:22:50 INFO DAGScheduler: Parents of final stage: List()
21/12/17 14:22:50 INFO DAGScheduler: Missing parents: List()
21/12/17 14:22:50 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[4] at collect at utils.scala:24), which has no missing parents
21/12/17 14:22:50 INFO ContextCleaner: Cleaned accumulator 0
21/12/17 14:22:50 INFO ContextCleaner: Cleaned accumulator 1
21/12/17 14:22:50 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.8 KB, free 912.3 MB)
21/12/17 14:22:50 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 3.3 KB, free 912.3 MB)
21/12/17 14:22:50 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on kubernetes.docker.internal:50990 (size: 3.3 KB, free: 912.3 MB)
21/12/17 14:22:50 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1039
21/12/17 14:22:50 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[4] at collect at utils.scala:24) (first 15 tasks are for partitions Vector(0))
21/12/17 14:22:50 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks
21/12/17 14:22:51 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 8067 bytes)
21/12/17 14:22:51 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
21/12/17 14:22:51 INFO Executor: Fetching spark://kubernetes.docker.internal:50949/jars/sparklyr-2.3-2.11.jar with timestamp 1639747357267
21/12/17 14:22:51 INFO TransportClientFactory: Successfully created connection to kubernetes.docker.internal/127.0.0.1:50949 after 41 ms (0 ms spent in bootstraps)
21/12/17 14:22:51 INFO Utils: Fetching spark://kubernetes.docker.internal:50949/jars/sparklyr-2.3-2.11.jar to C:\Users\uhp07025\AppData\Local\spark\spark-2.3.3-bin-hadoop2.7\tmp\local\spark-82d9eec9-a975-42c4-9022-a576e60a321e\userFiles-6a667cb1-735c-4cda-9933-3f9edc6a8c8a\fetchFileTemp2811553195341422992.tmp
21/12/17 14:22:51 INFO Executor: Adding file:/C:/Users/uhp07025/AppData/Local/spark/spark-2.3.3-bin-hadoop2.7/tmp/local/spark-82d9eec9-a975-42c4-9022-a576e60a321e/userFiles-6a667cb1-735c-4cda-9933-3f9edc6a8c8a/sparklyr-2.3-2.11.jar to class loader
21/12/17 14:22:51 INFO CodeGenerator: Code generated in 14.9116 ms
21/12/17 14:22:51 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1286 bytes result sent to driver
21/12/17 14:22:51 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 507 ms on localhost (executor driver) (1/1)
21/12/17 14:22:51 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
21/12/17 14:22:51 INFO DAGScheduler: ResultStage 0 (collect at utils.scala:24) finished in 0.866 s
21/12/17 14:22:51 INFO DAGScheduler: Job 0 finished: collect at utils.scala:24, took 0.927075 s
21/12/17 14:22:52 INFO SparkContext: Starting job: collect at utils.scala:24
21/12/17 14:22:52 INFO DAGScheduler: Got job 1 (collect at utils.scala:24) with 1 output partitions
21/12/17 14:22:52 INFO DAGScheduler: Final stage: ResultStage 1 (collect at utils.scala:24)
21/12/17 14:22:52 INFO DAGScheduler: Parents of final stage: List()
21/12/17 14:22:52 INFO DAGScheduler: Missing parents: List()
21/12/17 14:22:52 INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[9] at collect at utils.scala:24), which has no missing parents
21/12/17 14:22:52 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 6.8 KB, free 912.3 MB)
21/12/17 14:22:52 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.3 KB, free 912.3 MB)
21/12/17 14:22:52 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on kubernetes.docker.internal:50990 (size: 3.3 KB, free: 912.3 MB)
21/12/17 14:22:52 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1039
21/12/17 14:22:52 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[9] at collect at utils.scala:24) (first 15 tasks are for partitions Vector(0))
21/12/17 14:22:52 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks
21/12/17 14:22:52 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1, localhost, executor driver, partition 0, PROCESS_LOCAL, 8067 bytes)
21/12/17 14:22:52 INFO Executor: Running task 0.0 in stage 1.0 (TID 1)
21/12/17 14:22:52 INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 1200 bytes result sent to driver
21/12/17 14:22:52 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 9 ms on localhost (executor driver) (1/1)
21/12/17 14:22:52 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
21/12/17 14:22:52 INFO DAGScheduler: ResultStage 1 (collect at utils.scala:24) finished in 0.021 s
21/12/17 14:22:52 INFO DAGScheduler: Job 1 finished: collect at utils.scala:24, took 0.028575 s
21/12/17 14:22:52 INFO HiveMetaStore: 0: get_database: default
21/12/17 14:22:52 INFO audit: ugi=uhp07025	ip=unknown-ip-addr	cmd=get_database: default	
21/12/17 14:22:52 INFO HiveMetaStore: 0: get_database: default
21/12/17 14:22:52 INFO audit: ugi=uhp07025	ip=unknown-ip-addr	cmd=get_database: default	
21/12/17 14:22:52 INFO HiveMetaStore: 0: get_tables: db=default pat=*
21/12/17 14:22:52 INFO audit: ugi=uhp07025	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
21/12/17 14:22:52 INFO CodeGenerator: Code generated in 12.3519 ms
21/12/17 14:22:52 INFO CodeGenerator: Code generated in 26.4763 ms
21/12/17 14:22:52 INFO CodeGenerator: Code generated in 51.2225 ms
21/12/17 14:22:52 INFO SparkContext: Starting job: collect at utils.scala:24
21/12/17 14:22:52 INFO DAGScheduler: Got job 2 (collect at utils.scala:24) with 1 output partitions
21/12/17 14:22:52 INFO DAGScheduler: Final stage: ResultStage 2 (collect at utils.scala:24)
21/12/17 14:22:52 INFO DAGScheduler: Parents of final stage: List()
21/12/17 14:22:52 INFO DAGScheduler: Missing parents: List()
21/12/17 14:22:52 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[14] at collect at utils.scala:24), which has no missing parents
21/12/17 14:22:52 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 26.0 KB, free 912.3 MB)
21/12/17 14:22:52 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 9.3 KB, free 912.2 MB)
21/12/17 14:22:52 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on kubernetes.docker.internal:50990 (size: 9.3 KB, free: 912.3 MB)
21/12/17 14:22:52 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1039
21/12/17 14:22:52 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[14] at collect at utils.scala:24) (first 15 tasks are for partitions Vector(0))
21/12/17 14:22:52 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks
21/12/17 14:22:52 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2, localhost, executor driver, partition 0, PROCESS_LOCAL, 11614 bytes)
21/12/17 14:22:52 INFO Executor: Running task 0.0 in stage 2.0 (TID 2)
21/12/17 14:22:52 INFO CodeGenerator: Code generated in 26.2195 ms
21/12/17 14:22:52 INFO MemoryStore: Block rdd_6_0 stored as values in memory (estimated size 4.2 KB, free 912.2 MB)
21/12/17 14:22:52 INFO BlockManagerInfo: Added rdd_6_0 in memory on kubernetes.docker.internal:50990 (size: 4.2 KB, free: 912.3 MB)
21/12/17 14:22:52 INFO CodeGenerator: Code generated in 6.2944 ms
21/12/17 14:22:53 INFO Executor: Finished task 0.0 in stage 2.0 (TID 2). 2533 bytes result sent to driver
21/12/17 14:22:53 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 166 ms on localhost (executor driver) (1/1)
21/12/17 14:22:53 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
21/12/17 14:22:53 INFO DAGScheduler: ResultStage 2 (collect at utils.scala:24) finished in 0.196 s
21/12/17 14:22:53 INFO DAGScheduler: Job 2 finished: collect at utils.scala:24, took 0.206331 s
21/12/17 14:22:53 INFO HiveMetaStore: 0: get_database: default
21/12/17 14:22:53 INFO audit: ugi=uhp07025	ip=unknown-ip-addr	cmd=get_database: default	
21/12/17 14:22:53 INFO CodeGenerator: Code generated in 9.3895 ms
21/12/17 14:22:53 INFO CodeGenerator: Code generated in 16.2293 ms
21/12/17 14:22:53 INFO CodeGenerator: Code generated in 14.8218 ms
21/12/17 14:22:53 INFO SparkContext: Starting job: collect at utils.scala:24
21/12/17 14:22:53 INFO DAGScheduler: Registering RDD 17 (collect at utils.scala:24)
21/12/17 14:22:53 INFO DAGScheduler: Got job 3 (collect at utils.scala:24) with 1 output partitions
21/12/17 14:22:53 INFO DAGScheduler: Final stage: ResultStage 4 (collect at utils.scala:24)
21/12/17 14:22:53 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 3)
21/12/17 14:22:53 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 3)
21/12/17 14:22:53 INFO DAGScheduler: Submitting ShuffleMapStage 3 (MapPartitionsRDD[17] at collect at utils.scala:24), which has no missing parents
21/12/17 14:22:53 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 9.3 KB, free 912.2 MB)
21/12/17 14:22:53 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 4.8 KB, free 912.2 MB)
21/12/17 14:22:53 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on kubernetes.docker.internal:50990 (size: 4.8 KB, free: 912.3 MB)
21/12/17 14:22:53 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1039
21/12/17 14:22:53 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 3 (MapPartitionsRDD[17] at collect at utils.scala:24) (first 15 tasks are for partitions Vector(0))
21/12/17 14:22:53 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks
21/12/17 14:22:53 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 3, localhost, executor driver, partition 0, PROCESS_LOCAL, 11603 bytes)
21/12/17 14:22:53 INFO Executor: Running task 0.0 in stage 3.0 (TID 3)
21/12/17 14:22:53 INFO Executor: Finished task 0.0 in stage 3.0 (TID 3). 1516 bytes result sent to driver
21/12/17 14:22:53 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 3) in 93 ms on localhost (executor driver) (1/1)
21/12/17 14:22:53 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
21/12/17 14:22:53 INFO DAGScheduler: ShuffleMapStage 3 (collect at utils.scala:24) finished in 0.111 s
21/12/17 14:22:53 INFO DAGScheduler: looking for newly runnable stages
21/12/17 14:22:53 INFO DAGScheduler: running: Set()
21/12/17 14:22:53 INFO DAGScheduler: waiting: Set(ResultStage 4)
21/12/17 14:22:53 INFO DAGScheduler: failed: Set()
21/12/17 14:22:53 INFO DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[20] at collect at utils.scala:24), which has no missing parents
21/12/17 14:22:53 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 7.5 KB, free 912.2 MB)
21/12/17 14:22:53 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 3.9 KB, free 912.2 MB)
21/12/17 14:22:53 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on kubernetes.docker.internal:50990 (size: 3.9 KB, free: 912.3 MB)
21/12/17 14:22:53 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1039
21/12/17 14:22:53 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[20] at collect at utils.scala:24) (first 15 tasks are for partitions Vector(0))
21/12/17 14:22:53 INFO TaskSchedulerImpl: Adding task set 4.0 with 1 tasks
21/12/17 14:22:53 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 4, localhost, executor driver, partition 0, ANY, 7754 bytes)
21/12/17 14:22:53 INFO Executor: Running task 0.0 in stage 4.0 (TID 4)
21/12/17 14:22:53 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
21/12/17 14:22:53 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 30 ms
21/12/17 14:22:53 INFO Executor: Finished task 0.0 in stage 4.0 (TID 4). 1782 bytes result sent to driver
21/12/17 14:22:53 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 4) in 88 ms on localhost (executor driver) (1/1)
21/12/17 14:22:53 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool 
21/12/17 14:22:53 INFO DAGScheduler: ResultStage 4 (collect at utils.scala:24) finished in 0.106 s
21/12/17 14:22:53 INFO DAGScheduler: Job 3 finished: collect at utils.scala:24, took 0.261056 s
21/12/17 14:23:58 INFO HiveMetaStore: 0: get_database: default
21/12/17 14:23:58 INFO audit: ugi=uhp07025	ip=unknown-ip-addr	cmd=get_database: default	
21/12/17 14:23:58 INFO HiveMetaStore: 0: get_database: default
21/12/17 14:23:58 INFO audit: ugi=uhp07025	ip=unknown-ip-addr	cmd=get_database: default	
21/12/17 14:23:58 INFO SparkContext: Starting job: collect at utils.scala:24
21/12/17 14:23:58 INFO DAGScheduler: Registering RDD 23 (collect at utils.scala:24)
21/12/17 14:23:58 INFO DAGScheduler: Got job 4 (collect at utils.scala:24) with 1 output partitions
21/12/17 14:23:58 INFO DAGScheduler: Final stage: ResultStage 6 (collect at utils.scala:24)
21/12/17 14:23:58 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 5)
21/12/17 14:23:58 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 5)
21/12/17 14:23:58 INFO DAGScheduler: Submitting ShuffleMapStage 5 (MapPartitionsRDD[23] at collect at utils.scala:24), which has no missing parents
21/12/17 14:23:58 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 9.3 KB, free 912.2 MB)
21/12/17 14:23:58 INFO ContextCleaner: Cleaned accumulator 33
21/12/17 14:23:58 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 4.8 KB, free 912.2 MB)
21/12/17 14:23:58 INFO ContextCleaner: Cleaned accumulator 85
21/12/17 14:23:58 INFO ContextCleaner: Cleaned accumulator 108
21/12/17 14:23:58 INFO ContextCleaner: Cleaned accumulator 49
21/12/17 14:23:58 INFO ContextCleaner: Cleaned accumulator 60
21/12/17 14:23:58 INFO ContextCleaner: Cleaned accumulator 140
21/12/17 14:23:58 INFO ContextCleaner: Cleaned accumulator 78
21/12/17 14:23:58 INFO ContextCleaner: Cleaned accumulator 103
21/12/17 14:23:58 INFO ContextCleaner: Cleaned accumulator 56
21/12/17 14:23:58 INFO ContextCleaner: Cleaned accumulator 57
21/12/17 14:23:58 INFO ContextCleaner: Cleaned accumulator 150
21/12/17 14:23:58 INFO ContextCleaner: Cleaned accumulator 114
21/12/17 14:23:58 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on kubernetes.docker.internal:50990 (size: 4.8 KB, free: 912.3 MB)
21/12/17 14:23:58 INFO ContextCleaner: Cleaned accumulator 64
21/12/17 14:23:58 INFO ContextCleaner: Cleaned accumulator 47
21/12/17 14:23:58 INFO ContextCleaner: Cleaned accumulator 61
21/12/17 14:23:58 INFO ContextCleaner: Cleaned accumulator 69
21/12/17 14:23:58 INFO ContextCleaner: Cleaned accumulator 76
21/12/17 14:23:58 INFO ContextCleaner: Cleaned accumulator 92
21/12/17 14:23:58 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1039
21/12/17 14:23:58 INFO ContextCleaner: Cleaned accumulator 53
21/12/17 14:23:58 INFO ContextCleaner: Cleaned accumulator 122
21/12/17 14:23:58 INFO ContextCleaner: Cleaned accumulator 137
21/12/17 14:23:58 INFO ContextCleaner: Cleaned accumulator 128
21/12/17 14:23:58 INFO ContextCleaner: Cleaned accumulator 83
21/12/17 14:23:58 INFO ContextCleaner: Cleaned accumulator 44
21/12/17 14:23:58 INFO ContextCleaner: Cleaned accumulator 86
21/12/17 14:23:58 INFO ContextCleaner: Cleaned accumulator 120
21/12/17 14:23:58 INFO ContextCleaner: Cleaned accumulator 131
21/12/17 14:23:58 INFO ContextCleaner: Cleaned accumulator 116
21/12/17 14:23:58 INFO ContextCleaner: Cleaned accumulator 89
21/12/17 14:23:58 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 5 (MapPartitionsRDD[23] at collect at utils.scala:24) (first 15 tasks are for partitions Vector(0))
21/12/17 14:23:58 INFO ContextCleaner: Cleaned accumulator 34
21/12/17 14:23:58 INFO ContextCleaner: Cleaned accumulator 136
21/12/17 14:23:58 INFO ContextCleaner: Cleaned accumulator 54
21/12/17 14:23:58 INFO ContextCleaner: Cleaned accumulator 98
21/12/17 14:23:58 INFO TaskSchedulerImpl: Adding task set 5.0 with 1 tasks
21/12/17 14:23:58 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 5, localhost, executor driver, partition 0, PROCESS_LOCAL, 11603 bytes)
21/12/17 14:23:58 INFO Executor: Running task 0.0 in stage 5.0 (TID 5)
21/12/17 14:23:58 INFO BlockManagerInfo: Removed broadcast_1_piece0 on kubernetes.docker.internal:50990 in memory (size: 3.3 KB, free: 912.3 MB)
21/12/17 14:23:58 INFO Executor: Finished task 0.0 in stage 5.0 (TID 5). 1473 bytes result sent to driver
21/12/17 14:23:58 INFO ContextCleaner: Cleaned accumulator 112
21/12/17 14:23:58 INFO ContextCleaner: Cleaned accumulator 51
21/12/17 14:23:58 INFO ContextCleaner: Cleaned accumulator 94
21/12/17 14:23:58 INFO ContextCleaner: Cleaned accumulator 144
21/12/17 14:23:58 INFO ContextCleaner: Cleaned accumulator 133
21/12/17 14:23:58 INFO ContextCleaner: Cleaned accumulator 90
21/12/17 14:23:58 INFO ContextCleaner: Cleaned accumulator 91
21/12/17 14:23:58 INFO ContextCleaner: Cleaned accumulator 67
21/12/17 14:23:58 INFO ContextCleaner: Cleaned accumulator 73
21/12/17 14:23:58 INFO ContextCleaner: Cleaned accumulator 32
21/12/17 14:23:58 INFO ContextCleaner: Cleaned accumulator 151
21/12/17 14:23:58 INFO ContextCleaner: Cleaned accumulator 75
21/12/17 14:23:58 INFO ContextCleaner: Cleaned accumulator 119
21/12/17 14:23:58 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 5) in 18 ms on localhost (executor driver) (1/1)
21/12/17 14:23:58 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
21/12/17 14:23:58 INFO DAGScheduler: ShuffleMapStage 5 (collect at utils.scala:24) finished in 0.045 s
21/12/17 14:23:58 INFO DAGScheduler: looking for newly runnable stages
21/12/17 14:23:58 INFO DAGScheduler: running: Set()
21/12/17 14:23:58 INFO DAGScheduler: waiting: Set(ResultStage 6)
21/12/17 14:23:58 INFO DAGScheduler: failed: Set()
21/12/17 14:23:58 INFO DAGScheduler: Submitting ResultStage 6 (MapPartitionsRDD[27] at collect at utils.scala:24), which has no missing parents
21/12/17 14:23:58 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 7.6 KB, free 912.2 MB)
21/12/17 14:23:58 INFO ContextCleaner: Cleaned shuffle 0
21/12/17 14:23:58 INFO ContextCleaner: Cleaned accumulator 113
21/12/17 14:23:58 INFO ContextCleaner: Cleaned accumulator 31
21/12/17 14:23:58 INFO ContextCleaner: Cleaned accumulator 55
21/12/17 14:23:58 INFO ContextCleaner: Cleaned accumulator 147
21/12/17 14:23:58 INFO ContextCleaner: Cleaned accumulator 43
21/12/17 14:23:58 INFO ContextCleaner: Cleaned accumulator 104
21/12/17 14:23:58 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 3.9 KB, free 912.2 MB)
21/12/17 14:23:58 INFO ContextCleaner: Cleaned accumulator 79
21/12/17 14:23:58 INFO ContextCleaner: Cleaned accumulator 152
21/12/17 14:23:58 INFO ContextCleaner: Cleaned accumulator 40
21/12/17 14:23:58 INFO ContextCleaner: Cleaned accumulator 80
21/12/17 14:23:58 INFO ContextCleaner: Cleaned accumulator 88
21/12/17 14:23:58 INFO ContextCleaner: Cleaned accumulator 63
21/12/17 14:23:58 INFO ContextCleaner: Cleaned accumulator 107
21/12/17 14:23:58 INFO ContextCleaner: Cleaned accumulator 48
21/12/17 14:23:58 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on kubernetes.docker.internal:50990 (size: 3.9 KB, free: 912.3 MB)
21/12/17 14:23:58 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1039
21/12/17 14:23:58 INFO BlockManagerInfo: Removed broadcast_4_piece0 on kubernetes.docker.internal:50990 in memory (size: 3.9 KB, free: 912.3 MB)
21/12/17 14:23:58 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 6 (MapPartitionsRDD[27] at collect at utils.scala:24) (first 15 tasks are for partitions Vector(0))
21/12/17 14:23:58 INFO TaskSchedulerImpl: Adding task set 6.0 with 1 tasks
21/12/17 14:23:58 INFO ContextCleaner: Cleaned accumulator 70
21/12/17 14:23:58 INFO ContextCleaner: Cleaned accumulator 109
21/12/17 14:23:58 INFO ContextCleaner: Cleaned accumulator 110
21/12/17 14:23:58 INFO ContextCleaner: Cleaned accumulator 129
21/12/17 14:23:58 INFO ContextCleaner: Cleaned accumulator 125
21/12/17 14:23:58 INFO ContextCleaner: Cleaned accumulator 45
21/12/17 14:23:58 INFO ContextCleaner: Cleaned accumulator 36
21/12/17 14:23:58 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 6, localhost, executor driver, partition 0, ANY, 7754 bytes)
21/12/17 14:23:58 INFO ContextCleaner: Cleaned accumulator 50
21/12/17 14:23:58 INFO ContextCleaner: Cleaned accumulator 95
21/12/17 14:23:58 INFO Executor: Running task 0.0 in stage 6.0 (TID 6)
21/12/17 14:23:58 INFO ContextCleaner: Cleaned accumulator 37
21/12/17 14:23:58 INFO ContextCleaner: Cleaned accumulator 41
21/12/17 14:23:58 INFO ContextCleaner: Cleaned accumulator 71
21/12/17 14:23:58 INFO ContextCleaner: Cleaned accumulator 124
21/12/17 14:23:58 INFO ContextCleaner: Cleaned accumulator 68
21/12/17 14:23:58 INFO ContextCleaner: Cleaned accumulator 74
21/12/17 14:23:58 INFO ContextCleaner: Cleaned accumulator 127
21/12/17 14:23:58 INFO ContextCleaner: Cleaned accumulator 135
21/12/17 14:23:58 INFO ContextCleaner: Cleaned accumulator 46
21/12/17 14:23:58 INFO ContextCleaner: Cleaned accumulator 38
21/12/17 14:23:58 INFO ContextCleaner: Cleaned accumulator 62
21/12/17 14:23:58 INFO ContextCleaner: Cleaned accumulator 96
21/12/17 14:23:58 INFO ContextCleaner: Cleaned accumulator 82
21/12/17 14:23:58 INFO ContextCleaner: Cleaned accumulator 99
21/12/17 14:23:58 INFO ContextCleaner: Cleaned accumulator 142
21/12/17 14:23:58 INFO ContextCleaner: Cleaned accumulator 134
21/12/17 14:23:58 INFO ContextCleaner: Cleaned accumulator 130
21/12/17 14:23:58 INFO ContextCleaner: Cleaned accumulator 100
21/12/17 14:23:58 INFO ContextCleaner: Cleaned accumulator 52
21/12/17 14:23:58 INFO ContextCleaner: Cleaned accumulator 118
21/12/17 14:23:58 INFO ContextCleaner: Cleaned accumulator 42
21/12/17 14:23:58 INFO ContextCleaner: Cleaned accumulator 93
21/12/17 14:23:58 INFO ContextCleaner: Cleaned accumulator 141
21/12/17 14:23:58 INFO ContextCleaner: Cleaned accumulator 65
21/12/17 14:23:58 INFO ContextCleaner: Cleaned accumulator 148
21/12/17 14:23:58 INFO ContextCleaner: Cleaned accumulator 132
21/12/17 14:23:58 INFO ContextCleaner: Cleaned accumulator 58
21/12/17 14:23:58 INFO ContextCleaner: Cleaned accumulator 111
21/12/17 14:23:58 INFO ContextCleaner: Cleaned accumulator 97
21/12/17 14:23:58 INFO ContextCleaner: Cleaned accumulator 84
21/12/17 14:23:58 INFO ContextCleaner: Cleaned accumulator 101
21/12/17 14:23:58 INFO ContextCleaner: Cleaned accumulator 143
21/12/17 14:23:58 INFO ContextCleaner: Cleaned accumulator 39
21/12/17 14:23:58 INFO ContextCleaner: Cleaned accumulator 123
21/12/17 14:23:58 INFO ContextCleaner: Cleaned accumulator 139
21/12/17 14:23:58 INFO ContextCleaner: Cleaned accumulator 35
21/12/17 14:23:58 INFO ContextCleaner: Cleaned accumulator 126
21/12/17 14:23:58 INFO ContextCleaner: Cleaned accumulator 59
21/12/17 14:23:58 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
21/12/17 14:23:58 INFO ContextCleaner: Cleaned accumulator 138
21/12/17 14:23:58 INFO ContextCleaner: Cleaned accumulator 81
21/12/17 14:23:58 INFO ContextCleaner: Cleaned accumulator 105
21/12/17 14:23:58 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
21/12/17 14:23:58 INFO ContextCleaner: Cleaned accumulator 117
21/12/17 14:23:58 INFO ContextCleaner: Cleaned accumulator 149
21/12/17 14:23:58 INFO ContextCleaner: Cleaned accumulator 66
21/12/17 14:23:58 INFO ContextCleaner: Cleaned accumulator 77
21/12/17 14:23:58 INFO ContextCleaner: Cleaned accumulator 121
21/12/17 14:23:58 INFO ContextCleaner: Cleaned accumulator 102
21/12/17 14:23:58 INFO ContextCleaner: Cleaned accumulator 72
21/12/17 14:23:58 INFO BlockManagerInfo: Removed broadcast_3_piece0 on kubernetes.docker.internal:50990 in memory (size: 4.8 KB, free: 912.3 MB)
21/12/17 14:23:58 INFO ContextCleaner: Cleaned accumulator 115
21/12/17 14:23:58 INFO ContextCleaner: Cleaned accumulator 146
21/12/17 14:23:58 INFO ContextCleaner: Cleaned accumulator 87
21/12/17 14:23:58 INFO Executor: Finished task 0.0 in stage 6.0 (TID 6). 1514 bytes result sent to driver
21/12/17 14:23:58 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 6) in 5 ms on localhost (executor driver) (1/1)
21/12/17 14:23:58 INFO BlockManagerInfo: Removed broadcast_2_piece0 on kubernetes.docker.internal:50990 in memory (size: 9.3 KB, free: 912.3 MB)
21/12/17 14:23:58 INFO TaskSchedulerImpl: Removed TaskSet 6.0, whose tasks have all completed, from pool 
21/12/17 14:23:58 INFO ContextCleaner: Cleaned accumulator 145
21/12/17 14:23:58 INFO DAGScheduler: ResultStage 6 (collect at utils.scala:24) finished in 0.013 s
21/12/17 14:23:58 INFO ContextCleaner: Cleaned accumulator 106
21/12/17 14:23:58 INFO DAGScheduler: Job 4 finished: collect at utils.scala:24, took 0.061358 s
21/12/17 14:24:00 INFO CodeGenerator: Code generated in 6.3767 ms
21/12/17 14:24:00 INFO CodeGenerator: Code generated in 8.645 ms
21/12/17 14:24:00 INFO SparkContext: Starting job: collect at utils.scala:24
21/12/17 14:24:00 INFO DAGScheduler: Got job 5 (collect at utils.scala:24) with 1 output partitions
21/12/17 14:24:00 INFO DAGScheduler: Final stage: ResultStage 7 (collect at utils.scala:24)
21/12/17 14:24:00 INFO DAGScheduler: Parents of final stage: List()
21/12/17 14:24:00 INFO DAGScheduler: Missing parents: List()
21/12/17 14:24:00 INFO DAGScheduler: Submitting ResultStage 7 (MapPartitionsRDD[30] at collect at utils.scala:24), which has no missing parents
21/12/17 14:24:00 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 6.4 KB, free 912.3 MB)
21/12/17 14:24:00 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 3.2 KB, free 912.3 MB)
21/12/17 14:24:00 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on kubernetes.docker.internal:50990 (size: 3.2 KB, free: 912.3 MB)
21/12/17 14:24:00 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:1039
21/12/17 14:24:00 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 7 (MapPartitionsRDD[30] at collect at utils.scala:24) (first 15 tasks are for partitions Vector(0))
21/12/17 14:24:00 INFO TaskSchedulerImpl: Adding task set 7.0 with 1 tasks
21/12/17 14:24:00 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 7, localhost, executor driver, partition 0, PROCESS_LOCAL, 8067 bytes)
21/12/17 14:24:00 INFO Executor: Running task 0.0 in stage 7.0 (TID 7)
21/12/17 14:24:00 INFO Executor: Finished task 0.0 in stage 7.0 (TID 7). 1157 bytes result sent to driver
21/12/17 14:24:00 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 7) in 6 ms on localhost (executor driver) (1/1)
21/12/17 14:24:00 INFO TaskSchedulerImpl: Removed TaskSet 7.0, whose tasks have all completed, from pool 
21/12/17 14:24:00 INFO DAGScheduler: ResultStage 7 (collect at utils.scala:24) finished in 0.013 s
21/12/17 14:24:00 INFO DAGScheduler: Job 5 finished: collect at utils.scala:24, took 0.015565 s
21/12/17 14:24:00 INFO CodeGenerator: Code generated in 13.7104 ms
21/12/17 14:24:00 INFO SparkContext: Starting job: aggregate at samplingutils.scala:37
21/12/17 14:24:00 INFO DAGScheduler: Got job 6 (aggregate at samplingutils.scala:37) with 1 output partitions
21/12/17 14:24:00 INFO DAGScheduler: Final stage: ResultStage 8 (aggregate at samplingutils.scala:37)
21/12/17 14:24:00 INFO DAGScheduler: Parents of final stage: List()
21/12/17 14:24:00 INFO DAGScheduler: Missing parents: List()
21/12/17 14:24:00 INFO DAGScheduler: Submitting ResultStage 8 (MapPartitionsRDD[34] at rdd at NativeMethodAccessorImpl.java:0), which has no missing parents
21/12/17 14:24:00 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 11.3 KB, free 912.2 MB)
21/12/17 14:24:00 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 5.6 KB, free 912.2 MB)
21/12/17 14:24:00 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on kubernetes.docker.internal:50990 (size: 5.6 KB, free: 912.3 MB)
21/12/17 14:24:00 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:1039
21/12/17 14:24:00 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 8 (MapPartitionsRDD[34] at rdd at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
21/12/17 14:24:00 INFO TaskSchedulerImpl: Adding task set 8.0 with 1 tasks
21/12/17 14:24:00 INFO TaskSetManager: Starting task 0.0 in stage 8.0 (TID 8, localhost, executor driver, partition 0, PROCESS_LOCAL, 11614 bytes)
21/12/17 14:24:00 INFO Executor: Running task 0.0 in stage 8.0 (TID 8)
21/12/17 14:24:00 INFO CodeGenerator: Code generated in 9.315 ms
21/12/17 14:24:00 INFO Executor: Finished task 0.0 in stage 8.0 (TID 8). 4659 bytes result sent to driver
21/12/17 14:24:00 INFO TaskSetManager: Finished task 0.0 in stage 8.0 (TID 8) in 36 ms on localhost (executor driver) (1/1)
21/12/17 14:24:00 INFO TaskSchedulerImpl: Removed TaskSet 8.0, whose tasks have all completed, from pool 
21/12/17 14:24:00 INFO DAGScheduler: ResultStage 8 (aggregate at samplingutils.scala:37) finished in 0.047 s
21/12/17 14:24:00 INFO DAGScheduler: Job 6 finished: aggregate at samplingutils.scala:37, took 0.050258 s
21/12/17 14:24:00 INFO SparkContext: Starting job: collect at utils.scala:24
21/12/17 14:24:00 INFO DAGScheduler: Got job 7 (collect at utils.scala:24) with 1 output partitions
21/12/17 14:24:00 INFO DAGScheduler: Final stage: ResultStage 9 (collect at utils.scala:24)
21/12/17 14:24:00 INFO DAGScheduler: Parents of final stage: List()
21/12/17 14:24:00 INFO DAGScheduler: Missing parents: List()
21/12/17 14:24:00 INFO DAGScheduler: Submitting ResultStage 9 (MapPartitionsRDD[39] at collect at utils.scala:24), which has no missing parents
21/12/17 14:24:00 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 6.4 KB, free 912.2 MB)
21/12/17 14:24:00 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 3.2 KB, free 912.2 MB)
21/12/17 14:24:00 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on kubernetes.docker.internal:50990 (size: 3.2 KB, free: 912.3 MB)
21/12/17 14:24:00 INFO SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:1039
21/12/17 14:24:00 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 9 (MapPartitionsRDD[39] at collect at utils.scala:24) (first 15 tasks are for partitions Vector(0))
21/12/17 14:24:00 INFO TaskSchedulerImpl: Adding task set 9.0 with 1 tasks
21/12/17 14:24:00 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 9, localhost, executor driver, partition 0, PROCESS_LOCAL, 8067 bytes)
21/12/17 14:24:00 INFO Executor: Running task 0.0 in stage 9.0 (TID 9)
21/12/17 14:24:00 INFO Executor: Finished task 0.0 in stage 9.0 (TID 9). 1200 bytes result sent to driver
21/12/17 14:24:00 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 9) in 5 ms on localhost (executor driver) (1/1)
21/12/17 14:24:00 INFO TaskSchedulerImpl: Removed TaskSet 9.0, whose tasks have all completed, from pool 
21/12/17 14:24:00 INFO DAGScheduler: ResultStage 9 (collect at utils.scala:24) finished in 0.012 s
21/12/17 14:24:00 INFO DAGScheduler: Job 7 finished: collect at utils.scala:24, took 0.014639 s
21/12/17 14:24:00 INFO SparkContext: Starting job: collect at utils.scala:24
21/12/17 14:24:00 INFO DAGScheduler: Got job 8 (collect at utils.scala:24) with 8 output partitions
21/12/17 14:24:00 INFO DAGScheduler: Final stage: ResultStage 10 (collect at utils.scala:24)
21/12/17 14:24:00 INFO DAGScheduler: Parents of final stage: List()
21/12/17 14:24:00 INFO DAGScheduler: Missing parents: List()
21/12/17 14:24:00 INFO DAGScheduler: Submitting ResultStage 10 (MapPartitionsRDD[41] at collect at utils.scala:24), which has no missing parents
21/12/17 14:24:00 INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 8.0 KB, free 912.2 MB)
21/12/17 14:24:00 INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 4.4 KB, free 912.2 MB)
21/12/17 14:24:00 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on kubernetes.docker.internal:50990 (size: 4.4 KB, free: 912.3 MB)
21/12/17 14:24:00 INFO SparkContext: Created broadcast 10 from broadcast at DAGScheduler.scala:1039
21/12/17 14:24:00 INFO DAGScheduler: Submitting 8 missing tasks from ResultStage 10 (MapPartitionsRDD[41] at collect at utils.scala:24) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))
21/12/17 14:24:00 INFO TaskSchedulerImpl: Adding task set 10.0 with 8 tasks
21/12/17 14:24:00 INFO TaskSetManager: Starting task 0.0 in stage 10.0 (TID 10, localhost, executor driver, partition 0, PROCESS_LOCAL, 9059 bytes)
21/12/17 14:24:00 INFO TaskSetManager: Starting task 1.0 in stage 10.0 (TID 11, localhost, executor driver, partition 1, PROCESS_LOCAL, 9059 bytes)
21/12/17 14:24:00 INFO TaskSetManager: Starting task 2.0 in stage 10.0 (TID 12, localhost, executor driver, partition 2, PROCESS_LOCAL, 9059 bytes)
21/12/17 14:24:00 INFO TaskSetManager: Starting task 3.0 in stage 10.0 (TID 13, localhost, executor driver, partition 3, PROCESS_LOCAL, 9059 bytes)
21/12/17 14:24:00 INFO TaskSetManager: Starting task 4.0 in stage 10.0 (TID 14, localhost, executor driver, partition 4, PROCESS_LOCAL, 9059 bytes)
21/12/17 14:24:00 INFO TaskSetManager: Starting task 5.0 in stage 10.0 (TID 15, localhost, executor driver, partition 5, PROCESS_LOCAL, 9059 bytes)
21/12/17 14:24:00 INFO TaskSetManager: Starting task 6.0 in stage 10.0 (TID 16, localhost, executor driver, partition 6, PROCESS_LOCAL, 9059 bytes)
21/12/17 14:24:00 INFO TaskSetManager: Starting task 7.0 in stage 10.0 (TID 17, localhost, executor driver, partition 7, PROCESS_LOCAL, 9059 bytes)
21/12/17 14:24:00 INFO Executor: Running task 0.0 in stage 10.0 (TID 10)
21/12/17 14:24:00 INFO Executor: Running task 3.0 in stage 10.0 (TID 13)
21/12/17 14:24:00 INFO Executor: Running task 6.0 in stage 10.0 (TID 16)
21/12/17 14:24:00 INFO Executor: Running task 2.0 in stage 10.0 (TID 12)
21/12/17 14:24:00 INFO Executor: Running task 5.0 in stage 10.0 (TID 15)
21/12/17 14:24:00 INFO Executor: Running task 4.0 in stage 10.0 (TID 14)
21/12/17 14:24:00 INFO Executor: Running task 1.0 in stage 10.0 (TID 11)
21/12/17 14:24:00 INFO Executor: Running task 7.0 in stage 10.0 (TID 17)
21/12/17 14:24:00 INFO CodeGenerator: Code generated in 25.9784 ms
21/12/17 14:24:00 INFO CodeGenerator: Code generated in 60.5404 ms
21/12/17 14:24:00 INFO Executor: Finished task 5.0 in stage 10.0 (TID 15). 1153 bytes result sent to driver
21/12/17 14:24:00 INFO Executor: Finished task 6.0 in stage 10.0 (TID 16). 1191 bytes result sent to driver
21/12/17 14:24:00 INFO Executor: Finished task 0.0 in stage 10.0 (TID 10). 1190 bytes result sent to driver
21/12/17 14:24:00 INFO Executor: Finished task 3.0 in stage 10.0 (TID 13). 1152 bytes result sent to driver
21/12/17 14:24:00 INFO Executor: Finished task 4.0 in stage 10.0 (TID 14). 1275 bytes result sent to driver
21/12/17 14:24:00 INFO Executor: Finished task 1.0 in stage 10.0 (TID 11). 1193 bytes result sent to driver
21/12/17 14:24:00 INFO TaskSetManager: Finished task 5.0 in stage 10.0 (TID 15) in 119 ms on localhost (executor driver) (1/8)
21/12/17 14:24:00 INFO Executor: Finished task 2.0 in stage 10.0 (TID 12). 1235 bytes result sent to driver
21/12/17 14:24:00 INFO TaskSetManager: Finished task 6.0 in stage 10.0 (TID 16) in 121 ms on localhost (executor driver) (2/8)
21/12/17 14:24:00 INFO Executor: Finished task 7.0 in stage 10.0 (TID 17). 1150 bytes result sent to driver
21/12/17 14:24:00 INFO TaskSetManager: Finished task 4.0 in stage 10.0 (TID 14) in 129 ms on localhost (executor driver) (3/8)
21/12/17 14:24:00 INFO TaskSetManager: Finished task 2.0 in stage 10.0 (TID 12) in 132 ms on localhost (executor driver) (4/8)
21/12/17 14:24:00 INFO TaskSetManager: Finished task 7.0 in stage 10.0 (TID 17) in 129 ms on localhost (executor driver) (5/8)
21/12/17 14:24:00 INFO TaskSetManager: Finished task 3.0 in stage 10.0 (TID 13) in 134 ms on localhost (executor driver) (6/8)
21/12/17 14:24:00 INFO TaskSetManager: Finished task 1.0 in stage 10.0 (TID 11) in 138 ms on localhost (executor driver) (7/8)
21/12/17 14:24:00 INFO TaskSetManager: Finished task 0.0 in stage 10.0 (TID 10) in 143 ms on localhost (executor driver) (8/8)
21/12/17 14:24:00 INFO DAGScheduler: ResultStage 10 (collect at utils.scala:24) finished in 0.170 s
21/12/17 14:24:00 INFO TaskSchedulerImpl: Removed TaskSet 10.0, whose tasks have all completed, from pool 
21/12/17 14:24:00 INFO DAGScheduler: Job 8 finished: collect at utils.scala:24, took 0.172834 s
21/12/17 14:24:06 INFO HiveMetaStore: 0: get_database: default
21/12/17 14:24:06 INFO audit: ugi=uhp07025	ip=unknown-ip-addr	cmd=get_database: default	
21/12/17 14:24:06 INFO HiveMetaStore: 0: get_database: default
21/12/17 14:24:06 INFO audit: ugi=uhp07025	ip=unknown-ip-addr	cmd=get_database: default	
21/12/17 14:24:06 INFO SparkContext: Starting job: collect at utils.scala:24
21/12/17 14:24:06 INFO DAGScheduler: Registering RDD 44 (collect at utils.scala:24)
21/12/17 14:24:06 INFO DAGScheduler: Got job 9 (collect at utils.scala:24) with 1 output partitions
21/12/17 14:24:06 INFO DAGScheduler: Final stage: ResultStage 12 (collect at utils.scala:24)
21/12/17 14:24:06 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 11)
21/12/17 14:24:06 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 11)
21/12/17 14:24:06 INFO DAGScheduler: Submitting ShuffleMapStage 11 (MapPartitionsRDD[44] at collect at utils.scala:24), which has no missing parents
21/12/17 14:24:06 INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 9.3 KB, free 912.2 MB)
21/12/17 14:24:06 INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 4.8 KB, free 912.2 MB)
21/12/17 14:24:06 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on kubernetes.docker.internal:50990 (size: 4.8 KB, free: 912.3 MB)
21/12/17 14:24:06 INFO SparkContext: Created broadcast 11 from broadcast at DAGScheduler.scala:1039
21/12/17 14:24:06 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 11 (MapPartitionsRDD[44] at collect at utils.scala:24) (first 15 tasks are for partitions Vector(0))
21/12/17 14:24:06 INFO TaskSchedulerImpl: Adding task set 11.0 with 1 tasks
21/12/17 14:24:06 INFO TaskSetManager: Starting task 0.0 in stage 11.0 (TID 18, localhost, executor driver, partition 0, PROCESS_LOCAL, 11603 bytes)
21/12/17 14:24:06 INFO Executor: Running task 0.0 in stage 11.0 (TID 18)
21/12/17 14:24:06 INFO Executor: Finished task 0.0 in stage 11.0 (TID 18). 1473 bytes result sent to driver
21/12/17 14:24:06 INFO TaskSetManager: Finished task 0.0 in stage 11.0 (TID 18) in 18 ms on localhost (executor driver) (1/1)
21/12/17 14:24:06 INFO TaskSchedulerImpl: Removed TaskSet 11.0, whose tasks have all completed, from pool 
21/12/17 14:24:06 INFO DAGScheduler: ShuffleMapStage 11 (collect at utils.scala:24) finished in 0.024 s
21/12/17 14:24:06 INFO DAGScheduler: looking for newly runnable stages
21/12/17 14:24:06 INFO DAGScheduler: running: Set()
21/12/17 14:24:06 INFO DAGScheduler: waiting: Set(ResultStage 12)
21/12/17 14:24:06 INFO DAGScheduler: failed: Set()
21/12/17 14:24:06 INFO DAGScheduler: Submitting ResultStage 12 (MapPartitionsRDD[48] at collect at utils.scala:24), which has no missing parents
21/12/17 14:24:06 INFO MemoryStore: Block broadcast_12 stored as values in memory (estimated size 7.6 KB, free 912.2 MB)
21/12/17 14:24:06 INFO MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 3.9 KB, free 912.2 MB)
21/12/17 14:24:06 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on kubernetes.docker.internal:50990 (size: 3.9 KB, free: 912.3 MB)
21/12/17 14:24:06 INFO SparkContext: Created broadcast 12 from broadcast at DAGScheduler.scala:1039
21/12/17 14:24:06 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 12 (MapPartitionsRDD[48] at collect at utils.scala:24) (first 15 tasks are for partitions Vector(0))
21/12/17 14:24:06 INFO TaskSchedulerImpl: Adding task set 12.0 with 1 tasks
21/12/17 14:24:06 INFO TaskSetManager: Starting task 0.0 in stage 12.0 (TID 19, localhost, executor driver, partition 0, ANY, 7754 bytes)
21/12/17 14:24:06 INFO Executor: Running task 0.0 in stage 12.0 (TID 19)
21/12/17 14:24:06 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
21/12/17 14:24:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
21/12/17 14:24:06 INFO Executor: Finished task 0.0 in stage 12.0 (TID 19). 1557 bytes result sent to driver
21/12/17 14:24:06 INFO TaskSetManager: Finished task 0.0 in stage 12.0 (TID 19) in 12 ms on localhost (executor driver) (1/1)
21/12/17 14:24:06 INFO TaskSchedulerImpl: Removed TaskSet 12.0, whose tasks have all completed, from pool 
21/12/17 14:24:06 INFO DAGScheduler: ResultStage 12 (collect at utils.scala:24) finished in 0.020 s
21/12/17 14:24:06 INFO DAGScheduler: Job 9 finished: collect at utils.scala:24, took 0.049604 s
21/12/17 14:24:07 INFO SparkContext: Starting job: collect at utils.scala:24
21/12/17 14:24:07 INFO DAGScheduler: Got job 10 (collect at utils.scala:24) with 1 output partitions
21/12/17 14:24:07 INFO DAGScheduler: Final stage: ResultStage 13 (collect at utils.scala:24)
21/12/17 14:24:07 INFO DAGScheduler: Parents of final stage: List()
21/12/17 14:24:07 INFO DAGScheduler: Missing parents: List()
21/12/17 14:24:07 INFO DAGScheduler: Submitting ResultStage 13 (MapPartitionsRDD[51] at collect at utils.scala:24), which has no missing parents
21/12/17 14:24:07 INFO MemoryStore: Block broadcast_13 stored as values in memory (estimated size 6.4 KB, free 912.2 MB)
21/12/17 14:24:07 INFO MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 3.2 KB, free 912.2 MB)
21/12/17 14:24:07 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on kubernetes.docker.internal:50990 (size: 3.2 KB, free: 912.3 MB)
21/12/17 14:24:07 INFO SparkContext: Created broadcast 13 from broadcast at DAGScheduler.scala:1039
21/12/17 14:24:07 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 13 (MapPartitionsRDD[51] at collect at utils.scala:24) (first 15 tasks are for partitions Vector(0))
21/12/17 14:24:07 INFO TaskSchedulerImpl: Adding task set 13.0 with 1 tasks
21/12/17 14:24:07 INFO TaskSetManager: Starting task 0.0 in stage 13.0 (TID 20, localhost, executor driver, partition 0, PROCESS_LOCAL, 8067 bytes)
21/12/17 14:24:07 INFO Executor: Running task 0.0 in stage 13.0 (TID 20)
21/12/17 14:24:07 INFO Executor: Finished task 0.0 in stage 13.0 (TID 20). 1200 bytes result sent to driver
21/12/17 14:24:07 INFO TaskSetManager: Finished task 0.0 in stage 13.0 (TID 20) in 4 ms on localhost (executor driver) (1/1)
21/12/17 14:24:07 INFO TaskSchedulerImpl: Removed TaskSet 13.0, whose tasks have all completed, from pool 
21/12/17 14:24:07 INFO DAGScheduler: ResultStage 13 (collect at utils.scala:24) finished in 0.011 s
21/12/17 14:24:07 INFO DAGScheduler: Job 10 finished: collect at utils.scala:24, took 0.015973 s
21/12/17 14:24:08 INFO SparkContext: Starting job: aggregate at samplingutils.scala:37
21/12/17 14:24:08 INFO DAGScheduler: Got job 11 (aggregate at samplingutils.scala:37) with 1 output partitions
21/12/17 14:24:08 INFO DAGScheduler: Final stage: ResultStage 14 (aggregate at samplingutils.scala:37)
21/12/17 14:24:08 INFO DAGScheduler: Parents of final stage: List()
21/12/17 14:24:08 INFO DAGScheduler: Missing parents: List()
21/12/17 14:24:08 INFO DAGScheduler: Submitting ResultStage 14 (MapPartitionsRDD[55] at rdd at NativeMethodAccessorImpl.java:0), which has no missing parents
21/12/17 14:24:08 INFO MemoryStore: Block broadcast_14 stored as values in memory (estimated size 11.3 KB, free 912.2 MB)
21/12/17 14:24:08 INFO MemoryStore: Block broadcast_14_piece0 stored as bytes in memory (estimated size 5.6 KB, free 912.2 MB)
21/12/17 14:24:08 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on kubernetes.docker.internal:50990 (size: 5.6 KB, free: 912.3 MB)
21/12/17 14:24:08 INFO SparkContext: Created broadcast 14 from broadcast at DAGScheduler.scala:1039
21/12/17 14:24:08 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 14 (MapPartitionsRDD[55] at rdd at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
21/12/17 14:24:08 INFO TaskSchedulerImpl: Adding task set 14.0 with 1 tasks
21/12/17 14:24:08 INFO TaskSetManager: Starting task 0.0 in stage 14.0 (TID 21, localhost, executor driver, partition 0, PROCESS_LOCAL, 11614 bytes)
21/12/17 14:24:08 INFO Executor: Running task 0.0 in stage 14.0 (TID 21)
21/12/17 14:24:08 INFO Executor: Finished task 0.0 in stage 14.0 (TID 21). 4616 bytes result sent to driver
21/12/17 14:24:08 INFO TaskSetManager: Finished task 0.0 in stage 14.0 (TID 21) in 7 ms on localhost (executor driver) (1/1)
21/12/17 14:24:08 INFO TaskSchedulerImpl: Removed TaskSet 14.0, whose tasks have all completed, from pool 
21/12/17 14:24:08 INFO DAGScheduler: ResultStage 14 (aggregate at samplingutils.scala:37) finished in 0.015 s
21/12/17 14:24:08 INFO DAGScheduler: Job 11 finished: aggregate at samplingutils.scala:37, took 0.018310 s
21/12/17 14:24:08 INFO SparkContext: Starting job: collect at utils.scala:24
21/12/17 14:24:08 INFO DAGScheduler: Got job 12 (collect at utils.scala:24) with 1 output partitions
21/12/17 14:24:08 INFO DAGScheduler: Final stage: ResultStage 15 (collect at utils.scala:24)
21/12/17 14:24:08 INFO DAGScheduler: Parents of final stage: List()
21/12/17 14:24:08 INFO DAGScheduler: Missing parents: List()
21/12/17 14:24:08 INFO DAGScheduler: Submitting ResultStage 15 (MapPartitionsRDD[60] at collect at utils.scala:24), which has no missing parents
21/12/17 14:24:08 INFO MemoryStore: Block broadcast_15 stored as values in memory (estimated size 6.4 KB, free 912.2 MB)
21/12/17 14:24:08 INFO MemoryStore: Block broadcast_15_piece0 stored as bytes in memory (estimated size 3.2 KB, free 912.2 MB)
21/12/17 14:24:08 INFO BlockManagerInfo: Added broadcast_15_piece0 in memory on kubernetes.docker.internal:50990 (size: 3.2 KB, free: 912.2 MB)
21/12/17 14:24:08 INFO SparkContext: Created broadcast 15 from broadcast at DAGScheduler.scala:1039
21/12/17 14:24:08 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 15 (MapPartitionsRDD[60] at collect at utils.scala:24) (first 15 tasks are for partitions Vector(0))
21/12/17 14:24:08 INFO TaskSchedulerImpl: Adding task set 15.0 with 1 tasks
21/12/17 14:24:08 INFO TaskSetManager: Starting task 0.0 in stage 15.0 (TID 22, localhost, executor driver, partition 0, PROCESS_LOCAL, 8067 bytes)
21/12/17 14:24:08 INFO Executor: Running task 0.0 in stage 15.0 (TID 22)
21/12/17 14:24:08 INFO Executor: Finished task 0.0 in stage 15.0 (TID 22). 1243 bytes result sent to driver
21/12/17 14:24:08 INFO TaskSetManager: Finished task 0.0 in stage 15.0 (TID 22) in 7 ms on localhost (executor driver) (1/1)
21/12/17 14:24:08 INFO TaskSchedulerImpl: Removed TaskSet 15.0, whose tasks have all completed, from pool 
21/12/17 14:24:08 INFO DAGScheduler: ResultStage 15 (collect at utils.scala:24) finished in 0.018 s
21/12/17 14:24:08 INFO DAGScheduler: Job 12 finished: collect at utils.scala:24, took 0.020475 s
21/12/17 14:24:08 INFO SparkContext: Starting job: collect at utils.scala:24
21/12/17 14:24:08 INFO DAGScheduler: Got job 13 (collect at utils.scala:24) with 8 output partitions
21/12/17 14:24:08 INFO DAGScheduler: Final stage: ResultStage 16 (collect at utils.scala:24)
21/12/17 14:24:08 INFO DAGScheduler: Parents of final stage: List()
21/12/17 14:24:08 INFO DAGScheduler: Missing parents: List()
21/12/17 14:24:08 INFO DAGScheduler: Submitting ResultStage 16 (MapPartitionsRDD[62] at collect at utils.scala:24), which has no missing parents
21/12/17 14:24:08 INFO MemoryStore: Block broadcast_16 stored as values in memory (estimated size 8.0 KB, free 912.1 MB)
21/12/17 14:24:08 INFO MemoryStore: Block broadcast_16_piece0 stored as bytes in memory (estimated size 4.4 KB, free 912.1 MB)
21/12/17 14:24:08 INFO BlockManagerInfo: Added broadcast_16_piece0 in memory on kubernetes.docker.internal:50990 (size: 4.4 KB, free: 912.2 MB)
21/12/17 14:24:08 INFO SparkContext: Created broadcast 16 from broadcast at DAGScheduler.scala:1039
21/12/17 14:24:08 INFO DAGScheduler: Submitting 8 missing tasks from ResultStage 16 (MapPartitionsRDD[62] at collect at utils.scala:24) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))
21/12/17 14:24:08 INFO TaskSchedulerImpl: Adding task set 16.0 with 8 tasks
21/12/17 14:24:08 INFO TaskSetManager: Starting task 0.0 in stage 16.0 (TID 23, localhost, executor driver, partition 0, PROCESS_LOCAL, 9059 bytes)
21/12/17 14:24:08 INFO TaskSetManager: Starting task 1.0 in stage 16.0 (TID 24, localhost, executor driver, partition 1, PROCESS_LOCAL, 9059 bytes)
21/12/17 14:24:08 INFO TaskSetManager: Starting task 2.0 in stage 16.0 (TID 25, localhost, executor driver, partition 2, PROCESS_LOCAL, 9059 bytes)
21/12/17 14:24:08 INFO TaskSetManager: Starting task 3.0 in stage 16.0 (TID 26, localhost, executor driver, partition 3, PROCESS_LOCAL, 9059 bytes)
21/12/17 14:24:08 INFO TaskSetManager: Starting task 4.0 in stage 16.0 (TID 27, localhost, executor driver, partition 4, PROCESS_LOCAL, 9059 bytes)
21/12/17 14:24:08 INFO TaskSetManager: Starting task 5.0 in stage 16.0 (TID 28, localhost, executor driver, partition 5, PROCESS_LOCAL, 9059 bytes)
21/12/17 14:24:08 INFO TaskSetManager: Starting task 6.0 in stage 16.0 (TID 29, localhost, executor driver, partition 6, PROCESS_LOCAL, 9059 bytes)
21/12/17 14:24:08 INFO TaskSetManager: Starting task 7.0 in stage 16.0 (TID 30, localhost, executor driver, partition 7, PROCESS_LOCAL, 9059 bytes)
21/12/17 14:24:08 INFO Executor: Running task 1.0 in stage 16.0 (TID 24)
21/12/17 14:24:08 INFO Executor: Running task 0.0 in stage 16.0 (TID 23)
21/12/17 14:24:08 INFO Executor: Running task 3.0 in stage 16.0 (TID 26)
21/12/17 14:24:08 INFO Executor: Running task 6.0 in stage 16.0 (TID 29)
21/12/17 14:24:08 INFO Executor: Running task 5.0 in stage 16.0 (TID 28)
21/12/17 14:24:08 INFO Executor: Running task 4.0 in stage 16.0 (TID 27)
21/12/17 14:24:08 INFO Executor: Finished task 4.0 in stage 16.0 (TID 27). 1191 bytes result sent to driver
21/12/17 14:24:08 INFO Executor: Running task 2.0 in stage 16.0 (TID 25)
21/12/17 14:24:08 INFO Executor: Finished task 1.0 in stage 16.0 (TID 24). 1229 bytes result sent to driver
21/12/17 14:24:08 INFO Executor: Finished task 0.0 in stage 16.0 (TID 23). 1151 bytes result sent to driver
21/12/17 14:24:08 INFO Executor: Running task 7.0 in stage 16.0 (TID 30)
21/12/17 14:24:08 INFO Executor: Finished task 6.0 in stage 16.0 (TID 29). 1194 bytes result sent to driver
21/12/17 14:24:08 INFO TaskSetManager: Finished task 1.0 in stage 16.0 (TID 24) in 14 ms on localhost (executor driver) (1/8)
21/12/17 14:24:08 INFO TaskSetManager: Finished task 6.0 in stage 16.0 (TID 29) in 12 ms on localhost (executor driver) (2/8)
21/12/17 14:24:08 INFO Executor: Finished task 3.0 in stage 16.0 (TID 26). 1190 bytes result sent to driver
21/12/17 14:24:08 INFO TaskSetManager: Finished task 4.0 in stage 16.0 (TID 27) in 14 ms on localhost (executor driver) (3/8)
21/12/17 14:24:08 INFO Executor: Finished task 5.0 in stage 16.0 (TID 28). 1150 bytes result sent to driver
21/12/17 14:24:08 INFO TaskSetManager: Finished task 0.0 in stage 16.0 (TID 23) in 15 ms on localhost (executor driver) (4/8)
21/12/17 14:24:08 INFO Executor: Finished task 2.0 in stage 16.0 (TID 25). 1150 bytes result sent to driver
21/12/17 14:24:08 INFO TaskSetManager: Finished task 3.0 in stage 16.0 (TID 26) in 15 ms on localhost (executor driver) (5/8)
21/12/17 14:24:08 INFO TaskSetManager: Finished task 5.0 in stage 16.0 (TID 28) in 16 ms on localhost (executor driver) (6/8)
21/12/17 14:24:08 INFO TaskSetManager: Finished task 2.0 in stage 16.0 (TID 25) in 17 ms on localhost (executor driver) (7/8)
21/12/17 14:24:08 INFO Executor: Finished task 7.0 in stage 16.0 (TID 30). 1145 bytes result sent to driver
21/12/17 14:24:08 INFO TaskSetManager: Finished task 7.0 in stage 16.0 (TID 30) in 16 ms on localhost (executor driver) (8/8)
21/12/17 14:24:08 INFO TaskSchedulerImpl: Removed TaskSet 16.0, whose tasks have all completed, from pool 
21/12/17 14:24:08 INFO DAGScheduler: ResultStage 16 (collect at utils.scala:24) finished in 0.025 s
21/12/17 14:24:08 INFO DAGScheduler: Job 13 finished: collect at utils.scala:24, took 0.026758 s
21/12/17 14:25:25 INFO CodeGenerator: Code generated in 8.2539 ms
21/12/17 14:25:25 INFO CodeGenerator: Code generated in 47.1254 ms
21/12/17 14:25:25 INFO SparkContext: Starting job: first at LinearRegression.scala:319
21/12/17 14:25:25 INFO DAGScheduler: Got job 14 (first at LinearRegression.scala:319) with 1 output partitions
21/12/17 14:25:25 INFO DAGScheduler: Final stage: ResultStage 17 (first at LinearRegression.scala:319)
21/12/17 14:25:25 INFO DAGScheduler: Parents of final stage: List()
21/12/17 14:25:25 INFO DAGScheduler: Missing parents: List()
21/12/17 14:25:25 INFO DAGScheduler: Submitting ResultStage 17 (MapPartitionsRDD[67] at first at LinearRegression.scala:319), which has no missing parents
21/12/17 14:25:25 INFO MemoryStore: Block broadcast_17 stored as values in memory (estimated size 36.3 KB, free 912.1 MB)
21/12/17 14:25:25 INFO MemoryStore: Block broadcast_17_piece0 stored as bytes in memory (estimated size 13.8 KB, free 912.1 MB)
21/12/17 14:25:25 INFO BlockManagerInfo: Added broadcast_17_piece0 in memory on kubernetes.docker.internal:50990 (size: 13.8 KB, free: 912.2 MB)
21/12/17 14:25:25 INFO SparkContext: Created broadcast 17 from broadcast at DAGScheduler.scala:1039
21/12/17 14:25:25 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 17 (MapPartitionsRDD[67] at first at LinearRegression.scala:319) (first 15 tasks are for partitions Vector(0))
21/12/17 14:25:25 INFO TaskSchedulerImpl: Adding task set 17.0 with 1 tasks
21/12/17 14:25:25 INFO TaskSetManager: Starting task 0.0 in stage 17.0 (TID 31, localhost, executor driver, partition 0, PROCESS_LOCAL, 11614 bytes)
21/12/17 14:25:25 INFO Executor: Running task 0.0 in stage 17.0 (TID 31)
21/12/17 14:25:25 INFO BlockManager: Found block rdd_6_0 locally
21/12/17 14:25:25 INFO Executor: 1 block locks were not released by TID = 31:
[rdd_6_0]
21/12/17 14:25:25 INFO Executor: Finished task 0.0 in stage 17.0 (TID 31). 1415 bytes result sent to driver
21/12/17 14:25:25 INFO TaskSetManager: Finished task 0.0 in stage 17.0 (TID 31) in 105 ms on localhost (executor driver) (1/1)
21/12/17 14:25:25 INFO TaskSchedulerImpl: Removed TaskSet 17.0, whose tasks have all completed, from pool 
21/12/17 14:25:25 INFO DAGScheduler: ResultStage 17 (first at LinearRegression.scala:319) finished in 0.120 s
21/12/17 14:25:25 INFO DAGScheduler: Job 14 finished: first at LinearRegression.scala:319, took 0.128864 s
21/12/17 14:25:25 INFO CodeGenerator: Code generated in 30.5364 ms
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 494
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 405
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 324
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 475
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 253
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 502
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 219
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 330
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 262
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 424
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 221
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 450
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 478
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 236
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 281
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 191
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 312
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 207
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 509
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 279
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 306
21/12/17 14:25:25 INFO BlockManagerInfo: Removed broadcast_13_piece0 on kubernetes.docker.internal:50990 in memory (size: 3.2 KB, free: 912.2 MB)
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 348
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 230
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 504
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 296
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 359
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 169
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 335
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 371
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 332
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 217
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 445
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 283
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 522
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 448
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 204
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 499
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 153
21/12/17 14:25:25 INFO BlockManagerInfo: Removed broadcast_9_piece0 on kubernetes.docker.internal:50990 in memory (size: 3.2 KB, free: 912.2 MB)
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 286
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 469
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 163
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 458
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 209
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 347
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 418
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 247
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 317
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 354
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 224
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 395
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 311
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 487
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 160
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 258
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 239
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 194
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 360
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 299
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 431
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 365
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 233
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 198
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 210
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 465
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 178
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 184
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 380
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 481
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 199
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 203
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 201
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 172
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 211
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 270
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 436
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 523
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 342
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 368
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 232
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 318
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 353
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 437
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 427
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 390
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 423
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 251
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 301
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 261
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 417
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 274
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 193
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 267
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 491
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 288
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 265
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 263
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 429
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 291
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 515
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 214
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 208
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 176
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 249
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 364
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 154
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 356
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 213
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 483
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 308
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 414
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 238
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 245
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 331
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 316
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 451
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 466
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 517
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 480
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 287
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 396
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 185
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 200
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 206
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 434
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 482
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 337
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 362
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 244
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 173
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 428
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 422
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 439
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 212
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 420
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 260
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 254
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 455
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 181
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 166
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 180
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 197
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 290
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 304
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 192
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 463
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 464
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 514
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 485
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 508
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 159
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 179
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 241
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 216
21/12/17 14:25:25 INFO BlockManagerInfo: Removed broadcast_8_piece0 on kubernetes.docker.internal:50990 in memory (size: 5.6 KB, free: 912.2 MB)
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 398
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 443
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 313
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 234
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 386
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 358
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 430
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 521
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 186
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 446
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 276
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 389
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 272
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 375
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 322
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 407
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 376
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 467
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 168
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 246
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 361
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 374
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 410
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 256
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 298
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 273
21/12/17 14:25:25 INFO BlockManagerInfo: Removed broadcast_7_piece0 on kubernetes.docker.internal:50990 in memory (size: 3.2 KB, free: 912.2 MB)
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 252
21/12/17 14:25:25 INFO BlockManagerInfo: Removed broadcast_15_piece0 on kubernetes.docker.internal:50990 in memory (size: 3.2 KB, free: 912.2 MB)
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 294
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 369
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 453
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 496
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 512
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 388
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 474
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 459
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 495
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 155
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 519
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 486
21/12/17 14:25:25 INFO BlockManagerInfo: Removed broadcast_17_piece0 on kubernetes.docker.internal:50990 in memory (size: 13.8 KB, free: 912.3 MB)
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 355
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 314
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 370
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 164
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 305
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 320
21/12/17 14:25:25 INFO BlockManagerInfo: Removed broadcast_5_piece0 on kubernetes.docker.internal:50990 in memory (size: 4.8 KB, free: 912.3 MB)
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 188
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 385
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 473
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 484
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 229
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 349
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 498
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 447
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 505
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 174
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 456
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 275
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 310
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 440
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 220
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 421
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 500
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 329
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 492
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 372
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 393
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 328
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 325
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 479
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 237
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 302
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 167
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 452
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 470
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 391
21/12/17 14:25:25 INFO BlockManagerInfo: Removed broadcast_14_piece0 on kubernetes.docker.internal:50990 in memory (size: 5.6 KB, free: 912.3 MB)
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 309
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 379
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 363
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 334
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 506
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 240
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 366
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 461
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 333
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 351
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 401
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 462
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 285
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 399
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 426
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 520
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 457
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 336
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 218
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 319
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 409
21/12/17 14:25:25 INFO BlockManagerInfo: Removed broadcast_11_piece0 on kubernetes.docker.internal:50990 in memory (size: 4.8 KB, free: 912.3 MB)
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 383
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 259
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 327
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 471
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 350
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 228
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 507
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 419
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 493
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 441
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 278
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 307
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 442
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 271
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 340
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 227
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 367
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 438
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 235
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 392
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 268
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 384
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 382
21/12/17 14:25:25 INFO BlockManagerInfo: Removed broadcast_10_piece0 on kubernetes.docker.internal:50990 in memory (size: 4.4 KB, free: 912.3 MB)
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 503
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 315
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 345
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 510
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 416
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 411
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 346
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 490
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 406
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 425
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 378
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 321
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 226
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 284
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 165
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 158
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 303
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 196
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 171
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 157
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 161
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 205
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 449
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 175
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 177
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 182
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 223
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 373
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 402
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 189
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 280
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 293
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 341
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 404
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 513
21/12/17 14:25:25 INFO BlockManagerInfo: Removed broadcast_12_piece0 on kubernetes.docker.internal:50990 in memory (size: 3.9 KB, free: 912.3 MB)
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 202
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 243
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 269
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 282
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 338
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 187
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 412
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 222
21/12/17 14:25:25 INFO ContextCleaner: Cleaned shuffle 2
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 231
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 190
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 435
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 476
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 344
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 501
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 394
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 156
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 255
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 497
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 326
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 295
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 415
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 400
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 297
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 460
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 352
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 489
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 242
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 408
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 343
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 183
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 250
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 488
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 444
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 518
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 377
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 516
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 248
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 289
21/12/17 14:25:25 INFO BlockManagerInfo: Removed broadcast_6_piece0 on kubernetes.docker.internal:50990 in memory (size: 3.9 KB, free: 912.3 MB)
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 403
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 433
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 413
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 472
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 170
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 323
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 339
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 195
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 162
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 292
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 511
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 468
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 266
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 215
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 397
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 454
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 357
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 387
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 300
21/12/17 14:25:25 INFO BlockManagerInfo: Removed broadcast_16_piece0 on kubernetes.docker.internal:50990 in memory (size: 4.4 KB, free: 912.3 MB)
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 264
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 225
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 381
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 257
21/12/17 14:25:25 INFO ContextCleaner: Cleaned shuffle 1
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 432
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 477
21/12/17 14:25:25 INFO ContextCleaner: Cleaned accumulator 277
21/12/17 14:25:25 INFO CodeGenerator: Code generated in 29.5674 ms
21/12/17 14:25:25 INFO Instrumentation: LinearRegression-linear_regression__f9d81227_5145_4324_93ca_44aefc421289-420631082-1: training: numPartitions=1 storageLevel=StorageLevel(1 replicas)
21/12/17 14:25:25 INFO Instrumentation: LinearRegression-linear_regression__f9d81227_5145_4324_93ca_44aefc421289-420631082-1: {"elasticNetParam":0.0,"featuresCol":"features","fitIntercept":true,"solver":"auto","labelCol":"label","predictionCol":"prediction","standardization":true,"loss":"squaredError","regParam":0.0,"tol":1.0E-6,"maxIter":100}
21/12/17 14:25:25 INFO Instrumentation: LinearRegression-linear_regression__f9d81227_5145_4324_93ca_44aefc421289-420631082-1: {"numFeatures":1}
21/12/17 14:25:25 WARN WeightedLeastSquares: regParam is zero, which might cause numerical instability and overfitting.
21/12/17 14:25:25 INFO SparkContext: Starting job: treeAggregate at WeightedLeastSquares.scala:100
21/12/17 14:25:25 INFO DAGScheduler: Got job 15 (treeAggregate at WeightedLeastSquares.scala:100) with 1 output partitions
21/12/17 14:25:25 INFO DAGScheduler: Final stage: ResultStage 18 (treeAggregate at WeightedLeastSquares.scala:100)
21/12/17 14:25:25 INFO DAGScheduler: Parents of final stage: List()
21/12/17 14:25:25 INFO DAGScheduler: Missing parents: List()
21/12/17 14:25:25 INFO DAGScheduler: Submitting ResultStage 18 (MapPartitionsRDD[79] at treeAggregate at WeightedLeastSquares.scala:100), which has no missing parents
21/12/17 14:25:25 INFO MemoryStore: Block broadcast_18 stored as values in memory (estimated size 40.0 KB, free 912.2 MB)
21/12/17 14:25:25 INFO MemoryStore: Block broadcast_18_piece0 stored as bytes in memory (estimated size 15.6 KB, free 912.2 MB)
21/12/17 14:25:25 INFO BlockManagerInfo: Added broadcast_18_piece0 in memory on kubernetes.docker.internal:50990 (size: 15.6 KB, free: 912.3 MB)
21/12/17 14:25:25 INFO SparkContext: Created broadcast 18 from broadcast at DAGScheduler.scala:1039
21/12/17 14:25:25 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 18 (MapPartitionsRDD[79] at treeAggregate at WeightedLeastSquares.scala:100) (first 15 tasks are for partitions Vector(0))
21/12/17 14:25:25 INFO TaskSchedulerImpl: Adding task set 18.0 with 1 tasks
21/12/17 14:25:25 INFO TaskSetManager: Starting task 0.0 in stage 18.0 (TID 32, localhost, executor driver, partition 0, PROCESS_LOCAL, 11614 bytes)
21/12/17 14:25:25 INFO Executor: Running task 0.0 in stage 18.0 (TID 32)
21/12/17 14:25:25 INFO BlockManager: Found block rdd_6_0 locally
21/12/17 14:25:25 INFO CodeGenerator: Code generated in 6.4486 ms
21/12/17 14:25:25 WARN BLAS: Failed to load implementation from: com.github.fommil.netlib.NativeSystemBLAS
21/12/17 14:25:25 WARN BLAS: Failed to load implementation from: com.github.fommil.netlib.NativeRefBLAS
21/12/17 14:25:25 INFO Executor: Finished task 0.0 in stage 18.0 (TID 32). 1676 bytes result sent to driver
21/12/17 14:25:25 INFO TaskSetManager: Finished task 0.0 in stage 18.0 (TID 32) in 29 ms on localhost (executor driver) (1/1)
21/12/17 14:25:25 INFO TaskSchedulerImpl: Removed TaskSet 18.0, whose tasks have all completed, from pool 
21/12/17 14:25:25 INFO DAGScheduler: ResultStage 18 (treeAggregate at WeightedLeastSquares.scala:100) finished in 0.033 s
21/12/17 14:25:25 INFO DAGScheduler: Job 15 finished: treeAggregate at WeightedLeastSquares.scala:100, took 0.036116 s
21/12/17 14:25:25 INFO WeightedLeastSquares: Number of instances: 32.
21/12/17 14:25:25 WARN LAPACK: Failed to load implementation from: com.github.fommil.netlib.NativeSystemLAPACK
21/12/17 14:25:25 WARN LAPACK: Failed to load implementation from: com.github.fommil.netlib.NativeRefLAPACK
21/12/17 14:25:25 INFO CodeGenerator: Code generated in 13.91 ms
21/12/17 14:25:25 INFO SparkContext: Starting job: treeAggregate at RegressionMetrics.scala:57
21/12/17 14:25:25 INFO DAGScheduler: Got job 16 (treeAggregate at RegressionMetrics.scala:57) with 1 output partitions
21/12/17 14:25:25 INFO DAGScheduler: Final stage: ResultStage 19 (treeAggregate at RegressionMetrics.scala:57)
21/12/17 14:25:25 INFO DAGScheduler: Parents of final stage: List()
21/12/17 14:25:25 INFO DAGScheduler: Missing parents: List()
21/12/17 14:25:25 INFO DAGScheduler: Submitting ResultStage 19 (MapPartitionsRDD[87] at treeAggregate at RegressionMetrics.scala:57), which has no missing parents
21/12/17 14:25:25 INFO MemoryStore: Block broadcast_19 stored as values in memory (estimated size 40.1 KB, free 912.2 MB)
21/12/17 14:25:25 INFO MemoryStore: Block broadcast_19_piece0 stored as bytes in memory (estimated size 16.6 KB, free 912.2 MB)
21/12/17 14:25:25 INFO BlockManagerInfo: Added broadcast_19_piece0 in memory on kubernetes.docker.internal:50990 (size: 16.6 KB, free: 912.3 MB)
21/12/17 14:25:25 INFO SparkContext: Created broadcast 19 from broadcast at DAGScheduler.scala:1039
21/12/17 14:25:25 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 19 (MapPartitionsRDD[87] at treeAggregate at RegressionMetrics.scala:57) (first 15 tasks are for partitions Vector(0))
21/12/17 14:25:25 INFO TaskSchedulerImpl: Adding task set 19.0 with 1 tasks
21/12/17 14:25:25 INFO TaskSetManager: Starting task 0.0 in stage 19.0 (TID 33, localhost, executor driver, partition 0, PROCESS_LOCAL, 11614 bytes)
21/12/17 14:25:25 INFO Executor: Running task 0.0 in stage 19.0 (TID 33)
21/12/17 14:25:26 INFO BlockManager: Found block rdd_6_0 locally
21/12/17 14:25:26 INFO CodeGenerator: Code generated in 5.1667 ms
21/12/17 14:25:26 INFO Executor: Finished task 0.0 in stage 19.0 (TID 33). 1826 bytes result sent to driver
21/12/17 14:25:26 INFO TaskSetManager: Finished task 0.0 in stage 19.0 (TID 33) in 25 ms on localhost (executor driver) (1/1)
21/12/17 14:25:26 INFO TaskSchedulerImpl: Removed TaskSet 19.0, whose tasks have all completed, from pool 
21/12/17 14:25:26 INFO DAGScheduler: ResultStage 19 (treeAggregate at RegressionMetrics.scala:57) finished in 0.032 s
21/12/17 14:25:26 INFO DAGScheduler: Job 16 finished: treeAggregate at RegressionMetrics.scala:57, took 0.033461 s
21/12/17 14:25:26 INFO SparkContext: Starting job: sum at RegressionMetrics.scala:71
21/12/17 14:25:26 INFO DAGScheduler: Got job 17 (sum at RegressionMetrics.scala:71) with 1 output partitions
21/12/17 14:25:26 INFO DAGScheduler: Final stage: ResultStage 20 (sum at RegressionMetrics.scala:71)
21/12/17 14:25:26 INFO DAGScheduler: Parents of final stage: List()
21/12/17 14:25:26 INFO DAGScheduler: Missing parents: List()
21/12/17 14:25:26 INFO DAGScheduler: Submitting ResultStage 20 (MapPartitionsRDD[88] at map at RegressionMetrics.scala:69), which has no missing parents
21/12/17 14:25:26 INFO MemoryStore: Block broadcast_20 stored as values in memory (estimated size 39.2 KB, free 912.1 MB)
21/12/17 14:25:26 INFO MemoryStore: Block broadcast_20_piece0 stored as bytes in memory (estimated size 16.3 KB, free 912.1 MB)
21/12/17 14:25:26 INFO BlockManagerInfo: Added broadcast_20_piece0 in memory on kubernetes.docker.internal:50990 (size: 16.3 KB, free: 912.2 MB)
21/12/17 14:25:26 INFO SparkContext: Created broadcast 20 from broadcast at DAGScheduler.scala:1039
21/12/17 14:25:26 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 20 (MapPartitionsRDD[88] at map at RegressionMetrics.scala:69) (first 15 tasks are for partitions Vector(0))
21/12/17 14:25:26 INFO TaskSchedulerImpl: Adding task set 20.0 with 1 tasks
21/12/17 14:25:26 INFO TaskSetManager: Starting task 0.0 in stage 20.0 (TID 34, localhost, executor driver, partition 0, PROCESS_LOCAL, 11614 bytes)
21/12/17 14:25:26 INFO Executor: Running task 0.0 in stage 20.0 (TID 34)
21/12/17 14:25:26 INFO BlockManager: Found block rdd_6_0 locally
21/12/17 14:25:26 INFO Executor: Finished task 0.0 in stage 20.0 (TID 34). 1300 bytes result sent to driver
21/12/17 14:25:26 INFO TaskSetManager: Finished task 0.0 in stage 20.0 (TID 34) in 7 ms on localhost (executor driver) (1/1)
21/12/17 14:25:26 INFO TaskSchedulerImpl: Removed TaskSet 20.0, whose tasks have all completed, from pool 
21/12/17 14:25:26 INFO DAGScheduler: ResultStage 20 (sum at RegressionMetrics.scala:71) finished in 0.014 s
21/12/17 14:25:26 INFO DAGScheduler: Job 17 finished: sum at RegressionMetrics.scala:71, took 0.016905 s
21/12/17 14:25:26 INFO CodeGenerator: Code generated in 11.6936 ms
21/12/17 14:25:26 INFO SparkContext: Starting job: count at LinearRegression.scala:921
21/12/17 14:25:26 INFO DAGScheduler: Registering RDD 92 (count at LinearRegression.scala:921)
21/12/17 14:25:26 INFO DAGScheduler: Got job 18 (count at LinearRegression.scala:921) with 1 output partitions
21/12/17 14:25:26 INFO DAGScheduler: Final stage: ResultStage 22 (count at LinearRegression.scala:921)
21/12/17 14:25:26 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 21)
21/12/17 14:25:26 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 21)
21/12/17 14:25:26 INFO DAGScheduler: Submitting ShuffleMapStage 21 (MapPartitionsRDD[92] at count at LinearRegression.scala:921), which has no missing parents
21/12/17 14:25:26 INFO MemoryStore: Block broadcast_21 stored as values in memory (estimated size 24.8 KB, free 912.1 MB)
21/12/17 14:25:26 INFO MemoryStore: Block broadcast_21_piece0 stored as bytes in memory (estimated size 11.0 KB, free 912.1 MB)
21/12/17 14:25:26 INFO BlockManagerInfo: Added broadcast_21_piece0 in memory on kubernetes.docker.internal:50990 (size: 11.0 KB, free: 912.2 MB)
21/12/17 14:25:26 INFO SparkContext: Created broadcast 21 from broadcast at DAGScheduler.scala:1039
21/12/17 14:25:26 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 21 (MapPartitionsRDD[92] at count at LinearRegression.scala:921) (first 15 tasks are for partitions Vector(0))
21/12/17 14:25:26 INFO TaskSchedulerImpl: Adding task set 21.0 with 1 tasks
21/12/17 14:25:26 INFO TaskSetManager: Starting task 0.0 in stage 21.0 (TID 35, localhost, executor driver, partition 0, PROCESS_LOCAL, 11603 bytes)
21/12/17 14:25:26 INFO Executor: Running task 0.0 in stage 21.0 (TID 35)
21/12/17 14:25:26 INFO BlockManager: Found block rdd_6_0 locally
21/12/17 14:25:26 INFO Executor: Finished task 0.0 in stage 21.0 (TID 35). 1992 bytes result sent to driver
21/12/17 14:25:26 INFO TaskSetManager: Finished task 0.0 in stage 21.0 (TID 35) in 13 ms on localhost (executor driver) (1/1)
21/12/17 14:25:26 INFO TaskSchedulerImpl: Removed TaskSet 21.0, whose tasks have all completed, from pool 
21/12/17 14:25:26 INFO DAGScheduler: ShuffleMapStage 21 (count at LinearRegression.scala:921) finished in 0.018 s
21/12/17 14:25:26 INFO DAGScheduler: looking for newly runnable stages
21/12/17 14:25:26 INFO DAGScheduler: running: Set()
21/12/17 14:25:26 INFO DAGScheduler: waiting: Set(ResultStage 22)
21/12/17 14:25:26 INFO DAGScheduler: failed: Set()
21/12/17 14:25:26 INFO DAGScheduler: Submitting ResultStage 22 (MapPartitionsRDD[95] at count at LinearRegression.scala:921), which has no missing parents
21/12/17 14:25:26 INFO MemoryStore: Block broadcast_22 stored as values in memory (estimated size 7.5 KB, free 912.1 MB)
21/12/17 14:25:26 INFO MemoryStore: Block broadcast_22_piece0 stored as bytes in memory (estimated size 3.9 KB, free 912.1 MB)
21/12/17 14:25:26 INFO BlockManagerInfo: Added broadcast_22_piece0 in memory on kubernetes.docker.internal:50990 (size: 3.9 KB, free: 912.2 MB)
21/12/17 14:25:26 INFO SparkContext: Created broadcast 22 from broadcast at DAGScheduler.scala:1039
21/12/17 14:25:26 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 22 (MapPartitionsRDD[95] at count at LinearRegression.scala:921) (first 15 tasks are for partitions Vector(0))
21/12/17 14:25:26 INFO TaskSchedulerImpl: Adding task set 22.0 with 1 tasks
21/12/17 14:25:26 INFO TaskSetManager: Starting task 0.0 in stage 22.0 (TID 36, localhost, executor driver, partition 0, ANY, 7754 bytes)
21/12/17 14:25:26 INFO Executor: Running task 0.0 in stage 22.0 (TID 36)
21/12/17 14:25:26 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
21/12/17 14:25:26 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
21/12/17 14:25:26 INFO Executor: Finished task 0.0 in stage 22.0 (TID 36). 1696 bytes result sent to driver
21/12/17 14:25:26 INFO TaskSetManager: Finished task 0.0 in stage 22.0 (TID 36) in 5 ms on localhost (executor driver) (1/1)
21/12/17 14:25:26 INFO TaskSchedulerImpl: Removed TaskSet 22.0, whose tasks have all completed, from pool 
21/12/17 14:25:26 INFO DAGScheduler: ResultStage 22 (count at LinearRegression.scala:921) finished in 0.009 s
21/12/17 14:25:26 INFO DAGScheduler: Job 18 finished: count at LinearRegression.scala:921, took 0.028989 s
21/12/17 14:25:26 INFO Instrumentation: LinearRegression-linear_regression__f9d81227_5145_4324_93ca_44aefc421289-420631082-1: training finished
21/12/17 14:25:26 INFO CodeGenerator: Code generated in 5.7118 ms
21/12/17 14:25:26 INFO CodeGenerator: Code generated in 5.5149 ms
21/12/17 14:25:26 INFO SparkContext: Starting job: collect at utils.scala:24
21/12/17 14:25:26 INFO DAGScheduler: Got job 19 (collect at utils.scala:24) with 1 output partitions
21/12/17 14:25:26 INFO DAGScheduler: Final stage: ResultStage 23 (collect at utils.scala:24)
21/12/17 14:25:26 INFO DAGScheduler: Parents of final stage: List()
21/12/17 14:25:26 INFO DAGScheduler: Missing parents: List()
21/12/17 14:25:26 INFO DAGScheduler: Submitting ResultStage 23 (MapPartitionsRDD[98] at collect at utils.scala:24), which has no missing parents
21/12/17 14:25:26 INFO MemoryStore: Block broadcast_23 stored as values in memory (estimated size 6.9 KB, free 912.1 MB)
21/12/17 14:25:26 INFO MemoryStore: Block broadcast_23_piece0 stored as bytes in memory (estimated size 3.3 KB, free 912.1 MB)
21/12/17 14:25:26 INFO BlockManagerInfo: Added broadcast_23_piece0 in memory on kubernetes.docker.internal:50990 (size: 3.3 KB, free: 912.2 MB)
21/12/17 14:25:26 INFO SparkContext: Created broadcast 23 from broadcast at DAGScheduler.scala:1039
21/12/17 14:25:26 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 23 (MapPartitionsRDD[98] at collect at utils.scala:24) (first 15 tasks are for partitions Vector(0))
21/12/17 14:25:26 INFO TaskSchedulerImpl: Adding task set 23.0 with 1 tasks
21/12/17 14:25:26 INFO TaskSetManager: Starting task 0.0 in stage 23.0 (TID 37, localhost, executor driver, partition 0, PROCESS_LOCAL, 8067 bytes)
21/12/17 14:25:26 INFO Executor: Running task 0.0 in stage 23.0 (TID 37)
21/12/17 14:25:26 INFO Executor: Finished task 0.0 in stage 23.0 (TID 37). 1200 bytes result sent to driver
21/12/17 14:25:26 INFO TaskSetManager: Finished task 0.0 in stage 23.0 (TID 37) in 4 ms on localhost (executor driver) (1/1)
21/12/17 14:25:26 INFO TaskSchedulerImpl: Removed TaskSet 23.0, whose tasks have all completed, from pool 
21/12/17 14:25:26 INFO DAGScheduler: ResultStage 23 (collect at utils.scala:24) finished in 0.009 s
21/12/17 14:25:26 INFO DAGScheduler: Job 19 finished: collect at utils.scala:24, took 0.010972 s
21/12/17 14:25:26 INFO CodeGenerator: Code generated in 6.0363 ms
21/12/17 14:25:26 INFO CodeGenerator: Code generated in 7.9716 ms
21/12/17 14:25:26 INFO SparkContext: Starting job: collect at utils.scala:24
21/12/17 14:25:26 INFO DAGScheduler: Got job 20 (collect at utils.scala:24) with 1 output partitions
21/12/17 14:25:26 INFO DAGScheduler: Final stage: ResultStage 24 (collect at utils.scala:24)
21/12/17 14:25:26 INFO DAGScheduler: Parents of final stage: List()
21/12/17 14:25:26 INFO DAGScheduler: Missing parents: List()
21/12/17 14:25:26 INFO DAGScheduler: Submitting ResultStage 24 (MapPartitionsRDD[101] at collect at utils.scala:24), which has no missing parents
21/12/17 14:25:26 INFO MemoryStore: Block broadcast_24 stored as values in memory (estimated size 6.9 KB, free 912.1 MB)
21/12/17 14:25:26 INFO MemoryStore: Block broadcast_24_piece0 stored as bytes in memory (estimated size 3.3 KB, free 912.1 MB)
21/12/17 14:25:26 INFO BlockManagerInfo: Added broadcast_24_piece0 in memory on kubernetes.docker.internal:50990 (size: 3.3 KB, free: 912.2 MB)
21/12/17 14:25:26 INFO SparkContext: Created broadcast 24 from broadcast at DAGScheduler.scala:1039
21/12/17 14:25:26 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 24 (MapPartitionsRDD[101] at collect at utils.scala:24) (first 15 tasks are for partitions Vector(0))
21/12/17 14:25:26 INFO TaskSchedulerImpl: Adding task set 24.0 with 1 tasks
21/12/17 14:25:26 INFO TaskSetManager: Starting task 0.0 in stage 24.0 (TID 38, localhost, executor driver, partition 0, PROCESS_LOCAL, 8067 bytes)
21/12/17 14:25:26 INFO Executor: Running task 0.0 in stage 24.0 (TID 38)
21/12/17 14:25:26 INFO Executor: Finished task 0.0 in stage 24.0 (TID 38). 1157 bytes result sent to driver
21/12/17 14:25:26 INFO TaskSetManager: Finished task 0.0 in stage 24.0 (TID 38) in 6 ms on localhost (executor driver) (1/1)
21/12/17 14:25:26 INFO TaskSchedulerImpl: Removed TaskSet 24.0, whose tasks have all completed, from pool 
21/12/17 14:25:26 INFO DAGScheduler: ResultStage 24 (collect at utils.scala:24) finished in 0.010 s
21/12/17 14:25:26 INFO DAGScheduler: Job 20 finished: collect at utils.scala:24, took 0.012475 s
21/12/17 14:25:27 INFO SparkContext: Starting job: collect at utils.scala:24
21/12/17 14:25:27 INFO DAGScheduler: Got job 21 (collect at utils.scala:24) with 1 output partitions
21/12/17 14:25:27 INFO DAGScheduler: Final stage: ResultStage 25 (collect at utils.scala:24)
21/12/17 14:25:27 INFO DAGScheduler: Parents of final stage: List()
21/12/17 14:25:27 INFO DAGScheduler: Missing parents: List()
21/12/17 14:25:27 INFO DAGScheduler: Submitting ResultStage 25 (MapPartitionsRDD[104] at collect at utils.scala:24), which has no missing parents
21/12/17 14:25:27 INFO MemoryStore: Block broadcast_25 stored as values in memory (estimated size 6.9 KB, free 912.0 MB)
21/12/17 14:25:27 INFO MemoryStore: Block broadcast_25_piece0 stored as bytes in memory (estimated size 3.3 KB, free 912.0 MB)
21/12/17 14:25:27 INFO BlockManagerInfo: Added broadcast_25_piece0 in memory on kubernetes.docker.internal:50990 (size: 3.3 KB, free: 912.2 MB)
21/12/17 14:25:27 INFO SparkContext: Created broadcast 25 from broadcast at DAGScheduler.scala:1039
21/12/17 14:25:27 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 25 (MapPartitionsRDD[104] at collect at utils.scala:24) (first 15 tasks are for partitions Vector(0))
21/12/17 14:25:27 INFO TaskSchedulerImpl: Adding task set 25.0 with 1 tasks
21/12/17 14:25:27 INFO TaskSetManager: Starting task 0.0 in stage 25.0 (TID 39, localhost, executor driver, partition 0, PROCESS_LOCAL, 8067 bytes)
21/12/17 14:25:27 INFO Executor: Running task 0.0 in stage 25.0 (TID 39)
21/12/17 14:25:27 INFO Executor: Finished task 0.0 in stage 25.0 (TID 39). 1157 bytes result sent to driver
21/12/17 14:25:27 INFO TaskSetManager: Finished task 0.0 in stage 25.0 (TID 39) in 2 ms on localhost (executor driver) (1/1)
21/12/17 14:25:27 INFO TaskSchedulerImpl: Removed TaskSet 25.0, whose tasks have all completed, from pool 
21/12/17 14:25:27 INFO DAGScheduler: ResultStage 25 (collect at utils.scala:24) finished in 0.006 s
21/12/17 14:25:27 INFO DAGScheduler: Job 21 finished: collect at utils.scala:24, took 0.007451 s
21/12/17 14:25:27 INFO SparkContext: Starting job: first at LinearRegression.scala:319
21/12/17 14:25:27 INFO DAGScheduler: Got job 22 (first at LinearRegression.scala:319) with 1 output partitions
21/12/17 14:25:27 INFO DAGScheduler: Final stage: ResultStage 26 (first at LinearRegression.scala:319)
21/12/17 14:25:27 INFO DAGScheduler: Parents of final stage: List()
21/12/17 14:25:27 INFO DAGScheduler: Missing parents: List()
21/12/17 14:25:27 INFO DAGScheduler: Submitting ResultStage 26 (MapPartitionsRDD[109] at first at LinearRegression.scala:319), which has no missing parents
21/12/17 14:25:27 INFO MemoryStore: Block broadcast_26 stored as values in memory (estimated size 36.3 KB, free 912.0 MB)
21/12/17 14:25:27 INFO MemoryStore: Block broadcast_26_piece0 stored as bytes in memory (estimated size 13.8 KB, free 912.0 MB)
21/12/17 14:25:27 INFO BlockManagerInfo: Added broadcast_26_piece0 in memory on kubernetes.docker.internal:50990 (size: 13.8 KB, free: 912.2 MB)
21/12/17 14:25:27 INFO SparkContext: Created broadcast 26 from broadcast at DAGScheduler.scala:1039
21/12/17 14:25:27 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 26 (MapPartitionsRDD[109] at first at LinearRegression.scala:319) (first 15 tasks are for partitions Vector(0))
21/12/17 14:25:27 INFO TaskSchedulerImpl: Adding task set 26.0 with 1 tasks
21/12/17 14:25:27 INFO TaskSetManager: Starting task 0.0 in stage 26.0 (TID 40, localhost, executor driver, partition 0, PROCESS_LOCAL, 11614 bytes)
21/12/17 14:25:27 INFO Executor: Running task 0.0 in stage 26.0 (TID 40)
21/12/17 14:25:27 INFO BlockManager: Found block rdd_6_0 locally
21/12/17 14:25:27 INFO Executor: 1 block locks were not released by TID = 40:
[rdd_6_0]
21/12/17 14:25:27 INFO Executor: Finished task 0.0 in stage 26.0 (TID 40). 1329 bytes result sent to driver
21/12/17 14:25:27 INFO TaskSetManager: Finished task 0.0 in stage 26.0 (TID 40) in 4 ms on localhost (executor driver) (1/1)
21/12/17 14:25:27 INFO TaskSchedulerImpl: Removed TaskSet 26.0, whose tasks have all completed, from pool 
21/12/17 14:25:27 INFO DAGScheduler: ResultStage 26 (first at LinearRegression.scala:319) finished in 0.010 s
21/12/17 14:25:27 INFO DAGScheduler: Job 22 finished: first at LinearRegression.scala:319, took 0.012037 s
21/12/17 14:25:28 INFO Instrumentation: LinearRegression-linear_regression__cd7fc2cf_7287_4935_befb_15c07801188e-2105988007-2: training: numPartitions=1 storageLevel=StorageLevel(1 replicas)
21/12/17 14:25:28 INFO Instrumentation: LinearRegression-linear_regression__cd7fc2cf_7287_4935_befb_15c07801188e-2105988007-2: {"elasticNetParam":0.0,"featuresCol":"features","fitIntercept":true,"solver":"auto","labelCol":"label","predictionCol":"prediction","standardization":true,"loss":"squaredError","regParam":0.0,"tol":1.0E-6,"maxIter":100}
21/12/17 14:25:28 INFO Instrumentation: LinearRegression-linear_regression__cd7fc2cf_7287_4935_befb_15c07801188e-2105988007-2: {"numFeatures":1}
21/12/17 14:25:28 WARN WeightedLeastSquares: regParam is zero, which might cause numerical instability and overfitting.
21/12/17 14:25:28 INFO SparkContext: Starting job: treeAggregate at WeightedLeastSquares.scala:100
21/12/17 14:25:28 INFO DAGScheduler: Got job 23 (treeAggregate at WeightedLeastSquares.scala:100) with 1 output partitions
21/12/17 14:25:28 INFO DAGScheduler: Final stage: ResultStage 27 (treeAggregate at WeightedLeastSquares.scala:100)
21/12/17 14:25:28 INFO DAGScheduler: Parents of final stage: List()
21/12/17 14:25:28 INFO DAGScheduler: Missing parents: List()
21/12/17 14:25:28 INFO DAGScheduler: Submitting ResultStage 27 (MapPartitionsRDD[121] at treeAggregate at WeightedLeastSquares.scala:100), which has no missing parents
21/12/17 14:25:28 INFO MemoryStore: Block broadcast_27 stored as values in memory (estimated size 40.0 KB, free 912.0 MB)
21/12/17 14:25:28 INFO MemoryStore: Block broadcast_27_piece0 stored as bytes in memory (estimated size 15.6 KB, free 911.9 MB)
21/12/17 14:25:28 INFO BlockManagerInfo: Added broadcast_27_piece0 in memory on kubernetes.docker.internal:50990 (size: 15.6 KB, free: 912.2 MB)
21/12/17 14:25:28 INFO SparkContext: Created broadcast 27 from broadcast at DAGScheduler.scala:1039
21/12/17 14:25:28 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 27 (MapPartitionsRDD[121] at treeAggregate at WeightedLeastSquares.scala:100) (first 15 tasks are for partitions Vector(0))
21/12/17 14:25:28 INFO TaskSchedulerImpl: Adding task set 27.0 with 1 tasks
21/12/17 14:25:28 INFO TaskSetManager: Starting task 0.0 in stage 27.0 (TID 41, localhost, executor driver, partition 0, PROCESS_LOCAL, 11614 bytes)
21/12/17 14:25:28 INFO Executor: Running task 0.0 in stage 27.0 (TID 41)
21/12/17 14:25:28 INFO BlockManager: Found block rdd_6_0 locally
21/12/17 14:25:28 INFO Executor: Finished task 0.0 in stage 27.0 (TID 41). 1676 bytes result sent to driver
21/12/17 14:25:28 INFO TaskSetManager: Finished task 0.0 in stage 27.0 (TID 41) in 7 ms on localhost (executor driver) (1/1)
21/12/17 14:25:28 INFO TaskSchedulerImpl: Removed TaskSet 27.0, whose tasks have all completed, from pool 
21/12/17 14:25:28 INFO DAGScheduler: ResultStage 27 (treeAggregate at WeightedLeastSquares.scala:100) finished in 0.011 s
21/12/17 14:25:28 INFO DAGScheduler: Job 23 finished: treeAggregate at WeightedLeastSquares.scala:100, took 0.012748 s
21/12/17 14:25:28 INFO WeightedLeastSquares: Number of instances: 32.
21/12/17 14:25:28 INFO SparkContext: Starting job: treeAggregate at RegressionMetrics.scala:57
21/12/17 14:25:28 INFO DAGScheduler: Got job 24 (treeAggregate at RegressionMetrics.scala:57) with 1 output partitions
21/12/17 14:25:28 INFO DAGScheduler: Final stage: ResultStage 28 (treeAggregate at RegressionMetrics.scala:57)
21/12/17 14:25:28 INFO DAGScheduler: Parents of final stage: List()
21/12/17 14:25:28 INFO DAGScheduler: Missing parents: List()
21/12/17 14:25:28 INFO DAGScheduler: Submitting ResultStage 28 (MapPartitionsRDD[129] at treeAggregate at RegressionMetrics.scala:57), which has no missing parents
21/12/17 14:25:28 INFO MemoryStore: Block broadcast_28 stored as values in memory (estimated size 40.1 KB, free 911.9 MB)
21/12/17 14:25:28 INFO MemoryStore: Block broadcast_28_piece0 stored as bytes in memory (estimated size 16.6 KB, free 911.9 MB)
21/12/17 14:25:28 INFO BlockManagerInfo: Added broadcast_28_piece0 in memory on kubernetes.docker.internal:50990 (size: 16.6 KB, free: 912.2 MB)
21/12/17 14:25:28 INFO SparkContext: Created broadcast 28 from broadcast at DAGScheduler.scala:1039
21/12/17 14:25:28 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 28 (MapPartitionsRDD[129] at treeAggregate at RegressionMetrics.scala:57) (first 15 tasks are for partitions Vector(0))
21/12/17 14:25:28 INFO TaskSchedulerImpl: Adding task set 28.0 with 1 tasks
21/12/17 14:25:28 INFO TaskSetManager: Starting task 0.0 in stage 28.0 (TID 42, localhost, executor driver, partition 0, PROCESS_LOCAL, 11614 bytes)
21/12/17 14:25:28 INFO Executor: Running task 0.0 in stage 28.0 (TID 42)
21/12/17 14:25:28 INFO BlockManager: Found block rdd_6_0 locally
21/12/17 14:25:28 INFO Executor: Finished task 0.0 in stage 28.0 (TID 42). 1783 bytes result sent to driver
21/12/17 14:25:28 INFO TaskSetManager: Finished task 0.0 in stage 28.0 (TID 42) in 7 ms on localhost (executor driver) (1/1)
21/12/17 14:25:28 INFO TaskSchedulerImpl: Removed TaskSet 28.0, whose tasks have all completed, from pool 
21/12/17 14:25:28 INFO DAGScheduler: ResultStage 28 (treeAggregate at RegressionMetrics.scala:57) finished in 0.013 s
21/12/17 14:25:28 INFO DAGScheduler: Job 24 finished: treeAggregate at RegressionMetrics.scala:57, took 0.014595 s
21/12/17 14:25:28 INFO SparkContext: Starting job: sum at RegressionMetrics.scala:71
21/12/17 14:25:28 INFO DAGScheduler: Got job 25 (sum at RegressionMetrics.scala:71) with 1 output partitions
21/12/17 14:25:28 INFO DAGScheduler: Final stage: ResultStage 29 (sum at RegressionMetrics.scala:71)
21/12/17 14:25:28 INFO DAGScheduler: Parents of final stage: List()
21/12/17 14:25:28 INFO DAGScheduler: Missing parents: List()
21/12/17 14:25:28 INFO DAGScheduler: Submitting ResultStage 29 (MapPartitionsRDD[130] at map at RegressionMetrics.scala:69), which has no missing parents
21/12/17 14:25:28 INFO MemoryStore: Block broadcast_29 stored as values in memory (estimated size 39.2 KB, free 911.8 MB)
21/12/17 14:25:28 INFO MemoryStore: Block broadcast_29_piece0 stored as bytes in memory (estimated size 16.3 KB, free 911.8 MB)
21/12/17 14:25:28 INFO BlockManagerInfo: Added broadcast_29_piece0 in memory on kubernetes.docker.internal:50990 (size: 16.3 KB, free: 912.2 MB)
21/12/17 14:25:28 INFO SparkContext: Created broadcast 29 from broadcast at DAGScheduler.scala:1039
21/12/17 14:25:28 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 29 (MapPartitionsRDD[130] at map at RegressionMetrics.scala:69) (first 15 tasks are for partitions Vector(0))
21/12/17 14:25:28 INFO TaskSchedulerImpl: Adding task set 29.0 with 1 tasks
21/12/17 14:25:28 INFO TaskSetManager: Starting task 0.0 in stage 29.0 (TID 43, localhost, executor driver, partition 0, PROCESS_LOCAL, 11614 bytes)
21/12/17 14:25:28 INFO Executor: Running task 0.0 in stage 29.0 (TID 43)
21/12/17 14:25:28 INFO BlockManager: Found block rdd_6_0 locally
21/12/17 14:25:28 INFO Executor: Finished task 0.0 in stage 29.0 (TID 43). 1300 bytes result sent to driver
21/12/17 14:25:28 INFO TaskSetManager: Finished task 0.0 in stage 29.0 (TID 43) in 6 ms on localhost (executor driver) (1/1)
21/12/17 14:25:28 INFO TaskSchedulerImpl: Removed TaskSet 29.0, whose tasks have all completed, from pool 
21/12/17 14:25:28 INFO DAGScheduler: ResultStage 29 (sum at RegressionMetrics.scala:71) finished in 0.012 s
21/12/17 14:25:28 INFO DAGScheduler: Job 25 finished: sum at RegressionMetrics.scala:71, took 0.013240 s
21/12/17 14:25:28 INFO SparkContext: Starting job: count at LinearRegression.scala:921
21/12/17 14:25:28 INFO DAGScheduler: Registering RDD 134 (count at LinearRegression.scala:921)
21/12/17 14:25:28 INFO DAGScheduler: Got job 26 (count at LinearRegression.scala:921) with 1 output partitions
21/12/17 14:25:28 INFO DAGScheduler: Final stage: ResultStage 31 (count at LinearRegression.scala:921)
21/12/17 14:25:28 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 30)
21/12/17 14:25:28 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 30)
21/12/17 14:25:28 INFO DAGScheduler: Submitting ShuffleMapStage 30 (MapPartitionsRDD[134] at count at LinearRegression.scala:921), which has no missing parents
21/12/17 14:25:28 INFO MemoryStore: Block broadcast_30 stored as values in memory (estimated size 24.8 KB, free 911.8 MB)
21/12/17 14:25:28 INFO MemoryStore: Block broadcast_30_piece0 stored as bytes in memory (estimated size 10.9 KB, free 911.8 MB)
21/12/17 14:25:28 INFO BlockManagerInfo: Added broadcast_30_piece0 in memory on kubernetes.docker.internal:50990 (size: 10.9 KB, free: 912.1 MB)
21/12/17 14:25:28 INFO SparkContext: Created broadcast 30 from broadcast at DAGScheduler.scala:1039
21/12/17 14:25:28 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 30 (MapPartitionsRDD[134] at count at LinearRegression.scala:921) (first 15 tasks are for partitions Vector(0))
21/12/17 14:25:28 INFO TaskSchedulerImpl: Adding task set 30.0 with 1 tasks
21/12/17 14:25:28 INFO TaskSetManager: Starting task 0.0 in stage 30.0 (TID 44, localhost, executor driver, partition 0, PROCESS_LOCAL, 11603 bytes)
21/12/17 14:25:28 INFO Executor: Running task 0.0 in stage 30.0 (TID 44)
21/12/17 14:25:28 INFO BlockManager: Found block rdd_6_0 locally
21/12/17 14:25:28 INFO Executor: Finished task 0.0 in stage 30.0 (TID 44). 2035 bytes result sent to driver
21/12/17 14:25:28 INFO TaskSetManager: Finished task 0.0 in stage 30.0 (TID 44) in 14 ms on localhost (executor driver) (1/1)
21/12/17 14:25:28 INFO TaskSchedulerImpl: Removed TaskSet 30.0, whose tasks have all completed, from pool 
21/12/17 14:25:28 INFO DAGScheduler: ShuffleMapStage 30 (count at LinearRegression.scala:921) finished in 0.021 s
21/12/17 14:25:28 INFO DAGScheduler: looking for newly runnable stages
21/12/17 14:25:28 INFO DAGScheduler: running: Set()
21/12/17 14:25:28 INFO DAGScheduler: waiting: Set(ResultStage 31)
21/12/17 14:25:28 INFO DAGScheduler: failed: Set()
21/12/17 14:25:28 INFO DAGScheduler: Submitting ResultStage 31 (MapPartitionsRDD[137] at count at LinearRegression.scala:921), which has no missing parents
21/12/17 14:25:28 INFO MemoryStore: Block broadcast_31 stored as values in memory (estimated size 7.5 KB, free 911.8 MB)
21/12/17 14:25:28 INFO MemoryStore: Block broadcast_31_piece0 stored as bytes in memory (estimated size 3.9 KB, free 911.8 MB)
21/12/17 14:25:28 INFO BlockManagerInfo: Added broadcast_31_piece0 in memory on kubernetes.docker.internal:50990 (size: 3.9 KB, free: 912.1 MB)
21/12/17 14:25:28 INFO SparkContext: Created broadcast 31 from broadcast at DAGScheduler.scala:1039
21/12/17 14:25:28 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 31 (MapPartitionsRDD[137] at count at LinearRegression.scala:921) (first 15 tasks are for partitions Vector(0))
21/12/17 14:25:28 INFO TaskSchedulerImpl: Adding task set 31.0 with 1 tasks
21/12/17 14:25:28 INFO TaskSetManager: Starting task 0.0 in stage 31.0 (TID 45, localhost, executor driver, partition 0, ANY, 7754 bytes)
21/12/17 14:25:28 INFO Executor: Running task 0.0 in stage 31.0 (TID 45)
21/12/17 14:25:28 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
21/12/17 14:25:28 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
21/12/17 14:25:28 INFO Executor: Finished task 0.0 in stage 31.0 (TID 45). 1696 bytes result sent to driver
21/12/17 14:25:28 INFO TaskSetManager: Finished task 0.0 in stage 31.0 (TID 45) in 6 ms on localhost (executor driver) (1/1)
21/12/17 14:25:28 INFO TaskSchedulerImpl: Removed TaskSet 31.0, whose tasks have all completed, from pool 
21/12/17 14:25:28 INFO DAGScheduler: ResultStage 31 (count at LinearRegression.scala:921) finished in 0.011 s
21/12/17 14:25:28 INFO DAGScheduler: Job 26 finished: count at LinearRegression.scala:921, took 0.035797 s
21/12/17 14:25:28 INFO Instrumentation: LinearRegression-linear_regression__cd7fc2cf_7287_4935_befb_15c07801188e-2105988007-2: training finished
21/12/17 14:25:28 INFO SparkContext: Starting job: collect at utils.scala:24
21/12/17 14:25:28 INFO DAGScheduler: Got job 27 (collect at utils.scala:24) with 1 output partitions
21/12/17 14:25:28 INFO DAGScheduler: Final stage: ResultStage 32 (collect at utils.scala:24)
21/12/17 14:25:28 INFO DAGScheduler: Parents of final stage: List()
21/12/17 14:25:28 INFO DAGScheduler: Missing parents: List()
21/12/17 14:25:28 INFO DAGScheduler: Submitting ResultStage 32 (MapPartitionsRDD[140] at collect at utils.scala:24), which has no missing parents
21/12/17 14:25:28 INFO MemoryStore: Block broadcast_32 stored as values in memory (estimated size 6.9 KB, free 911.8 MB)
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 771
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 916
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 568
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 762
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 770
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 867
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 702
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 834
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 756
21/12/17 14:25:28 INFO MemoryStore: Block broadcast_32_piece0 stored as bytes in memory (estimated size 3.3 KB, free 911.8 MB)
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 909
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 930
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 548
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 624
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 720
21/12/17 14:25:28 INFO BlockManagerInfo: Added broadcast_32_piece0 in memory on kubernetes.docker.internal:50990 (size: 3.3 KB, free: 912.1 MB)
21/12/17 14:25:28 INFO ContextCleaner: Cleaned shuffle 3
21/12/17 14:25:28 INFO SparkContext: Created broadcast 32 from broadcast at DAGScheduler.scala:1039
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 583
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 741
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 714
21/12/17 14:25:28 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 32 (MapPartitionsRDD[140] at collect at utils.scala:24) (first 15 tasks are for partitions Vector(0))
21/12/17 14:25:28 INFO TaskSchedulerImpl: Adding task set 32.0 with 1 tasks
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 733
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 829
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 569
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 765
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 763
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 817
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 530
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 799
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 866
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 749
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 695
21/12/17 14:25:28 INFO TaskSetManager: Starting task 0.0 in stage 32.0 (TID 46, localhost, executor driver, partition 0, PROCESS_LOCAL, 8067 bytes)
21/12/17 14:25:28 INFO Executor: Running task 0.0 in stage 32.0 (TID 46)
21/12/17 14:25:28 INFO BlockManagerInfo: Removed broadcast_26_piece0 on kubernetes.docker.internal:50990 in memory (size: 13.8 KB, free: 912.2 MB)
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 906
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 628
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 789
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 917
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 704
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 650
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 721
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 864
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 857
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 669
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 684
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 863
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 560
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 619
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 722
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 700
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 707
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 904
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 822
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 854
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 839
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 772
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 873
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 889
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 546
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 630
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 681
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 688
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 662
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 575
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 653
21/12/17 14:25:28 INFO Executor: Finished task 0.0 in stage 32.0 (TID 46). 1157 bytes result sent to driver
21/12/17 14:25:28 INFO TaskSetManager: Finished task 0.0 in stage 32.0 (TID 46) in 4 ms on localhost (executor driver) (1/1)
21/12/17 14:25:28 INFO TaskSchedulerImpl: Removed TaskSet 32.0, whose tasks have all completed, from pool 
21/12/17 14:25:28 INFO BlockManagerInfo: Removed broadcast_21_piece0 on kubernetes.docker.internal:50990 in memory (size: 11.0 KB, free: 912.2 MB)
21/12/17 14:25:28 INFO DAGScheduler: ResultStage 32 (collect at utils.scala:24) finished in 0.025 s
21/12/17 14:25:28 INFO DAGScheduler: Job 27 finished: collect at utils.scala:24, took 0.026921 s
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 810
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 748
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 529
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 636
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 635
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 803
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 922
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 617
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 819
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 768
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 536
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 631
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 602
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 622
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 671
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 847
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 640
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 732
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 598
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 761
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 572
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 836
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 715
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 565
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 766
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 886
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 699
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 737
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 923
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 648
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 792
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 903
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 562
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 856
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 621
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 869
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 794
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 790
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 620
21/12/17 14:25:28 INFO BlockManagerInfo: Removed broadcast_24_piece0 on kubernetes.docker.internal:50990 in memory (size: 3.3 KB, free: 912.2 MB)
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 734
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 623
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 842
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 703
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 776
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 797
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 694
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 584
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 779
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 908
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 667
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 706
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 755
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 806
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 840
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 691
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 915
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 821
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 597
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 659
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 690
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 844
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 592
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 753
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 784
21/12/17 14:25:28 INFO BlockManagerInfo: Removed broadcast_31_piece0 on kubernetes.docker.internal:50990 in memory (size: 3.9 KB, free: 912.2 MB)
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 537
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 666
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 685
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 767
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 831
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 774
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 600
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 626
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 586
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 566
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 918
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 809
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 835
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 877
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 610
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 738
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 539
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 678
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 910
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 865
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 759
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 892
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 881
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 544
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 769
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 750
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 880
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 895
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 559
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 780
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 652
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 808
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 775
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 785
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 578
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 719
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 728
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 615
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 595
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 661
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 882
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 551
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 811
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 911
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 664
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 588
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 890
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 655
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 782
21/12/17 14:25:28 INFO BlockManagerInfo: Removed broadcast_29_piece0 on kubernetes.docker.internal:50990 in memory (size: 16.3 KB, free: 912.2 MB)
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 747
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 745
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 825
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 676
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 919
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 547
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 807
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 642
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 607
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 675
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 826
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 905
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 561
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 743
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 674
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 581
21/12/17 14:25:28 INFO BlockManagerInfo: Removed broadcast_30_piece0 on kubernetes.docker.internal:50990 in memory (size: 10.9 KB, free: 912.2 MB)
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 532
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 927
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 591
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 849
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 931
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 672
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 764
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 599
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 590
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 754
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 701
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 781
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 533
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 542
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 639
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 582
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 552
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 717
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 618
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 793
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 660
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 705
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 649
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 668
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 535
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 576
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 527
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 680
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 541
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 587
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 887
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 629
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 739
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 870
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 925
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 687
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 900
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 751
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 778
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 924
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 902
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 901
21/12/17 14:25:28 INFO ContextCleaner: Cleaned shuffle 4
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 726
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 727
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 845
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 801
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 818
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 718
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 820
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 787
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 683
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 862
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 716
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 841
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 885
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 673
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 859
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 686
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 614
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 796
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 670
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 735
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 744
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 570
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 611
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 638
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 543
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 709
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 757
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 594
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 800
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 752
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 723
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 725
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 731
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 932
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 713
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 696
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 545
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 852
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 651
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 612
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 613
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 679
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 526
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 634
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 907
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 833
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 827
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 812
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 920
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 805
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 824
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 837
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 677
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 550
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 858
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 637
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 596
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 580
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 534
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 724
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 605
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 788
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 846
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 627
21/12/17 14:25:28 INFO BlockManagerInfo: Removed broadcast_28_piece0 on kubernetes.docker.internal:50990 in memory (size: 16.6 KB, free: 912.2 MB)
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 850
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 632
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 884
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 878
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 645
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 894
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 608
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 896
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 558
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 571
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 848
21/12/17 14:25:28 INFO BlockManagerInfo: Removed broadcast_22_piece0 on kubernetes.docker.internal:50990 in memory (size: 3.9 KB, free: 912.2 MB)
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 698
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 603
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 843
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 798
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 593
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 888
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 710
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 929
21/12/17 14:25:28 INFO BlockManagerInfo: Removed broadcast_23_piece0 on kubernetes.docker.internal:50990 in memory (size: 3.3 KB, free: 912.2 MB)
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 830
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 861
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 564
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 657
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 791
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 813
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 897
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 921
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 654
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 658
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 913
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 760
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 823
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 838
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 773
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 898
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 692
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 875
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 665
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 554
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 786
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 549
21/12/17 14:25:28 INFO BlockManagerInfo: Removed broadcast_25_piece0 on kubernetes.docker.internal:50990 in memory (size: 3.3 KB, free: 912.2 MB)
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 625
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 606
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 871
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 758
21/12/17 14:25:28 INFO BlockManagerInfo: Removed broadcast_18_piece0 on kubernetes.docker.internal:50990 in memory (size: 15.6 KB, free: 912.2 MB)
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 804
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 853
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 525
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 663
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 855
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 644
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 646
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 693
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 697
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 851
21/12/17 14:25:28 INFO BlockManagerInfo: Removed broadcast_27_piece0 on kubernetes.docker.internal:50990 in memory (size: 15.6 KB, free: 912.3 MB)
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 874
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 879
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 585
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 633
21/12/17 14:25:28 INFO BlockManagerInfo: Removed broadcast_20_piece0 on kubernetes.docker.internal:50990 in memory (size: 16.3 KB, free: 912.3 MB)
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 708
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 531
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 912
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 538
21/12/17 14:25:28 INFO BlockManagerInfo: Removed broadcast_19_piece0 on kubernetes.docker.internal:50990 in memory (size: 16.6 KB, free: 912.3 MB)
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 730
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 860
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 883
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 682
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 795
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 736
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 914
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 832
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 711
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 528
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 609
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 573
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 712
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 746
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 553
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 868
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 577
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 689
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 783
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 802
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 574
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 899
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 567
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 647
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 891
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 641
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 742
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 777
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 872
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 643
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 616
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 729
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 601
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 604
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 524
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 589
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 656
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 893
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 740
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 876
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 579
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 828
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 926
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 928
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 540
21/12/17 14:25:28 INFO ContextCleaner: Cleaned accumulator 563
21/12/17 14:25:29 INFO SparkContext: Starting job: collect at utils.scala:24
21/12/17 14:25:29 INFO DAGScheduler: Got job 28 (collect at utils.scala:24) with 1 output partitions
21/12/17 14:25:29 INFO DAGScheduler: Final stage: ResultStage 33 (collect at utils.scala:24)
21/12/17 14:25:29 INFO DAGScheduler: Parents of final stage: List()
21/12/17 14:25:29 INFO DAGScheduler: Missing parents: List()
21/12/17 14:25:29 INFO DAGScheduler: Submitting ResultStage 33 (MapPartitionsRDD[143] at collect at utils.scala:24), which has no missing parents
21/12/17 14:25:29 INFO MemoryStore: Block broadcast_33 stored as values in memory (estimated size 6.9 KB, free 912.3 MB)
21/12/17 14:25:29 INFO MemoryStore: Block broadcast_33_piece0 stored as bytes in memory (estimated size 3.3 KB, free 912.3 MB)
21/12/17 14:25:29 INFO BlockManagerInfo: Added broadcast_33_piece0 in memory on kubernetes.docker.internal:50990 (size: 3.3 KB, free: 912.3 MB)
21/12/17 14:25:29 INFO SparkContext: Created broadcast 33 from broadcast at DAGScheduler.scala:1039
21/12/17 14:25:29 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 33 (MapPartitionsRDD[143] at collect at utils.scala:24) (first 15 tasks are for partitions Vector(0))
21/12/17 14:25:29 INFO TaskSchedulerImpl: Adding task set 33.0 with 1 tasks
21/12/17 14:25:29 INFO TaskSetManager: Starting task 0.0 in stage 33.0 (TID 47, localhost, executor driver, partition 0, PROCESS_LOCAL, 8067 bytes)
21/12/17 14:25:29 INFO Executor: Running task 0.0 in stage 33.0 (TID 47)
21/12/17 14:25:29 INFO Executor: Finished task 0.0 in stage 33.0 (TID 47). 1157 bytes result sent to driver
21/12/17 14:25:29 INFO TaskSetManager: Finished task 0.0 in stage 33.0 (TID 47) in 3 ms on localhost (executor driver) (1/1)
21/12/17 14:25:29 INFO TaskSchedulerImpl: Removed TaskSet 33.0, whose tasks have all completed, from pool 
21/12/17 14:25:29 INFO DAGScheduler: ResultStage 33 (collect at utils.scala:24) finished in 0.009 s
21/12/17 14:25:29 INFO DAGScheduler: Job 28 finished: collect at utils.scala:24, took 0.010413 s
21/12/17 14:25:29 INFO SparkContext: Starting job: collect at utils.scala:24
21/12/17 14:25:29 INFO DAGScheduler: Got job 29 (collect at utils.scala:24) with 1 output partitions
21/12/17 14:25:29 INFO DAGScheduler: Final stage: ResultStage 34 (collect at utils.scala:24)
21/12/17 14:25:29 INFO DAGScheduler: Parents of final stage: List()
21/12/17 14:25:29 INFO DAGScheduler: Missing parents: List()
21/12/17 14:25:29 INFO DAGScheduler: Submitting ResultStage 34 (MapPartitionsRDD[146] at collect at utils.scala:24), which has no missing parents
21/12/17 14:25:29 INFO MemoryStore: Block broadcast_34 stored as values in memory (estimated size 6.9 KB, free 912.3 MB)
21/12/17 14:25:29 INFO MemoryStore: Block broadcast_34_piece0 stored as bytes in memory (estimated size 3.3 KB, free 912.3 MB)
21/12/17 14:25:29 INFO BlockManagerInfo: Added broadcast_34_piece0 in memory on kubernetes.docker.internal:50990 (size: 3.3 KB, free: 912.3 MB)
21/12/17 14:25:29 INFO SparkContext: Created broadcast 34 from broadcast at DAGScheduler.scala:1039
21/12/17 14:25:29 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 34 (MapPartitionsRDD[146] at collect at utils.scala:24) (first 15 tasks are for partitions Vector(0))
21/12/17 14:25:29 INFO TaskSchedulerImpl: Adding task set 34.0 with 1 tasks
21/12/17 14:25:29 INFO TaskSetManager: Starting task 0.0 in stage 34.0 (TID 48, localhost, executor driver, partition 0, PROCESS_LOCAL, 8067 bytes)
21/12/17 14:25:29 INFO Executor: Running task 0.0 in stage 34.0 (TID 48)
21/12/17 14:25:29 INFO Executor: Finished task 0.0 in stage 34.0 (TID 48). 1157 bytes result sent to driver
21/12/17 14:25:29 INFO TaskSetManager: Finished task 0.0 in stage 34.0 (TID 48) in 3 ms on localhost (executor driver) (1/1)
21/12/17 14:25:29 INFO TaskSchedulerImpl: Removed TaskSet 34.0, whose tasks have all completed, from pool 
21/12/17 14:25:29 INFO DAGScheduler: ResultStage 34 (collect at utils.scala:24) finished in 0.007 s
21/12/17 14:25:29 INFO DAGScheduler: Job 29 finished: collect at utils.scala:24, took 0.008643 s
21/12/17 14:25:32 INFO HiveMetaStore: 0: get_database: default
21/12/17 14:25:32 INFO audit: ugi=uhp07025	ip=unknown-ip-addr	cmd=get_database: default	
21/12/17 14:25:32 INFO HiveMetaStore: 0: get_database: default
21/12/17 14:25:32 INFO audit: ugi=uhp07025	ip=unknown-ip-addr	cmd=get_database: default	
21/12/17 14:25:32 INFO HiveMetaStore: 0: get_tables: db=default pat=*
21/12/17 14:25:32 INFO audit: ugi=uhp07025	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
21/12/17 14:25:32 INFO CodeGenerator: Code generated in 6.3886 ms
21/12/17 14:25:33 INFO CodeGenerator: Code generated in 4.3566 ms
21/12/17 14:25:33 INFO SparkContext: Starting job: collect at utils.scala:24
21/12/17 14:25:33 INFO DAGScheduler: Got job 30 (collect at utils.scala:24) with 1 output partitions
21/12/17 14:25:33 INFO DAGScheduler: Final stage: ResultStage 35 (collect at utils.scala:24)
21/12/17 14:25:33 INFO DAGScheduler: Parents of final stage: List()
21/12/17 14:25:33 INFO DAGScheduler: Missing parents: List()
21/12/17 14:25:33 INFO DAGScheduler: Submitting ResultStage 35 (MapPartitionsRDD[150] at collect at utils.scala:24), which has no missing parents
21/12/17 14:25:33 INFO MemoryStore: Block broadcast_35 stored as values in memory (estimated size 6.3 KB, free 912.2 MB)
21/12/17 14:25:33 INFO MemoryStore: Block broadcast_35_piece0 stored as bytes in memory (estimated size 3.2 KB, free 912.2 MB)
21/12/17 14:25:33 INFO BlockManagerInfo: Added broadcast_35_piece0 in memory on kubernetes.docker.internal:50990 (size: 3.2 KB, free: 912.3 MB)
21/12/17 14:25:33 INFO SparkContext: Created broadcast 35 from broadcast at DAGScheduler.scala:1039
21/12/17 14:25:33 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 35 (MapPartitionsRDD[150] at collect at utils.scala:24) (first 15 tasks are for partitions Vector(0))
21/12/17 14:25:33 INFO TaskSchedulerImpl: Adding task set 35.0 with 1 tasks
21/12/17 14:25:33 INFO TaskSetManager: Starting task 0.0 in stage 35.0 (TID 49, localhost, executor driver, partition 0, PROCESS_LOCAL, 8067 bytes)
21/12/17 14:25:33 INFO Executor: Running task 0.0 in stage 35.0 (TID 49)
21/12/17 14:25:33 INFO Executor: Finished task 0.0 in stage 35.0 (TID 49). 1242 bytes result sent to driver
21/12/17 14:25:33 INFO TaskSetManager: Finished task 0.0 in stage 35.0 (TID 49) in 4 ms on localhost (executor driver) (1/1)
21/12/17 14:25:33 INFO TaskSchedulerImpl: Removed TaskSet 35.0, whose tasks have all completed, from pool 
21/12/17 14:25:33 INFO DAGScheduler: ResultStage 35 (collect at utils.scala:24) finished in 0.009 s
21/12/17 14:25:33 INFO DAGScheduler: Job 30 finished: collect at utils.scala:24, took 0.009975 s
21/12/17 14:25:33 INFO SparkContext: Starting job: collect at utils.scala:24
21/12/17 14:25:33 INFO DAGScheduler: Got job 31 (collect at utils.scala:24) with 1 output partitions
21/12/17 14:25:33 INFO DAGScheduler: Final stage: ResultStage 36 (collect at utils.scala:24)
21/12/17 14:25:33 INFO DAGScheduler: Parents of final stage: List()
21/12/17 14:25:33 INFO DAGScheduler: Missing parents: List()
21/12/17 14:25:33 INFO DAGScheduler: Submitting ResultStage 36 (MapPartitionsRDD[155] at collect at utils.scala:24), which has no missing parents
21/12/17 14:25:33 INFO MemoryStore: Block broadcast_36 stored as values in memory (estimated size 6.3 KB, free 912.2 MB)
21/12/17 14:25:33 INFO MemoryStore: Block broadcast_36_piece0 stored as bytes in memory (estimated size 3.2 KB, free 912.2 MB)
21/12/17 14:25:33 INFO BlockManagerInfo: Added broadcast_36_piece0 in memory on kubernetes.docker.internal:50990 (size: 3.2 KB, free: 912.3 MB)
21/12/17 14:25:33 INFO SparkContext: Created broadcast 36 from broadcast at DAGScheduler.scala:1039
21/12/17 14:25:33 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 36 (MapPartitionsRDD[155] at collect at utils.scala:24) (first 15 tasks are for partitions Vector(0))
21/12/17 14:25:33 INFO TaskSchedulerImpl: Adding task set 36.0 with 1 tasks
21/12/17 14:25:33 INFO TaskSetManager: Starting task 0.0 in stage 36.0 (TID 50, localhost, executor driver, partition 0, PROCESS_LOCAL, 8067 bytes)
21/12/17 14:25:33 INFO Executor: Running task 0.0 in stage 36.0 (TID 50)
21/12/17 14:25:33 INFO Executor: Finished task 0.0 in stage 36.0 (TID 50). 1156 bytes result sent to driver
21/12/17 14:25:33 INFO TaskSetManager: Finished task 0.0 in stage 36.0 (TID 50) in 3 ms on localhost (executor driver) (1/1)
21/12/17 14:25:33 INFO TaskSchedulerImpl: Removed TaskSet 36.0, whose tasks have all completed, from pool 
21/12/17 14:25:33 INFO DAGScheduler: ResultStage 36 (collect at utils.scala:24) finished in 0.008 s
21/12/17 14:25:33 INFO DAGScheduler: Job 31 finished: collect at utils.scala:24, took 0.008778 s
21/12/17 14:25:33 INFO CodeGenerator: Code generated in 4.021 ms
21/12/17 14:25:33 INFO CodeGenerator: Code generated in 5.4934 ms
21/12/17 14:25:33 INFO SparkContext: Starting job: collect at utils.scala:24
21/12/17 14:25:33 INFO DAGScheduler: Got job 32 (collect at utils.scala:24) with 1 output partitions
21/12/17 14:25:33 INFO DAGScheduler: Final stage: ResultStage 37 (collect at utils.scala:24)
21/12/17 14:25:33 INFO DAGScheduler: Parents of final stage: List()
21/12/17 14:25:33 INFO DAGScheduler: Missing parents: List()
21/12/17 14:25:33 INFO DAGScheduler: Submitting ResultStage 37 (MapPartitionsRDD[158] at collect at utils.scala:24), which has no missing parents
21/12/17 14:25:33 INFO MemoryStore: Block broadcast_37 stored as values in memory (estimated size 6.4 KB, free 912.2 MB)
21/12/17 14:25:33 INFO MemoryStore: Block broadcast_37_piece0 stored as bytes in memory (estimated size 3.3 KB, free 912.2 MB)
21/12/17 14:25:33 INFO BlockManagerInfo: Added broadcast_37_piece0 in memory on kubernetes.docker.internal:50990 (size: 3.3 KB, free: 912.3 MB)
21/12/17 14:25:33 INFO SparkContext: Created broadcast 37 from broadcast at DAGScheduler.scala:1039
21/12/17 14:25:33 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 37 (MapPartitionsRDD[158] at collect at utils.scala:24) (first 15 tasks are for partitions Vector(0))
21/12/17 14:25:33 INFO TaskSchedulerImpl: Adding task set 37.0 with 1 tasks
21/12/17 14:25:33 INFO TaskSetManager: Starting task 0.0 in stage 37.0 (TID 51, localhost, executor driver, partition 0, PROCESS_LOCAL, 8067 bytes)
21/12/17 14:25:33 INFO Executor: Running task 0.0 in stage 37.0 (TID 51)
21/12/17 14:25:33 INFO Executor: Finished task 0.0 in stage 37.0 (TID 51). 1200 bytes result sent to driver
21/12/17 14:25:33 INFO TaskSetManager: Finished task 0.0 in stage 37.0 (TID 51) in 5 ms on localhost (executor driver) (1/1)
21/12/17 14:25:33 INFO TaskSchedulerImpl: Removed TaskSet 37.0, whose tasks have all completed, from pool 
21/12/17 14:25:33 INFO DAGScheduler: ResultStage 37 (collect at utils.scala:24) finished in 0.015 s
21/12/17 14:25:33 INFO DAGScheduler: Job 32 finished: collect at utils.scala:24, took 0.017067 s
21/12/17 14:25:33 INFO HiveMetaStore: 0: get_database: default
21/12/17 14:25:33 INFO audit: ugi=uhp07025	ip=unknown-ip-addr	cmd=get_database: default	
21/12/17 14:25:33 INFO HiveMetaStore: 0: get_database: default
21/12/17 14:25:33 INFO audit: ugi=uhp07025	ip=unknown-ip-addr	cmd=get_database: default	
21/12/17 14:25:33 INFO CodeGenerator: Code generated in 9.3862 ms
21/12/17 14:25:33 INFO CodeGenerator: Code generated in 18.6394 ms
21/12/17 14:25:33 INFO CodeGenerator: Code generated in 26.281 ms
21/12/17 14:25:33 INFO CodeGenerator: Code generated in 24.8748 ms
21/12/17 14:25:33 INFO CodeGenerator: Code generated in 13.9256 ms
21/12/17 14:25:34 INFO SparkContext: Starting job: collect at utils.scala:24
21/12/17 14:25:34 INFO DAGScheduler: Registering RDD 162 (collect at utils.scala:24)
21/12/17 14:25:34 INFO DAGScheduler: Registering RDD 167 (collect at utils.scala:24)
21/12/17 14:25:34 INFO DAGScheduler: Got job 33 (collect at utils.scala:24) with 8 output partitions
21/12/17 14:25:34 INFO DAGScheduler: Final stage: ResultStage 40 (collect at utils.scala:24)
21/12/17 14:25:34 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 38, ShuffleMapStage 39)
21/12/17 14:25:34 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 38, ShuffleMapStage 39)
21/12/17 14:25:34 INFO DAGScheduler: Submitting ShuffleMapStage 38 (MapPartitionsRDD[162] at collect at utils.scala:24), which has no missing parents
21/12/17 14:25:34 INFO MemoryStore: Block broadcast_38 stored as values in memory (estimated size 32.6 KB, free 912.2 MB)
21/12/17 14:25:34 INFO MemoryStore: Block broadcast_38_piece0 stored as bytes in memory (estimated size 14.0 KB, free 912.2 MB)
21/12/17 14:25:34 INFO BlockManagerInfo: Added broadcast_38_piece0 in memory on kubernetes.docker.internal:50990 (size: 14.0 KB, free: 912.3 MB)
21/12/17 14:25:34 INFO SparkContext: Created broadcast 38 from broadcast at DAGScheduler.scala:1039
21/12/17 14:25:34 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 38 (MapPartitionsRDD[162] at collect at utils.scala:24) (first 15 tasks are for partitions Vector(0))
21/12/17 14:25:34 INFO TaskSchedulerImpl: Adding task set 38.0 with 1 tasks
21/12/17 14:25:34 INFO DAGScheduler: Submitting ShuffleMapStage 39 (MapPartitionsRDD[167] at collect at utils.scala:24), which has no missing parents
21/12/17 14:25:34 INFO TaskSetManager: Starting task 0.0 in stage 38.0 (TID 52, localhost, executor driver, partition 0, PROCESS_LOCAL, 8317 bytes)
21/12/17 14:25:34 INFO Executor: Running task 0.0 in stage 38.0 (TID 52)
21/12/17 14:25:34 INFO MemoryStore: Block broadcast_39 stored as values in memory (estimated size 8.8 KB, free 912.2 MB)
21/12/17 14:25:34 INFO MemoryStore: Block broadcast_39_piece0 stored as bytes in memory (estimated size 4.5 KB, free 912.2 MB)
21/12/17 14:25:34 INFO BlockManagerInfo: Added broadcast_39_piece0 in memory on kubernetes.docker.internal:50990 (size: 4.5 KB, free: 912.3 MB)
21/12/17 14:25:34 INFO SparkContext: Created broadcast 39 from broadcast at DAGScheduler.scala:1039
21/12/17 14:25:34 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 39 (MapPartitionsRDD[167] at collect at utils.scala:24) (first 15 tasks are for partitions Vector(0))
21/12/17 14:25:34 INFO TaskSchedulerImpl: Adding task set 39.0 with 1 tasks
21/12/17 14:25:34 INFO TaskSetManager: Starting task 0.0 in stage 39.0 (TID 53, localhost, executor driver, partition 0, PROCESS_LOCAL, 11603 bytes)
21/12/17 14:25:34 INFO Executor: Running task 0.0 in stage 39.0 (TID 53)
21/12/17 14:25:34 INFO CodeGenerator: Code generated in 15.2531 ms
21/12/17 14:25:34 INFO MemoryStore: Block rdd_152_0 stored as values in memory (estimated size 336.0 B, free 912.2 MB)
21/12/17 14:25:34 INFO BlockManagerInfo: Added rdd_152_0 in memory on kubernetes.docker.internal:50990 (size: 336.0 B, free: 912.3 MB)
21/12/17 14:25:34 INFO CodeGenerator: Code generated in 26.9684 ms
21/12/17 14:25:34 INFO CodeGenerator: Code generated in 26.3828 ms
21/12/17 14:25:34 INFO Executor: Finished task 0.0 in stage 38.0 (TID 52). 1518 bytes result sent to driver
21/12/17 14:25:34 INFO TaskSetManager: Finished task 0.0 in stage 38.0 (TID 52) in 143 ms on localhost (executor driver) (1/1)
21/12/17 14:25:34 INFO TaskSchedulerImpl: Removed TaskSet 38.0, whose tasks have all completed, from pool 
21/12/17 14:25:34 INFO DAGScheduler: ShuffleMapStage 38 (collect at utils.scala:24) finished in 0.154 s
21/12/17 14:25:34 INFO DAGScheduler: looking for newly runnable stages
21/12/17 14:25:34 INFO DAGScheduler: running: Set(ShuffleMapStage 39)
21/12/17 14:25:34 INFO DAGScheduler: waiting: Set(ResultStage 40)
21/12/17 14:25:34 INFO DAGScheduler: failed: Set()
21/12/17 14:25:34 INFO Executor: Finished task 0.0 in stage 39.0 (TID 53). 1322 bytes result sent to driver
21/12/17 14:25:34 INFO TaskSetManager: Finished task 0.0 in stage 39.0 (TID 53) in 151 ms on localhost (executor driver) (1/1)
21/12/17 14:25:34 INFO TaskSchedulerImpl: Removed TaskSet 39.0, whose tasks have all completed, from pool 
21/12/17 14:25:34 INFO DAGScheduler: ShuffleMapStage 39 (collect at utils.scala:24) finished in 0.161 s
21/12/17 14:25:34 INFO DAGScheduler: looking for newly runnable stages
21/12/17 14:25:34 INFO DAGScheduler: running: Set()
21/12/17 14:25:34 INFO DAGScheduler: waiting: Set(ResultStage 40)
21/12/17 14:25:34 INFO DAGScheduler: failed: Set()
21/12/17 14:25:34 INFO DAGScheduler: Submitting ResultStage 40 (MapPartitionsRDD[172] at collect at utils.scala:24), which has no missing parents
21/12/17 14:25:34 INFO MemoryStore: Block broadcast_40 stored as values in memory (estimated size 33.5 KB, free 912.1 MB)
21/12/17 14:25:34 INFO MemoryStore: Block broadcast_40_piece0 stored as bytes in memory (estimated size 14.8 KB, free 912.1 MB)
21/12/17 14:25:34 INFO BlockManagerInfo: Added broadcast_40_piece0 in memory on kubernetes.docker.internal:50990 (size: 14.8 KB, free: 912.2 MB)
21/12/17 14:25:34 INFO SparkContext: Created broadcast 40 from broadcast at DAGScheduler.scala:1039
21/12/17 14:25:34 INFO DAGScheduler: Submitting 8 missing tasks from ResultStage 40 (MapPartitionsRDD[172] at collect at utils.scala:24) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))
21/12/17 14:25:34 INFO TaskSchedulerImpl: Adding task set 40.0 with 8 tasks
21/12/17 14:25:34 INFO TaskSetManager: Starting task 0.0 in stage 40.0 (TID 54, localhost, executor driver, partition 0, ANY, 8082 bytes)
21/12/17 14:25:34 INFO TaskSetManager: Starting task 1.0 in stage 40.0 (TID 55, localhost, executor driver, partition 1, ANY, 8082 bytes)
21/12/17 14:25:34 INFO TaskSetManager: Starting task 2.0 in stage 40.0 (TID 56, localhost, executor driver, partition 2, ANY, 8082 bytes)
21/12/17 14:25:34 INFO TaskSetManager: Starting task 3.0 in stage 40.0 (TID 57, localhost, executor driver, partition 3, ANY, 8082 bytes)
21/12/17 14:25:34 INFO TaskSetManager: Starting task 4.0 in stage 40.0 (TID 58, localhost, executor driver, partition 4, ANY, 8082 bytes)
21/12/17 14:25:34 INFO TaskSetManager: Starting task 5.0 in stage 40.0 (TID 59, localhost, executor driver, partition 5, ANY, 8082 bytes)
21/12/17 14:25:34 INFO TaskSetManager: Starting task 6.0 in stage 40.0 (TID 60, localhost, executor driver, partition 6, ANY, 8082 bytes)
21/12/17 14:25:34 INFO TaskSetManager: Starting task 7.0 in stage 40.0 (TID 61, localhost, executor driver, partition 7, ANY, 8082 bytes)
21/12/17 14:25:34 INFO Executor: Running task 0.0 in stage 40.0 (TID 54)
21/12/17 14:25:34 INFO Executor: Running task 1.0 in stage 40.0 (TID 55)
21/12/17 14:25:34 INFO Executor: Running task 2.0 in stage 40.0 (TID 56)
21/12/17 14:25:34 INFO Executor: Running task 3.0 in stage 40.0 (TID 57)
21/12/17 14:25:34 INFO Executor: Running task 5.0 in stage 40.0 (TID 59)
21/12/17 14:25:34 INFO Executor: Running task 7.0 in stage 40.0 (TID 61)
21/12/17 14:25:34 INFO Executor: Running task 4.0 in stage 40.0 (TID 58)
21/12/17 14:25:34 INFO Executor: Running task 6.0 in stage 40.0 (TID 60)
21/12/17 14:25:34 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 1 blocks
21/12/17 14:25:34 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
21/12/17 14:25:34 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
21/12/17 14:25:34 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
21/12/17 14:25:34 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
21/12/17 14:25:34 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 1 blocks
21/12/17 14:25:34 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
21/12/17 14:25:34 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 1 blocks
21/12/17 14:25:34 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
21/12/17 14:25:34 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 4 ms
21/12/17 14:25:34 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
21/12/17 14:25:34 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 4 ms
21/12/17 14:25:34 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
21/12/17 14:25:34 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
21/12/17 14:25:34 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
21/12/17 14:25:34 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
21/12/17 14:25:34 INFO CodeGenerator: Code generated in 21.2865 ms
21/12/17 14:25:34 INFO CodeGenerator: Code generated in 21.9357 ms
21/12/17 14:25:34 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
21/12/17 14:25:34 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
21/12/17 14:25:34 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 1 blocks
21/12/17 14:25:34 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
21/12/17 14:25:34 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
21/12/17 14:25:34 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
21/12/17 14:25:34 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
21/12/17 14:25:34 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
21/12/17 14:25:34 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
21/12/17 14:25:34 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
21/12/17 14:25:34 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
21/12/17 14:25:34 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
21/12/17 14:25:34 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
21/12/17 14:25:34 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
21/12/17 14:25:34 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms
21/12/17 14:25:34 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
21/12/17 14:25:34 INFO CodeGenerator: Code generated in 15.9279 ms
21/12/17 14:25:34 INFO CodeGenerator: Code generated in 16.0474 ms
21/12/17 14:25:34 INFO CodeGenerator: Code generated in 17.4398 ms
21/12/17 14:25:34 INFO Executor: Finished task 7.0 in stage 40.0 (TID 61). 3056 bytes result sent to driver
21/12/17 14:25:34 INFO Executor: Finished task 1.0 in stage 40.0 (TID 55). 3013 bytes result sent to driver
21/12/17 14:25:34 INFO TaskSetManager: Finished task 7.0 in stage 40.0 (TID 61) in 228 ms on localhost (executor driver) (1/8)
21/12/17 14:25:34 INFO Executor: Finished task 3.0 in stage 40.0 (TID 57). 3130 bytes result sent to driver
21/12/17 14:25:34 INFO TaskSetManager: Finished task 1.0 in stage 40.0 (TID 55) in 239 ms on localhost (executor driver) (2/8)
21/12/17 14:25:34 INFO Executor: Finished task 0.0 in stage 40.0 (TID 54). 3049 bytes result sent to driver
21/12/17 14:25:34 INFO Executor: Finished task 4.0 in stage 40.0 (TID 58). 3062 bytes result sent to driver
21/12/17 14:25:34 INFO TaskSetManager: Finished task 3.0 in stage 40.0 (TID 57) in 245 ms on localhost (executor driver) (3/8)
21/12/17 14:25:34 INFO TaskSetManager: Finished task 0.0 in stage 40.0 (TID 54) in 250 ms on localhost (executor driver) (4/8)
21/12/17 14:25:34 INFO TaskSetManager: Finished task 4.0 in stage 40.0 (TID 58) in 247 ms on localhost (executor driver) (5/8)
21/12/17 14:25:34 INFO Executor: Finished task 2.0 in stage 40.0 (TID 56). 3102 bytes result sent to driver
21/12/17 14:25:34 INFO Executor: Finished task 5.0 in stage 40.0 (TID 59). 3063 bytes result sent to driver
21/12/17 14:25:34 INFO Executor: Finished task 6.0 in stage 40.0 (TID 60). 3180 bytes result sent to driver
21/12/17 14:25:34 INFO TaskSetManager: Finished task 2.0 in stage 40.0 (TID 56) in 251 ms on localhost (executor driver) (6/8)
21/12/17 14:25:34 INFO TaskSetManager: Finished task 5.0 in stage 40.0 (TID 59) in 251 ms on localhost (executor driver) (7/8)
21/12/17 14:25:34 INFO TaskSetManager: Finished task 6.0 in stage 40.0 (TID 60) in 251 ms on localhost (executor driver) (8/8)
21/12/17 14:25:34 INFO TaskSchedulerImpl: Removed TaskSet 40.0, whose tasks have all completed, from pool 
21/12/17 14:25:34 INFO DAGScheduler: ResultStage 40 (collect at utils.scala:24) finished in 0.264 s
21/12/17 14:25:34 INFO DAGScheduler: Job 33 finished: collect at utils.scala:24, took 0.445984 s
21/12/17 14:52:37 INFO ContextCleaner: Cleaned accumulator 8
21/12/17 14:52:37 INFO ContextCleaner: Cleaned accumulator 5
21/12/17 14:52:37 INFO ContextCleaner: Cleaned accumulator 999
21/12/17 14:52:37 INFO ContextCleaner: Cleaned accumulator 1110
21/12/17 14:52:37 INFO ContextCleaner: Cleaned accumulator 1126
21/12/17 14:52:37 INFO ContextCleaner: Cleaned accumulator 1122
21/12/17 14:52:37 INFO ContextCleaner: Cleaned accumulator 966
21/12/17 14:52:37 INFO ContextCleaner: Cleaned accumulator 978
21/12/17 14:52:37 INFO ContextCleaner: Cleaned accumulator 1180
21/12/17 14:52:37 INFO ContextCleaner: Cleaned accumulator 1108
21/12/17 14:52:37 INFO ContextCleaner: Cleaned accumulator 1104
21/12/17 14:52:37 INFO ContextCleaner: Cleaned accumulator 939
21/12/17 14:52:37 INFO ContextCleaner: Cleaned accumulator 1066
21/12/17 14:52:37 INFO ContextCleaner: Cleaned accumulator 1147
21/12/17 14:52:37 INFO ContextCleaner: Cleaned accumulator 1176
21/12/17 14:52:37 INFO ContextCleaner: Cleaned accumulator 1170
21/12/17 14:52:37 INFO ContextCleaner: Cleaned accumulator 1045
21/12/17 14:52:37 INFO ContextCleaner: Cleaned accumulator 1031
21/12/17 14:52:37 INFO ContextCleaner: Cleaned accumulator 989
21/12/17 14:52:37 INFO ContextCleaner: Cleaned accumulator 1060
21/12/17 14:52:37 INFO ContextCleaner: Cleaned accumulator 1044
21/12/17 14:52:37 INFO ContextCleaner: Cleaned accumulator 1120
21/12/17 14:52:37 INFO ContextCleaner: Cleaned accumulator 1083
21/12/17 14:52:37 INFO ContextCleaner: Cleaned accumulator 935
21/12/17 14:52:37 INFO ContextCleaner: Cleaned accumulator 1033
21/12/17 14:52:37 INFO ContextCleaner: Cleaned accumulator 1119
21/12/17 14:52:37 INFO ContextCleaner: Cleaned accumulator 1028
21/12/17 14:52:37 INFO ContextCleaner: Cleaned accumulator 1191
21/12/17 14:52:37 INFO ContextCleaner: Cleaned accumulator 1007
21/12/17 14:52:37 INFO ContextCleaner: Cleaned accumulator 1030
21/12/17 14:52:37 INFO ContextCleaner: Cleaned accumulator 1169
21/12/17 14:52:37 INFO ContextCleaner: Cleaned accumulator 1175
21/12/17 14:52:37 INFO ContextCleaner: Cleaned accumulator 958
21/12/17 14:52:37 INFO ContextCleaner: Cleaned accumulator 1171
21/12/17 14:52:37 INFO ContextCleaner: Cleaned accumulator 992
21/12/17 14:52:37 INFO ContextCleaner: Cleaned accumulator 1151
21/12/17 14:52:37 INFO ContextCleaner: Cleaned accumulator 973
21/12/17 14:52:37 INFO ContextCleaner: Cleaned accumulator 1177
21/12/17 14:52:37 INFO ContextCleaner: Cleaned accumulator 961
21/12/17 14:52:37 INFO ContextCleaner: Cleaned accumulator 1142
21/12/17 14:52:37 INFO ContextCleaner: Cleaned accumulator 1133
21/12/17 14:52:37 INFO ContextCleaner: Cleaned accumulator 1080
21/12/17 14:52:37 INFO ContextCleaner: Cleaned accumulator 1161
21/12/17 14:52:37 INFO ContextCleaner: Cleaned accumulator 936
21/12/17 14:52:37 INFO BlockManagerInfo: Removed broadcast_32_piece0 on kubernetes.docker.internal:50990 in memory (size: 3.3 KB, free: 912.2 MB)
21/12/17 14:52:37 INFO ContextCleaner: Cleaned accumulator 1124
21/12/17 14:52:37 INFO ContextCleaner: Cleaned accumulator 1075
21/12/17 14:52:37 INFO ContextCleaner: Cleaned accumulator 1086
21/12/17 14:52:37 INFO ContextCleaner: Cleaned accumulator 1003
21/12/17 14:52:37 INFO ContextCleaner: Cleaned accumulator 982
21/12/17 14:52:37 INFO ContextCleaner: Cleaned accumulator 1107
21/12/17 14:52:37 INFO ContextCleaner: Cleaned accumulator 1012
21/12/17 14:52:37 INFO ContextCleaner: Cleaned accumulator 1156
21/12/17 14:52:37 INFO ContextCleaner: Cleaned shuffle 6
21/12/17 14:52:37 INFO ContextCleaner: Cleaned accumulator 957
21/12/17 14:52:37 INFO ContextCleaner: Cleaned accumulator 1093
21/12/17 14:52:37 INFO ContextCleaner: Cleaned accumulator 1076
21/12/17 14:52:37 INFO ContextCleaner: Cleaned accumulator 1053
21/12/17 14:52:37 INFO ContextCleaner: Cleaned accumulator 1121
21/12/17 14:52:37 INFO ContextCleaner: Cleaned accumulator 997
21/12/17 14:52:37 INFO ContextCleaner: Cleaned accumulator 1081
21/12/17 14:52:37 INFO ContextCleaner: Cleaned accumulator 1163
21/12/17 14:52:37 INFO ContextCleaner: Cleaned accumulator 1004
21/12/17 14:52:37 INFO ContextCleaner: Cleaned accumulator 971
21/12/17 14:52:37 INFO ContextCleaner: Cleaned accumulator 1025
21/12/17 14:52:37 INFO ContextCleaner: Cleaned accumulator 934
21/12/17 14:52:37 INFO ContextCleaner: Cleaned accumulator 1117
21/12/17 14:52:37 INFO ContextCleaner: Cleaned accumulator 1132
21/12/17 14:52:37 INFO ContextCleaner: Cleaned accumulator 949
21/12/17 14:52:37 INFO ContextCleaner: Cleaned accumulator 984
21/12/17 14:52:37 INFO ContextCleaner: Cleaned accumulator 1019
21/12/17 14:52:37 INFO ContextCleaner: Cleaned accumulator 1054
21/12/17 14:52:37 INFO ContextCleaner: Cleaned accumulator 1034
21/12/17 14:52:37 INFO ContextCleaner: Cleaned accumulator 940
21/12/17 14:52:37 INFO ContextCleaner: Cleaned accumulator 1016
21/12/17 14:52:37 INFO ContextCleaner: Cleaned accumulator 1063
21/12/17 14:52:37 INFO ContextCleaner: Cleaned accumulator 1154
21/12/17 14:52:37 INFO ContextCleaner: Cleaned accumulator 1048
21/12/17 14:52:37 INFO ContextCleaner: Cleaned accumulator 1103
21/12/17 14:52:37 INFO ContextCleaner: Cleaned accumulator 1059
21/12/17 14:52:37 INFO ContextCleaner: Cleaned accumulator 1087
21/12/17 14:52:37 INFO BlockManagerInfo: Removed broadcast_39_piece0 on kubernetes.docker.internal:50990 in memory (size: 4.5 KB, free: 912.2 MB)
21/12/17 14:52:37 INFO ContextCleaner: Cleaned accumulator 941
21/12/17 14:52:37 INFO ContextCleaner: Cleaned accumulator 977
21/12/17 14:52:37 INFO ContextCleaner: Cleaned accumulator 1027
21/12/17 14:52:37 INFO ContextCleaner: Cleaned accumulator 994
21/12/17 14:52:37 INFO ContextCleaner: Cleaned accumulator 1109
21/12/17 14:52:37 INFO ContextCleaner: Cleaned accumulator 996
21/12/17 14:52:37 INFO ContextCleaner: Cleaned accumulator 1073
21/12/17 14:52:37 INFO ContextCleaner: Cleaned accumulator 1148
21/12/17 14:52:37 INFO ContextCleaner: Cleaned accumulator 1051
21/12/17 14:52:37 INFO ContextCleaner: Cleaned accumulator 1153
21/12/17 14:52:37 INFO ContextCleaner: Cleaned accumulator 1111
21/12/17 14:52:37 INFO ContextCleaner: Cleaned accumulator 938
21/12/17 14:52:37 INFO ContextCleaner: Cleaned accumulator 1149
21/12/17 14:52:37 INFO ContextCleaner: Cleaned accumulator 1072
21/12/17 14:52:37 INFO ContextCleaner: Cleaned accumulator 1097
21/12/17 14:52:37 INFO ContextCleaner: Cleaned accumulator 1162
21/12/17 14:52:37 INFO ContextCleaner: Cleaned accumulator 1020
21/12/17 14:52:37 INFO ContextCleaner: Cleaned accumulator 1074
21/12/17 14:52:37 INFO ContextCleaner: Cleaned accumulator 985
21/12/17 14:52:37 INFO ContextCleaner: Cleaned accumulator 1011
21/12/17 14:52:37 INFO ContextCleaner: Cleaned accumulator 1069
21/12/17 14:52:37 INFO ContextCleaner: Cleaned accumulator 1157
21/12/17 14:52:37 INFO ContextCleaner: Cleaned accumulator 956
21/12/17 14:52:37 INFO ContextCleaner: Cleaned accumulator 1077
21/12/17 14:52:37 INFO ContextCleaner: Cleaned accumulator 953
21/12/17 14:52:37 INFO ContextCleaner: Cleaned accumulator 1152
21/12/17 14:52:37 INFO ContextCleaner: Cleaned accumulator 954
21/12/17 14:52:37 INFO ContextCleaner: Cleaned accumulator 986
21/12/17 14:52:37 INFO ContextCleaner: Cleaned accumulator 1102
21/12/17 14:52:37 INFO ContextCleaner: Cleaned accumulator 1138
21/12/17 14:52:37 INFO ContextCleaner: Cleaned accumulator 1184
21/12/17 14:52:37 INFO ContextCleaner: Cleaned accumulator 1139
21/12/17 14:52:37 INFO ContextCleaner: Cleaned accumulator 1056
21/12/17 14:52:37 INFO ContextCleaner: Cleaned accumulator 991
21/12/17 14:52:37 INFO ContextCleaner: Cleaned accumulator 959
21/12/17 14:52:37 INFO ContextCleaner: Cleaned accumulator 967
21/12/17 14:52:37 INFO ContextCleaner: Cleaned accumulator 946
21/12/17 14:52:37 INFO BlockManagerInfo: Removed broadcast_40_piece0 on kubernetes.docker.internal:50990 in memory (size: 14.8 KB, free: 912.3 MB)
21/12/17 14:52:37 INFO ContextCleaner: Cleaned accumulator 1040
21/12/17 14:52:37 INFO ContextCleaner: Cleaned accumulator 1041
21/12/17 14:52:37 INFO ContextCleaner: Cleaned accumulator 1050
21/12/17 14:52:37 INFO ContextCleaner: Cleaned accumulator 1113
21/12/17 14:52:37 INFO ContextCleaner: Cleaned accumulator 1014
21/12/17 14:52:37 INFO ContextCleaner: Cleaned accumulator 942
21/12/17 14:52:37 INFO ContextCleaner: Cleaned accumulator 1023
21/12/17 14:52:37 INFO ContextCleaner: Cleaned accumulator 1094
21/12/17 14:52:37 INFO ContextCleaner: Cleaned accumulator 1084
21/12/17 14:52:37 INFO ContextCleaner: Cleaned accumulator 1000
21/12/17 14:52:37 INFO ContextCleaner: Cleaned accumulator 1036
21/12/17 14:52:37 INFO ContextCleaner: Cleaned accumulator 1168
21/12/17 14:52:37 INFO ContextCleaner: Cleaned accumulator 1164
21/12/17 14:52:37 INFO ContextCleaner: Cleaned accumulator 1167
21/12/17 14:52:37 INFO ContextCleaner: Cleaned accumulator 1039
21/12/17 14:52:37 INFO ContextCleaner: Cleaned accumulator 981
21/12/17 14:52:37 INFO ContextCleaner: Cleaned accumulator 995
21/12/17 14:52:37 INFO ContextCleaner: Cleaned accumulator 1071
21/12/17 14:52:37 INFO ContextCleaner: Cleaned accumulator 1128
21/12/17 14:52:37 INFO ContextCleaner: Cleaned accumulator 1178
21/12/17 14:52:37 INFO ContextCleaner: Cleaned accumulator 979
21/12/17 14:52:37 INFO ContextCleaner: Cleaned accumulator 1181
21/12/17 14:52:37 INFO ContextCleaner: Cleaned accumulator 1035
21/12/17 14:52:37 INFO ContextCleaner: Cleaned accumulator 1185
21/12/17 14:52:37 INFO ContextCleaner: Cleaned accumulator 965
21/12/17 14:52:37 INFO ContextCleaner: Cleaned accumulator 1187
21/12/17 14:52:37 INFO ContextCleaner: Cleaned accumulator 976
21/12/17 14:52:37 INFO ContextCleaner: Cleaned accumulator 1100
21/12/17 14:52:37 INFO ContextCleaner: Cleaned accumulator 1144
21/12/17 14:52:37 INFO ContextCleaner: Cleaned accumulator 969
21/12/17 14:52:37 INFO ContextCleaner: Cleaned accumulator 998
21/12/17 14:52:37 INFO ContextCleaner: Cleaned accumulator 1024
21/12/17 14:52:37 INFO ContextCleaner: Cleaned accumulator 1131
21/12/17 14:52:37 INFO ContextCleaner: Cleaned accumulator 1172
21/12/17 14:52:37 INFO ContextCleaner: Cleaned accumulator 972
21/12/17 14:52:37 INFO ContextCleaner: Cleaned accumulator 1158
21/12/17 14:52:37 INFO ContextCleaner: Cleaned accumulator 1165
21/12/17 14:52:37 INFO ContextCleaner: Cleaned accumulator 1186
21/12/17 14:52:37 INFO ContextCleaner: Cleaned accumulator 944
21/12/17 14:52:37 INFO ContextCleaner: Cleaned accumulator 1088
21/12/17 14:52:37 INFO ContextCleaner: Cleaned accumulator 983
21/12/17 14:52:37 INFO ContextCleaner: Cleaned accumulator 1115
21/12/17 14:52:37 INFO ContextCleaner: Cleaned accumulator 1096
21/12/17 14:52:37 INFO BlockManagerInfo: Removed broadcast_36_piece0 on kubernetes.docker.internal:50990 in memory (size: 3.2 KB, free: 912.3 MB)
21/12/17 14:52:37 INFO ContextCleaner: Cleaned accumulator 1058
21/12/17 14:52:37 INFO ContextCleaner: Cleaned accumulator 1182
21/12/17 14:52:37 INFO ContextCleaner: Cleaned accumulator 970
21/12/17 14:52:37 INFO ContextCleaner: Cleaned accumulator 1068
21/12/17 14:52:37 INFO ContextCleaner: Cleaned accumulator 1118
21/12/17 14:52:37 INFO ContextCleaner: Cleaned accumulator 1140
21/12/17 14:52:37 INFO ContextCleaner: Cleaned accumulator 1101
21/12/17 14:52:37 INFO ContextCleaner: Cleaned accumulator 988
21/12/17 14:52:37 INFO ContextCleaner: Cleaned accumulator 1017
21/12/17 14:52:37 INFO ContextCleaner: Cleaned accumulator 951
21/12/17 14:52:37 INFO ContextCleaner: Cleaned accumulator 1129
21/12/17 14:52:37 INFO ContextCleaner: Cleaned accumulator 1009
21/12/17 14:52:37 INFO ContextCleaner: Cleaned accumulator 1091
21/12/17 14:52:37 INFO ContextCleaner: Cleaned accumulator 955
21/12/17 14:52:37 INFO ContextCleaner: Cleaned accumulator 1145
21/12/17 14:52:37 INFO ContextCleaner: Cleaned accumulator 1106
21/12/17 14:52:37 INFO ContextCleaner: Cleaned accumulator 974
21/12/17 14:52:37 INFO ContextCleaner: Cleaned accumulator 963
21/12/17 14:52:37 INFO ContextCleaner: Cleaned accumulator 950
21/12/17 14:52:37 INFO ContextCleaner: Cleaned accumulator 1189
21/12/17 14:52:37 INFO ContextCleaner: Cleaned accumulator 1022
21/12/17 14:52:37 INFO ContextCleaner: Cleaned accumulator 1064
21/12/17 14:52:37 INFO ContextCleaner: Cleaned accumulator 1105
21/12/17 14:52:37 INFO ContextCleaner: Cleaned accumulator 1155
21/12/17 14:52:37 INFO ContextCleaner: Cleaned accumulator 1078
21/12/17 14:52:37 INFO ContextCleaner: Cleaned accumulator 1047
21/12/17 14:52:37 INFO ContextCleaner: Cleaned accumulator 1092
21/12/17 14:52:37 INFO ContextCleaner: Cleaned accumulator 1134
21/12/17 14:52:37 INFO ContextCleaner: Cleaned accumulator 1098
21/12/17 14:52:37 INFO ContextCleaner: Cleaned accumulator 1135
21/12/17 14:52:37 INFO ContextCleaner: Cleaned accumulator 1146
21/12/17 14:52:37 INFO ContextCleaner: Cleaned accumulator 1143
21/12/17 14:52:37 INFO ContextCleaner: Cleaned accumulator 980
21/12/17 14:52:37 INFO ContextCleaner: Cleaned accumulator 1046
21/12/17 14:52:37 INFO ContextCleaner: Cleaned accumulator 1026
21/12/17 14:52:37 INFO ContextCleaner: Cleaned accumulator 987
21/12/17 14:52:37 INFO ContextCleaner: Cleaned accumulator 1136
21/12/17 14:52:37 INFO ContextCleaner: Cleaned accumulator 960
21/12/17 14:52:37 INFO ContextCleaner: Cleaned accumulator 1002
21/12/17 14:52:37 INFO ContextCleaner: Cleaned accumulator 1166
21/12/17 14:52:37 INFO ContextCleaner: Cleaned accumulator 1062
21/12/17 14:52:37 INFO ContextCleaner: Cleaned accumulator 1065
21/12/17 14:52:37 INFO ContextCleaner: Cleaned accumulator 1159
21/12/17 14:52:37 INFO BlockManagerInfo: Removed broadcast_33_piece0 on kubernetes.docker.internal:50990 in memory (size: 3.3 KB, free: 912.3 MB)
21/12/17 14:52:37 INFO ContextCleaner: Cleaned accumulator 993
21/12/17 14:52:37 INFO ContextCleaner: Cleaned accumulator 1067
21/12/17 14:52:37 INFO ContextCleaner: Cleaned accumulator 1049
21/12/17 14:52:37 INFO ContextCleaner: Cleaned accumulator 1055
21/12/17 14:52:37 INFO ContextCleaner: Cleaned accumulator 947
21/12/17 14:52:37 INFO ContextCleaner: Cleaned accumulator 1090
21/12/17 14:52:37 INFO ContextCleaner: Cleaned accumulator 1174
21/12/17 14:52:37 INFO ContextCleaner: Cleaned accumulator 1114
21/12/17 14:52:37 INFO ContextCleaner: Cleaned accumulator 945
21/12/17 14:52:37 INFO ContextCleaner: Cleaned accumulator 1001
21/12/17 14:52:37 INFO ContextCleaner: Cleaned accumulator 933
21/12/17 14:52:37 INFO ContextCleaner: Cleaned accumulator 1112
21/12/17 14:52:37 INFO ContextCleaner: Cleaned accumulator 964
21/12/17 14:52:37 INFO ContextCleaner: Cleaned accumulator 1141
21/12/17 14:52:37 INFO ContextCleaner: Cleaned accumulator 948
21/12/17 14:52:37 INFO ContextCleaner: Cleaned accumulator 1183
21/12/17 14:52:37 INFO ContextCleaner: Cleaned accumulator 1116
21/12/17 14:52:37 INFO BlockManagerInfo: Removed broadcast_34_piece0 on kubernetes.docker.internal:50990 in memory (size: 3.3 KB, free: 912.3 MB)
21/12/17 14:52:37 INFO ContextCleaner: Cleaned accumulator 968
21/12/17 14:52:37 INFO BlockManagerInfo: Removed broadcast_38_piece0 on kubernetes.docker.internal:50990 in memory (size: 14.0 KB, free: 912.3 MB)
21/12/17 14:52:37 INFO ContextCleaner: Cleaned accumulator 1099
21/12/17 14:52:37 INFO ContextCleaner: Cleaned accumulator 1010
21/12/17 14:52:37 INFO ContextCleaner: Cleaned accumulator 943
21/12/17 14:52:37 INFO ContextCleaner: Cleaned accumulator 1127
21/12/17 14:52:37 INFO ContextCleaner: Cleaned accumulator 975
21/12/17 14:52:37 INFO ContextCleaner: Cleaned accumulator 1130
21/12/17 14:52:37 INFO BlockManagerInfo: Removed broadcast_37_piece0 on kubernetes.docker.internal:50990 in memory (size: 3.3 KB, free: 912.3 MB)
21/12/17 14:52:37 INFO ContextCleaner: Cleaned shuffle 5
21/12/17 14:52:37 INFO ContextCleaner: Cleaned accumulator 1079
21/12/17 14:52:37 INFO ContextCleaner: Cleaned accumulator 1006
21/12/17 14:52:37 INFO ContextCleaner: Cleaned accumulator 1179
21/12/17 14:52:37 INFO ContextCleaner: Cleaned accumulator 1013
21/12/17 14:52:37 INFO ContextCleaner: Cleaned accumulator 1015
21/12/17 14:52:37 INFO ContextCleaner: Cleaned accumulator 1005
21/12/17 14:52:37 INFO BlockManagerInfo: Removed broadcast_35_piece0 on kubernetes.docker.internal:50990 in memory (size: 3.2 KB, free: 912.3 MB)
21/12/17 14:52:37 INFO ContextCleaner: Cleaned accumulator 1082
21/12/17 14:52:37 INFO ContextCleaner: Cleaned accumulator 1188
21/12/17 14:52:37 INFO ContextCleaner: Cleaned accumulator 1085
21/12/17 14:52:37 INFO ContextCleaner: Cleaned accumulator 1008
21/12/17 14:52:37 INFO ContextCleaner: Cleaned accumulator 1070
21/12/17 14:52:37 INFO ContextCleaner: Cleaned accumulator 1057
21/12/17 14:52:37 INFO ContextCleaner: Cleaned accumulator 1190
21/12/17 14:52:37 INFO ContextCleaner: Cleaned accumulator 1038
21/12/17 14:52:37 INFO ContextCleaner: Cleaned accumulator 990
21/12/17 14:52:37 INFO ContextCleaner: Cleaned accumulator 1125
21/12/17 14:52:37 INFO ContextCleaner: Cleaned accumulator 1061
21/12/17 14:52:37 INFO ContextCleaner: Cleaned accumulator 1089
21/12/17 14:52:37 INFO ContextCleaner: Cleaned accumulator 1018
21/12/17 14:52:37 INFO ContextCleaner: Cleaned accumulator 1150
21/12/17 14:52:37 INFO ContextCleaner: Cleaned accumulator 1052
21/12/17 14:52:37 INFO ContextCleaner: Cleaned accumulator 1095
21/12/17 14:52:37 INFO ContextCleaner: Cleaned accumulator 1032
21/12/17 14:52:37 INFO ContextCleaner: Cleaned accumulator 937
21/12/17 14:52:37 INFO ContextCleaner: Cleaned accumulator 1123
21/12/17 14:52:37 INFO ContextCleaner: Cleaned accumulator 952
21/12/17 14:52:37 INFO ContextCleaner: Cleaned accumulator 1029
21/12/17 14:52:37 INFO ContextCleaner: Cleaned accumulator 1037
21/12/17 14:52:37 INFO ContextCleaner: Cleaned accumulator 962
21/12/17 14:52:37 INFO ContextCleaner: Cleaned accumulator 1137
21/12/17 14:52:37 INFO ContextCleaner: Cleaned accumulator 1173
21/12/17 14:52:37 INFO ContextCleaner: Cleaned accumulator 1021
21/12/17 14:52:37 INFO ContextCleaner: Cleaned accumulator 1160
21/12/17 14:52:37 INFO ContextCleaner: Cleaned accumulator 21
21/12/17 14:52:37 INFO ContextCleaner: Cleaned accumulator 15
21/12/17 14:52:37 INFO ContextCleaner: Cleaned accumulator 26
21/12/17 14:52:37 INFO ContextCleaner: Cleaned accumulator 7
21/12/17 14:52:37 INFO ContextCleaner: Cleaned accumulator 22
21/12/17 14:52:37 INFO ContextCleaner: Cleaned accumulator 16
21/12/17 14:52:37 INFO ContextCleaner: Cleaned accumulator 23
21/12/17 14:52:37 INFO ContextCleaner: Cleaned accumulator 13
21/12/17 14:52:37 INFO ContextCleaner: Cleaned accumulator 11
21/12/17 14:52:37 INFO ContextCleaner: Cleaned accumulator 28
21/12/17 14:52:37 INFO ContextCleaner: Cleaned accumulator 20
21/12/17 14:52:37 INFO ContextCleaner: Cleaned accumulator 9
21/12/17 14:52:37 INFO ContextCleaner: Cleaned accumulator 24
21/12/17 14:52:37 INFO ContextCleaner: Cleaned accumulator 12
21/12/17 14:52:37 INFO ContextCleaner: Cleaned accumulator 27
21/12/17 14:52:37 INFO ContextCleaner: Cleaned accumulator 4
21/12/17 14:52:37 INFO ContextCleaner: Cleaned accumulator 3
21/12/17 14:52:37 INFO ContextCleaner: Cleaned accumulator 14
21/12/17 14:52:37 INFO ContextCleaner: Cleaned accumulator 10
21/12/17 14:52:37 INFO ContextCleaner: Cleaned accumulator 18
21/12/17 14:52:37 INFO ContextCleaner: Cleaned accumulator 6
21/12/17 14:52:37 INFO BlockManagerInfo: Removed broadcast_0_piece0 on kubernetes.docker.internal:50990 in memory (size: 3.3 KB, free: 912.3 MB)
21/12/17 14:52:37 INFO ContextCleaner: Cleaned accumulator 2
21/12/17 14:52:37 INFO ContextCleaner: Cleaned accumulator 25
21/12/17 14:52:37 INFO ContextCleaner: Cleaned accumulator 17
21/12/17 14:52:37 INFO ContextCleaner: Cleaned accumulator 19
21/12/17 15:14:53 INFO SparkContext: Invoking stop() from shutdown hook
21/12/17 15:14:53 INFO SparkUI: Stopped Spark web UI at http://kubernetes.docker.internal:4040
21/12/17 15:14:53 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
21/12/17 15:14:53 INFO MemoryStore: MemoryStore cleared
21/12/17 15:14:53 INFO BlockManager: BlockManager stopped
21/12/17 15:14:53 INFO BlockManagerMaster: BlockManagerMaster stopped
21/12/17 15:14:53 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
21/12/17 15:14:53 WARN SparkEnv: Exception while deleting Spark temp dir: C:\Users\uhp07025\AppData\Local\spark\spark-2.3.3-bin-hadoop2.7\tmp\local\spark-82d9eec9-a975-42c4-9022-a576e60a321e\userFiles-6a667cb1-735c-4cda-9933-3f9edc6a8c8a
java.io.IOException: Failed to delete: C:\Users\uhp07025\AppData\Local\spark\spark-2.3.3-bin-hadoop2.7\tmp\local\spark-82d9eec9-a975-42c4-9022-a576e60a321e\userFiles-6a667cb1-735c-4cda-9933-3f9edc6a8c8a
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1074)
	at org.apache.spark.SparkEnv.stop(SparkEnv.scala:103)
	at org.apache.spark.SparkContext$$anonfun$stop$11.apply$mcV$sp(SparkContext.scala:1947)
	at org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1361)
	at org.apache.spark.SparkContext.stop(SparkContext.scala:1946)
	at org.apache.spark.SparkContext$$anonfun$2.apply$mcV$sp(SparkContext.scala:573)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:216)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1992)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at scala.util.Try$.apply(Try.scala:192)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at org.apache.hadoop.util.ShutdownHookManager$1.run(ShutdownHookManager.java:54)
21/12/17 15:14:53 INFO SparkContext: Successfully stopped SparkContext
21/12/17 15:14:53 INFO ShutdownHookManager: Shutdown hook called
21/12/17 15:14:53 INFO ShutdownHookManager: Deleting directory C:\Users\uhp07025\AppData\Local\spark\spark-2.3.3-bin-hadoop2.7\tmp\local\spark-82d9eec9-a975-42c4-9022-a576e60a321e\userFiles-6a667cb1-735c-4cda-9933-3f9edc6a8c8a
21/12/17 15:14:53 ERROR ShutdownHookManager: Exception while deleting Spark temp dir: C:\Users\uhp07025\AppData\Local\spark\spark-2.3.3-bin-hadoop2.7\tmp\local\spark-82d9eec9-a975-42c4-9022-a576e60a321e\userFiles-6a667cb1-735c-4cda-9933-3f9edc6a8c8a
java.io.IOException: Failed to delete: C:\Users\uhp07025\AppData\Local\spark\spark-2.3.3-bin-hadoop2.7\tmp\local\spark-82d9eec9-a975-42c4-9022-a576e60a321e\userFiles-6a667cb1-735c-4cda-9933-3f9edc6a8c8a
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1074)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1$$anonfun$apply$mcV$sp$3.apply(ShutdownHookManager.scala:65)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1$$anonfun$apply$mcV$sp$3.apply(ShutdownHookManager.scala:62)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1.apply$mcV$sp(ShutdownHookManager.scala:62)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:216)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1992)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at scala.util.Try$.apply(Try.scala:192)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at org.apache.hadoop.util.ShutdownHookManager$1.run(ShutdownHookManager.java:54)
21/12/17 15:14:53 INFO ShutdownHookManager: Deleting directory C:\Users\uhp07025\AppData\Local\Temp\spark-c3077172-0bdb-433e-b21f-75d72a4e6048
21/12/17 15:14:53 INFO ShutdownHookManager: Deleting directory C:\Users\uhp07025\AppData\Local\spark\spark-2.3.3-bin-hadoop2.7\tmp\local\spark-82d9eec9-a975-42c4-9022-a576e60a321e
21/12/17 15:14:53 ERROR ShutdownHookManager: Exception while deleting Spark temp dir: C:\Users\uhp07025\AppData\Local\spark\spark-2.3.3-bin-hadoop2.7\tmp\local\spark-82d9eec9-a975-42c4-9022-a576e60a321e
java.io.IOException: Failed to delete: C:\Users\uhp07025\AppData\Local\spark\spark-2.3.3-bin-hadoop2.7\tmp\local\spark-82d9eec9-a975-42c4-9022-a576e60a321e
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1074)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1$$anonfun$apply$mcV$sp$3.apply(ShutdownHookManager.scala:65)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1$$anonfun$apply$mcV$sp$3.apply(ShutdownHookManager.scala:62)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1.apply$mcV$sp(ShutdownHookManager.scala:62)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:216)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1992)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at scala.util.Try$.apply(Try.scala:192)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at org.apache.hadoop.util.ShutdownHookManager$1.run(ShutdownHookManager.java:54)
